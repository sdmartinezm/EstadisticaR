# Probabilidad y estadística en `R`

## Probabilidad en `R`

### Distribuciones

Cuando trabajamos con diferentes distribuciones estadísticas, a menudo queremos hacer declaraciones probabilísticas basadas en la distribución.

Por lo general, queremos saber una de cuatro cosas:

* La densidad (pdf) a un valor particular.
* La distribución (cdf) a un valor particular.
* El valor de un cuantil correspondiente a una probabilidad particular.
* Una extracción aleatoria de valores de una distribución particular.

Esto solía hacerse con tablas estadísticas impresas en la parte posterior de los libros de texto. Ahora, `R` tiene funciones para obtener densidad, distribución, cuantiles y valores aleatorios.

La estructura general de nomenclaturas de las funciones relevantes de `R`:

* `dname` calcula la densidad (pdf) en la entrada `x`.
* `pname` calcula la distribución (cdf) en la entrada `x`.
* `qname` calcula el cuantil con una probabilidad de entrada.
* `rname` genera valores aleatorios de una distribución particular.

Tenga en cuenta que `name` representa el nombre de la distribución dada.

Por ejemplo, considere una variable aleatoria $X$ que es $N(\mu = 2, \sigma^2 = 25)$. (Tenga en cuenta que estamos parametrizando usando la varianza $\sigma^2$. Sin embargo, `R` usa la desviación estándar).

Para calcular el valor del pdf en `x = 3`, es decir, la altura de la curva en `x = 3`, utilice:

```{r}
dnorm(x = 3, mean = 2, sd = 5)
```

Para calcular el valor de la cdf en `x = 3`, es decir, $P(X\leq3)$, la probabilidad de que $X$ sea menor o igual que `3`, utilice:

```{r}
pnorm(q = 3, mean = 2, sd = 5)
```

O, para calcular el cuantil de probabilidad 0.975, use:

```{r}
qnorm(p = 0.975, mean = 2, sd = 5)
```

Por último, para generar una muestra aleatoria de tamaño `n = 10`, utilice:

```{r}
rnorm(n = 10, mean = 2, sd = 5)
```

Estas funciones existen para muchas otras distribuciones, que incluyen, entre otras:

| Command  | Distribution |
|----------|--------------|
| `*binom` | Binomial     |
| `*t`     | t            |
| `*pois`  | Poisson      |
| `*f`     | F            |
| `*chisq` | Chi-cuadrado |

Donde `*` puede ser `d`,` p`, `q` y` r`. Cada distribución tendrá su propio conjunto de parámetros que deben pasarse a las funciones como argumentos. Por ejemplo, `dbinom()` no tendría argumentos para `mean` y` sd`, ya que no son parámetros de la distribución. En cambio, una distribución binomial suele estar parametrizada por $n$ y $p$, sin embargo, `R` elige llamarlos de otra manera. Para encontrar los nombres que usa `R`, usaríamos `?dbinom` y veremos que `R` en su lugar llama a los argumentos` size` y `prob`. Por ejemplo:

```{r}
dbinom(x = 6, size = 10, prob = 0.75)
```

También tenga en cuenta que, cuando se utilizan las funciones `dname` con distribuciones discretas, son las pmf de la distribución. Por ejemplo, el comando anterior es $P(Y = 6)$ si $Y\sim b(n = 10, p = 0,75)$. (La probabilidad de lanzar una moneda injusta "10" veces y ver "6" caras, si la probabilidad de que salga cara es `0.75`).

## Pruebas de hipótesis en `R`

Un requisito previo es la comprensión de los conceptos básicos de la prueba de hipótesis. Recuerde la estructura básica de las pruebas de hipótesis:

- Se realiza un modelo general y los supuestos relacionados. (Las más comunes son las observaciones que siguen una distribución normal).
- Se especifican las hipótesis **nula** ($H_ {0}$) y **alternativa** ($H_ {1}$ o $H_{A}$). Por lo general, la nula especifica un valor particular de un parámetro.
- Con los datos dados, se calcula el **valor** del *estadístico de prueba*.
- Bajo los supuestos generales, además de asumir que la hipótesis nula es cierta, se conoce la **distribución** del *estadístico de prueba*.
- Dada la distribución y el valor del estadístico de la prueba, así como la forma de la hipótesis alternativa, podemos calcular un **valor p** de la prueba.
- Basándonos en el **valor p** y el nivel de significancia preespecificado, tomamos una decisión:
    - No rechazar la hipótesis nula.
    - Rechazar la hipótesis nula.
    
Haremos una revisión rápida de dos de las pruebas más comunes para mostrar cómo se realizan usando `R`.

### Prueba t de una muestra: revisión

Suponer que $x_{i} \sim \mathrm{N}(\mu,\sigma^{2})$ Y nosotros queremos probar $H_{0}: \mu = \mu_{0}$ versus $H_{1}: \mu \neq \mu_{0}.$

Asumiendo que $\sigma$ es desconocido, usamos la estadística de prueba $t$ de Student de una muestra:

\[
t = \frac{\bar{x}-\mu_{0}}{s/\sqrt{n}} \sim t_{n-1},
\]

donde $\bar{x} = \displaystyle\frac{\sum_{i=1}^{n}x_{i}}{n}$ y $s = \sqrt{\displaystyle\frac{1}{n - 1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$.

un intervalo de confianza al $100(1 - \alpha)$\% para $\mu$ esta dado por,

\[
\bar{x} \pm t_{n-1}(\alpha/2)\frac{s}{\sqrt{n}}
\]

donde $t_{n-1}(\alpha/2)$ es el valor crítico tal que $P\left(t>t_{n-1}(\alpha/2)\right) = \alpha/2$ con $n-1$ grados de libertad.

### Prueba t de una muestra: ejemplo

Suponga que una tienda vende cajas de "16 onzas" de cereal *Captain Crisp*. Se tomó y pesó una muestra aleatoria de 9 cajas. El peso en onzas se almacena en el marco de datos `capt_crisp`.

```{r}
capt_crisp = data.frame(weight = c(15.5, 16.2, 16.1, 15.8, 15.6, 16.0, 15.8, 15.9, 16.2))
```

La compañía que fabrica el cereal *Captain Crisp* afirma que el peso promedio de una caja es de al menos 16 onzas. Supondremos que el peso del cereal en una caja se distribuye normalmente y usaremos un nivel de significancia de 0.05 para probar la afirmación de la compañía.

Probar $H_{0}: \mu \geq 16$ versus $H_{1}: \mu < 16$, el estadístico de prueba es

\[
t = \frac{\bar{x} - \mu_{0}}{s / \sqrt{n}}
\]

La media muestral $\bar{x}$ y la desviación estándar muestral $s$ pueden calcularse fácilmente usando `R`. También creamos variables que almacenan la media hipotética y el tamaño de la muestra.

```{r}
x_bar = mean(capt_crisp$weight)
s     = sd(capt_crisp$weight)
mu_0  = 16
n     = 9
```

Entonces podemos calcular fácilmente la estadística de prueba.

```{r}
t = (x_bar - mu_0) / (s / sqrt(n))
t
```

Bajo la hipótesis nula, el estadístico de prueba tiene una distribución $t$ con $n - 1$ grados de libertad, en este caso `r n - 1`.

Para completar la prueba, necesitamos obtener el valor p de la prueba. Dado que esta es una prueba unilateral con una alternativa menor que, necesitamos el área a la izquierda de `r t` para una distribución $t$ con `r n - 1` grados de libertad. Es decir,

\[
P(t_{`r n - 1`} < `r t`)
\]

```{r}
pt(t, df = n - 1)
```

Ahora tenemos el valor p de nuestra prueba, que es mayor que nuestro nivel de significancia (0.05), por lo que no rechazamos la hipótesis nula.

Alternativamente, todo este proceso podría haberse completado usando una línea de código en `R`.

```{r}
t.test(x = capt_crisp$weight, mu = 16, alternative = c("less"), conf.level = 0.95)
```

Proporcionamos a `R` los datos, el valor hipotético de $\mu$, la alternativa y el nivel de confianza. `R` luego devuelve una gran cantidad de información que incluye:

- El valor del estadístico de prueba.
- Los grados de libertad de la distribución bajo la hipótesis nula.
- El valor p de la prueba.
- El intervalo de confianza que corresponde a la prueba.
- Una estimación de $\mu$.

Dado que la prueba fue unilateral, `R` arrojó un intervalo de confianza unilateral. Si por el contrario quisiéramos un intervalo de dos caras para el peso medio de las cajas de cereal *Captain Crisp*, podríamos modificar nuestro código.

```{r}
capt_test_results = t.test(capt_crisp$weight, mu = 16,
                           alternative = c("two.sided"), conf.level = 0.95)
```

Esta vez hemos almacenado los resultados. Al hacerlo, podemos acceder directamente a partes de la salida de `t.test()`. Para ver qué información está disponible usamos la función `names()`.

```{r}
names(capt_test_results)
```

Estamos interesados en el intervalo de confianza que se almacena en `conf.int`.

```{r}
capt_test_results$conf.int
```

Comprobemos este intervalo "a mano". La única información que nos falta es el valor crítico, $t_{n-1}(\alpha/2) = t_{8}(0.025)$, que se puede calcular en `R` usando la función `qt()`.

```{r}
qt(0.975, df = 8)
```

Entonces, el IC del 95\% para el peso medio de una caja de cereal se calcula ingresando a la fórmula,

\[
\bar{x} \pm t_{n-1}(\alpha/2) \frac{s}{\sqrt{n}}
\]

```{r}
c(mean(capt_crisp$weight) - qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9),
  mean(capt_crisp$weight) + qt(0.975, df = 8) * sd(capt_crisp$weight) / sqrt(9))
```

### Prueba t de dos muestras: revisión

Suponer que $x_{i} \sim \mathrm{N}(\mu_{x}, \sigma^{2})$ y $y_{i} \sim \mathrm{N}(\mu_{y}, \sigma^{2}).$ 

Se quiere probar $H_{0}: \mu_{x} - \mu_{y} = \mu_{0}$ versus $H_{1}: \mu_{x} - \mu_{y} \neq \mu_{0}.$

Asumiendo que $\sigma$ es desconocido, use la estadística de prueba $t$ de Student de dos muestras:

\[
t = \frac{(\bar{x} - \bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2},
\]

donde $\displaystyle\bar{x}=\frac{\sum_{i=1}^{n}x_{i}}{n}$, $\displaystyle\bar{y}=\frac{\sum_{i=1}^{m}y_{i}}{m}$, y $s_p^2 = \displaystyle\frac{(n-1)s_x^2+(m-1)s_y^2}{n+m-2}$.

Un IC al $100(1-\alpha)$\% para $\mu_{x}-\mu_{y}$ esta dado por

\[
(\bar{x} - \bar{y}) \pm t_{n+m-2}(\alpha/2) \left(s_{p}\textstyle\sqrt{\frac{1}{n}+\frac{1}{m}}\right),
\]

donde $t_{n+m-2}(\alpha/2)$ es el valor crítico tal que $P\left(t>t_{n+m-2}(\alpha/2)\right)=\alpha/2$.

### Prueba t de dos muestras: Ejemplo

Suponga que las distribuciones de $X$ y $Y$ son $\mathrm{N}(\mu_{1},\sigma^{2})$ y $\mathrm{N}(\mu_{2},\sigma^{2})$, respectivamente. Dadas las $n = 6$ observaciones de $X$,

```{r}
x = c(70, 82, 78, 74, 94, 82)
n = length(x)
```

y las $m = 8$ observaciones de $Y$,

```{r}
y = c(64, 72, 60, 76, 72, 80, 84, 68)
m = length(y)
```

Probaremos $H_{0}: \mu_{1} = \mu_{2}$ versus $H_{1}: \mu_{1} > \mu_{2}$.

Primero, tenga en cuenta que podemos calcular las medias muestrales y las desviaciones estándar.

```{r}
x_bar = mean(x)
s_x   = sd(x)
y_bar = mean(y)
s_y   = sd(y)
```

Luego podemos calcular la desviación estándar combinada.

\[
s_{p} = \sqrt{\frac{(n-1)s_{x}^{2}+(m-1)s_{y}^{2}}{n+m-2}}
\]

```{r}
s_p = sqrt(((n - 1) * s_x ^ 2 + (m - 1) * s_y ^ 2) / (n + m - 2))
```

Por lo tanto, el estadístico de prueba $t$ relevante viene dado por

\[
t = \frac{(\bar{x}-\bar{y})-\mu_{0}}{s_{p}\sqrt{\frac{1}{n}+\frac{1}{m}}}.
\]

```{r}
t = ((x_bar - y_bar) - 0) / (s_p * sqrt(1 / n + 1 / m))
t
```

Tenga en cuenta que $t \sim t_{n + m - 2} = t_{`r n + m - 2`}$, para que podamos calcular el valor p, que es

\[
P(t_{`r n + m - 2`} > `r t`).
\]

```{r}
1 - pt(t, df = n + m - 2)
```

Pero, de nuevo, podríamos haber realizado simplemente esta prueba en una línea de `R`.

```{r}
t.test(x, y, alternative = c("greater"), var.equal = TRUE)
```

Recuerde que una prueba $t$ de dos muestras se puede realizar con o sin un supuesto de varianza igual. Aquí, `var.equal = TRUE` le dice a` R` que nos gustaría realizar la prueba bajo el supuesto de varianza igual.

Arriba llevamos a cabo el análisis usando dos vectores `x` y `y`. En general, tendremos preferencia por usar marcos de datos.

```{r}
t_test_data = data.frame(values = c(x, y),
                         group  = c(rep("A", length(x)), rep("B", length(y))))
```

Ahora tenemos los datos almacenados en una sola variable (`values`) y hemos creado una segunda variable (`group`) que indica a qué "muestra" pertenece el valor.

```{r}
t_test_data
```

Ahora, para realizar la prueba, todavía usamos la función `t.test()` pero con la sintaxis `~` y un argumento `data`.

```{r}
t.test(values ~ group, data = t_test_data,
       alternative = c("greater"), var.equal = TRUE)
```

## Simulación

La simulación y el ajuste del modelo son procesos relacionados pero opuestos.

- En **simulación**, se conoce el *proceso de generación de datos*. Conoceremos la forma del modelo así como el valor de cada uno de los parámetros. En particular, a menudo controlaremos la distribución y los parámetros que definen la aleatoriedad o el ruido en los datos.
- En **ajuste de modelo**, se conocen los *datos*. Luego asumiremos una cierta forma de modelo y encontraremos los mejores valores posibles de los parámetros dados los datos observados. Esencialmente buscamos descubrir la verdad. A menudo, intentaremos ajustarnos a muchos modelos y aprenderemos métricas para evaluar qué modelo encaja mejor.


![Simulación vs modelado](images/simulation.png)

A menudo, simularemos datos de acuerdo con un proceso que decidamos, posteriormente usaremos un método de modelado visto. Luego podemos verificar qué tan bien funciona el método, ya que conocemos el proceso de generación de datos.

Una de las mayores fortalezas de `R` es su capacidad para realizar simulaciones utilizando funciones integradas para generar muestras aleatorias a partir de ciertas distribuciones. Veremos dos ejemplos muy simples aquí.

### Diferencias emparejadas

Consider the model:

\[
\begin{split}
X_{11}, X_{12}, \ldots, X_{1n} \sim N(\mu_1,\sigma^2)\\
X_{21}, X_{22}, \ldots, X_{2n} \sim N(\mu_2,\sigma^2)
\end{split}
\]

Se asume que $\mu_1 = 6$, $\mu_2 = 5$, $\sigma^2 = 4$ y $n = 25$.


\[
\begin{aligned}
\bar{X}_1 &= \displaystyle\frac{1}{n}\sum_{i=1}^{n}X_{1i}\\
\bar{X}_2 &= \displaystyle\frac{1}{n}\sum_{i=1}^{n}X_{2i}\\
D &= \bar{X}_1 - \bar{X}_2.
\end{aligned}
\]

Supongamos que nos gustaría calcular $P(0<D<2)$. Primero necesitaremos obtener la distribución de $D$.

Ahora,

\[
\bar{X}_1 \sim N\left(\mu_1,\frac{\sigma^2}{n}\right)
\]

y

\[
\bar{X}_2 \sim N\left(\mu_2,\frac{\sigma^2}{n}\right).
\]

Luego, 

\[
D = \bar{X}_1 - \bar{X}_2 \sim N\left(\mu_1-\mu_2, \frac{\sigma^2}{n} + \frac{\sigma^2}{n}\right) = N\left(6-5, \frac{4}{25} + \frac{4}{25}\right).
\]

Entnonces, 

\[
D \sim N(\mu = 1, \sigma^2 = 0.32).
\]

Thus,

\[
P(0 < D < 2) = P(D < 2) - P(D < 0).
\]

Esto se puede calcular usando `R` sin necesidad de estandarizar primero o usar una tabla.

```{r}
pnorm(2, mean = 1, sd = sqrt(0.32)) - pnorm(0, mean = 1, sd = sqrt(0.32))
```

Un enfoque alternativo sería **simular** una gran cantidad de observaciones de $D$ y luego usar la **distribución empírica** para calcular la probabilidad.

Nuestra estrategia será:

- Generar una muestra de 25 observaciones aleatorias a partir de $N(\mu_1 = 6,\sigma^2 = 4)$. Llamar a la media de esta muestra $\bar {x}_{1s}$.
- Generar una muestra de 25 observaciones aleatorias a partir de $N(\mu_1 = 5,\sigma^2 = 4)$. Llamar a la media de esta muestra $\bar {x}_{2s} $.
- Calcular las diferencias de las medias, $d_s=\bar{x}_{1s}-\bar{x}_{2s}$.

Repetir el proceso un gran número de veces. Luego usar la distribución de las observaciones simuladas de $d_s$ como una estimación de la verdadera distribución de $D$.

```{r}
set.seed(42)
num_samples = 10000
differences = rep(0, num_samples)
```

Antes de iniciar el ciclo `for` para realizar la operación, establecer una semilla para la reproducibilidad, crear y configurar una variable `num_samples` que definirá el número de repeticiones y, por último, crear una variable `differences` que almacenará los valores simulados, $d_s$.

Usando `set.seed()` podemos reproducir los resultados aleatorios de `rnorm()` cada vez que comience desde esa línea.

```{r}
for (s in 1:num_samples) {
  x1 = rnorm(n = 25, mean = 6, sd = 2)
  x2 = rnorm(n = 25, mean = 5, sd = 2)
  differences[s] = mean(x1) - mean(x2)
}
```

Para estimar $P(0<D<2) $ encontrar la proporción de valores de $d_s$ (entre los `r num_samples` valores de $d_s$ generados) que están entre 0 y 2.

```{r}
mean(0 < differences & differences < 2)
```

Recuerde que arriba la distribución de $D$ es $N(\mu=1,\sigma^2=0.32)$

Si miramos un histograma de las diferencias, encontramos que se parece mucho a una distribución normal.

```{r}
hist(differences, breaks = 20, 
     main   = "Distribución empírica de D",
     xlab   = "Valores simulados de D",
     col    = "dodgerblue",
     border = "darkorange")
```

Además, la media y la varianza de la muestra están muy cerca de lo que cabría esperar.

```{r}
mean(differences)
var(differences)
```

También podríamos haber logrado esta tarea con una sola línea de `R` más "idiomática".

```{r}
set.seed(42)
diffs = replicate(10000, mean(rnorm(25, 6, 2)) - mean(rnorm(25, 5, 2)))
```

Use `?Replicate` para echar un vistazo a la documentación de la función `replicate` y vea si puede entender cómo esta línea realiza las mismas operaciones que ejecutó nuestro ciclo `for` anterior.

```{r}
mean(differences == diffs)
```

Vemos que al establecer la misma semilla para la aleatorización, ¡obtenemos resultados idénticos!

### Distribución de una media muestral

Para otro ejemplo de simulación, simularemos observaciones de una distribución de Poisson y examinaremos la distribución empírica de la media muestral de estas observaciones.

Recuerde, si

\[
X \sim Pois(\mu)
\]

luego

\[
E[X] = \mu
\]

y

\[
Var[X] = \mu.
\]

Además, recuerde que para una variable aleatoria $X$ con media finita $\mu$ y varianza finita $\sigma^2$, el teorema del límite central nos dice que la media, $\bar{X}$ de una muestra aleatoria de tamaño $n$ es aproximadamente normal para valores *grandes* de $n$. Específicamente, como $n\to\infty $,

\[
\bar{X} \overset{d}{\to} N\left(\mu, \frac{\sigma^2}{n}\right).
\]

Lo siguiente verifica este resultado para una distribución de Poisson con $\mu=10$ y un tamaño de muestra de $n=50$.

```{r}
set.seed(1337)
mu          = 10
sample_size = 50
samples     = 100000
x_bars      = rep(0, samples)
```

```{r}
for(i in 1:samples){
  x_bars[i] = mean(rpois(sample_size, lambda = mu))
}
```

```{r}
x_bar_hist = hist(x_bars, breaks = 50, 
                  main = "Histograma de medias muestrales",
                  xlab = "Medias muestrales")
```

Ahora compararemos las estadísticas de muestra de la distribución empírica con sus valores conocidos basados en la distribución principal.

```{r}
c(mean(x_bars), mu)
```

```{r}
c(var(x_bars), mu / sample_size)
```

```{r}
c(sd(x_bars), sqrt(mu) / sqrt(sample_size))
```

Y aquí, calcularemos la proporción de medias muestrales que están dentro de 2 desviaciones estándar de la media poblacional.

```{r}
mean(x_bars > mu - 2 * sqrt(mu) / sqrt(sample_size) &
     x_bars < mu + 2 * sqrt(mu) / sqrt(sample_size))
```

Este último histograma utiliza un truco para sombrear aproximadamente las barras que están dentro de dos desviaciones estándar de la media).

```{r}
shading = ifelse(x_bar_hist$breaks > mu - 2 * sqrt(mu) / sqrt(sample_size) & 
                   x_bar_hist$breaks < mu + 2 * sqrt(mu) / sqrt(sample_size),
                  "darkorange", "dodgerblue")

x_bar_hist = hist(x_bars, breaks = 50, col = shading,
                  main = "Histograma de medias muestrales, Dos desviaciones estándar",
                  xlab = "Medias muestrales")
```



