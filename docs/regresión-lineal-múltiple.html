<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 9 Regresión lineal múltiple | Estadística aplicada con R</title>
  <meta name="description" content="Capítulo 9 Regresión lineal múltiple | Estadística aplicada con R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 9 Regresión lineal múltiple | Estadística aplicada con R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Regresión lineal múltiple | Estadística aplicada con R" />
  
  
  



<meta name="date" content="2021-05-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.gif" type="image/x-icon" />
<link rel="prev" href="inferencia-para-regresión-lineal-simple.html"/>
<link rel="next" href="construcción-del-modelo.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística aplicada con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#convenciones"><i class="fa fa-check"></i><b>1.1</b> Convenciones</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-a-r.html"><a href="introducción-a-r.html"><i class="fa fa-check"></i><b>2</b> Introducción a <code>R</code></a>
<ul>
<li class="chapter" data-level="2.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#primeros-pasos"><i class="fa fa-check"></i><b>2.1</b> Primeros pasos</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#cálculos-básicos"><i class="fa fa-check"></i><b>2.2</b> Cálculos básicos</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#obteniendo-ayuda"><i class="fa fa-check"></i><b>2.3</b> Obteniendo ayuda</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instalación-de-paquetes"><i class="fa fa-check"></i><b>2.4</b> Instalación de paquetes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datos-y-programación.html"><a href="datos-y-programación.html"><i class="fa fa-check"></i><b>3</b> Datos y programación</a>
<ul>
<li class="chapter" data-level="3.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#tipos-de-datos"><i class="fa fa-check"></i><b>3.1</b> Tipos de datos</a></li>
<li class="chapter" data-level="3.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#estructuras-de-datos"><i class="fa fa-check"></i><b>3.2</b> Estructuras de datos</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#vectores"><i class="fa fa-check"></i><b>3.2.1</b> Vectores</a></li>
<li class="chapter" data-level="3.2.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#vectorización"><i class="fa fa-check"></i><b>3.2.2</b> Vectorización</a></li>
<li class="chapter" data-level="3.2.3" data-path="datos-y-programación.html"><a href="datos-y-programación.html#operadores-logicos"><i class="fa fa-check"></i><b>3.2.3</b> Operadores logicos</a></li>
<li class="chapter" data-level="3.2.4" data-path="datos-y-programación.html"><a href="datos-y-programación.html#más-vectorización"><i class="fa fa-check"></i><b>3.2.4</b> Más vectorización</a></li>
<li class="chapter" data-level="3.2.5" data-path="datos-y-programación.html"><a href="datos-y-programación.html#matrices"><i class="fa fa-check"></i><b>3.2.5</b> Matrices</a></li>
<li class="chapter" data-level="3.2.6" data-path="datos-y-programación.html"><a href="datos-y-programación.html#listas"><i class="fa fa-check"></i><b>3.2.6</b> Listas</a></li>
<li class="chapter" data-level="3.2.7" data-path="datos-y-programación.html"><a href="datos-y-programación.html#marcos-de-datos"><i class="fa fa-check"></i><b>3.2.7</b> Marcos de datos</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="datos-y-programación.html"><a href="datos-y-programación.html#conceptos-básicos-de-programación"><i class="fa fa-check"></i><b>3.3</b> Conceptos básicos de programación</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#flujo-de-control"><i class="fa fa-check"></i><b>3.3.1</b> Flujo de control</a></li>
<li class="chapter" data-level="3.3.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#funciones"><i class="fa fa-check"></i><b>3.3.2</b> Funciones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html"><i class="fa fa-check"></i><b>4</b> Resumen de datos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#resumen-estadístico"><i class="fa fa-check"></i><b>4.1</b> Resumen estadístico</a>
<ul>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#tendencia-central"><i class="fa fa-check"></i>Tendencia central</a></li>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#dispersión"><i class="fa fa-check"></i>Dispersión</a></li>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#categórica"><i class="fa fa-check"></i>Categórica</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#graficas"><i class="fa fa-check"></i><b>4.2</b> Graficas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#histogramas"><i class="fa fa-check"></i><b>4.2.1</b> Histogramas</a></li>
<li class="chapter" data-level="4.2.2" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#gráfico-de-barras"><i class="fa fa-check"></i><b>4.2.2</b> Gráfico de barras</a></li>
<li class="chapter" data-level="4.2.3" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#diagramas-de-cajas"><i class="fa fa-check"></i><b>4.2.3</b> Diagramas de cajas</a></li>
<li class="chapter" data-level="4.2.4" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#gráfico-de-dispersión"><i class="fa fa-check"></i><b>4.2.4</b> Gráfico de dispersión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html"><i class="fa fa-check"></i><b>5</b> Probabilidad y estadística en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#probabilidad-en-r"><i class="fa fa-check"></i><b>5.1</b> Probabilidad en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#distribuciones"><i class="fa fa-check"></i><b>5.1.1</b> Distribuciones</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#pruebas-de-hipótesis-en-r"><i class="fa fa-check"></i><b>5.2</b> Pruebas de hipótesis en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-una-muestra-revisión"><i class="fa fa-check"></i><b>5.2.1</b> Prueba t de una muestra: revisión</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-una-muestra-ejemplo"><i class="fa fa-check"></i><b>5.2.2</b> Prueba t de una muestra: ejemplo</a></li>
<li class="chapter" data-level="5.2.3" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-dos-muestras-revisión"><i class="fa fa-check"></i><b>5.2.3</b> Prueba t de dos muestras: revisión</a></li>
<li class="chapter" data-level="5.2.4" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-dos-muestras-ejemplo"><i class="fa fa-check"></i><b>5.2.4</b> Prueba t de dos muestras: Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#simulación"><i class="fa fa-check"></i><b>5.3</b> Simulación</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#diferencias-emparejadas"><i class="fa fa-check"></i><b>5.3.1</b> Diferencias emparejadas</a></li>
<li class="chapter" data-level="5.3.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#distribución-de-una-media-muestral"><i class="fa fa-check"></i><b>5.3.2</b> Distribución de una media muestral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="recursos-r.html"><a href="recursos-r.html"><i class="fa fa-check"></i><b>6</b> Recursos <code>R</code></a>
<ul>
<li class="chapter" data-level="6.1" data-path="recursos-r.html"><a href="recursos-r.html#referencias-y-tutoriales-para-principiantes"><i class="fa fa-check"></i><b>6.1</b> Referencias y tutoriales para principiantes</a></li>
<li class="chapter" data-level="6.2" data-path="recursos-r.html"><a href="recursos-r.html#referencias-intermedias"><i class="fa fa-check"></i><b>6.2</b> Referencias intermedias</a></li>
<li class="chapter" data-level="6.3" data-path="recursos-r.html"><a href="recursos-r.html#referencias-avanzadas"><i class="fa fa-check"></i><b>6.3</b> Referencias avanzadas</a></li>
<li class="chapter" data-level="6.4" data-path="recursos-r.html"><a href="recursos-r.html#comparaciones-rápidas-con-otros-lenguajes"><i class="fa fa-check"></i><b>6.4</b> Comparaciones rápidas con otros lenguajes</a></li>
<li class="chapter" data-level="6.5" data-path="recursos-r.html"><a href="recursos-r.html#vídeos-de-rstudio-y-rmarkdown"><i class="fa fa-check"></i><b>6.5</b> Vídeos de RStudio y RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html"><i class="fa fa-check"></i><b>7</b> Regresión lineal simple</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#modelado"><i class="fa fa-check"></i><b>7.1</b> Modelado</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#modelo-de-regresión-lineal-simple"><i class="fa fa-check"></i><b>7.1.1</b> Modelo de regresión lineal simple</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#enfoque-de-mínimos-cuadrados"><i class="fa fa-check"></i><b>7.2</b> Enfoque de mínimos cuadrados</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#haciendo-predicciones"><i class="fa fa-check"></i><b>7.2.1</b> Haciendo predicciones</a></li>
<li class="chapter" data-level="7.2.2" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#residuales"><i class="fa fa-check"></i><b>7.2.2</b> Residuales</a></li>
<li class="chapter" data-level="7.2.3" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#estimación-de-la-varianza"><i class="fa fa-check"></i><b>7.2.3</b> Estimación de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#descomposición-de-variación"><i class="fa fa-check"></i><b>7.3</b> Descomposición de variación</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#coeficiente-de-determinación"><i class="fa fa-check"></i><b>7.3.1</b> Coeficiente de determinación</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#la-función-lm"><i class="fa fa-check"></i><b>7.4</b> La función <code>lm</code></a></li>
<li class="chapter" data-level="7.5" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#enfoque-de-estimación-de-máxima-verosimilitud-mle"><i class="fa fa-check"></i><b>7.5</b> Enfoque de estimación de máxima verosimilitud (MLE)</a></li>
<li class="chapter" data-level="7.6" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#simulando-slr"><i class="fa fa-check"></i><b>7.6</b> Simulando SLR</a></li>
<li class="chapter" data-level="7.7" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#historia"><i class="fa fa-check"></i><b>7.7</b> Historia</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html"><i class="fa fa-check"></i><b>8</b> Inferencia para regresión lineal simple</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#teorema-de-gauss-markov"><i class="fa fa-check"></i><b>8.1</b> Teorema de Gauss-Markov</a></li>
<li class="chapter" data-level="8.2" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#distribuciones-muestrales"><i class="fa fa-check"></i><b>8.2</b> Distribuciones muestrales</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#simular-distribuciones-muestrales"><i class="fa fa-check"></i><b>8.2.1</b> Simular distribuciones muestrales</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#errores-estándar"><i class="fa fa-check"></i><b>8.3</b> Errores estándar</a></li>
<li class="chapter" data-level="8.4" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalos-de-confianza-para-pendiente-e-intercepto"><i class="fa fa-check"></i><b>8.4</b> Intervalos de confianza para pendiente e Intercepto</a></li>
<li class="chapter" data-level="8.5" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>8.5</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="8.6" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#ejemplo-cars"><i class="fa fa-check"></i><b>8.6</b> Ejemplo <code>cars</code></a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#pruebas-en-r"><i class="fa fa-check"></i><b>8.6.1</b> Pruebas en <code>R</code></a></li>
<li class="chapter" data-level="8.6.2" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#significancia-de-la-regresión-prueba-t."><i class="fa fa-check"></i><b>8.6.2</b> Significancia de la regresión, prueba t.</a></li>
<li class="chapter" data-level="8.6.3" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalos-de-confianza-en-r"><i class="fa fa-check"></i><b>8.6.3</b> Intervalos de confianza en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalo-de-confianza-para-la-respuesta-promedio"><i class="fa fa-check"></i><b>8.7</b> Intervalo de confianza para la respuesta Promedio</a></li>
<li class="chapter" data-level="8.8" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalo-de-predicción-para-nuevas-observaciones"><i class="fa fa-check"></i><b>8.8</b> Intervalo de predicción para nuevas observaciones</a></li>
<li class="chapter" data-level="8.9" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#bandas-de-confianza-y-predicción"><i class="fa fa-check"></i><b>8.9</b> Bandas de confianza y predicción</a></li>
<li class="chapter" data-level="8.10" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#significancia-de-la-regresión-prueba-f"><i class="fa fa-check"></i><b>8.10</b> Significancia de la regresión, prueba F</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html"><i class="fa fa-check"></i><b>9</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#enfoque-matricial-para-la-regresión"><i class="fa fa-check"></i><b>9.1</b> Enfoque matricial para la regresión</a></li>
<li class="chapter" data-level="9.2" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#distribución-muestral"><i class="fa fa-check"></i><b>9.2</b> Distribución muestral</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#pruebas-de-un-solo-parámetro"><i class="fa fa-check"></i><b>9.2.1</b> Pruebas de un solo parámetro</a></li>
<li class="chapter" data-level="9.2.2" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>9.2.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="9.2.3" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-confianza-para-la-respuesta-media"><i class="fa fa-check"></i><b>9.2.3</b> Intervalos de confianza para la respuesta media</a></li>
<li class="chapter" data-level="9.2.4" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-predicción"><i class="fa fa-check"></i><b>9.2.4</b> Intervalos de predicción</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#significancia-de-la-regresión"><i class="fa fa-check"></i><b>9.3</b> Significancia de la regresión</a></li>
<li class="chapter" data-level="9.4" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#modelos-anidados"><i class="fa fa-check"></i><b>9.4</b> Modelos anidados</a></li>
<li class="chapter" data-level="9.5" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#simulación-1"><i class="fa fa-check"></i><b>9.5</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html"><i class="fa fa-check"></i><b>10</b> Construcción del modelo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#familia-forma-y-ajuste."><i class="fa fa-check"></i><b>10.1</b> Familia, forma, y ajuste.</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#ajuste."><i class="fa fa-check"></i><b>10.1.1</b> Ajuste.</a></li>
<li class="chapter" data-level="10.1.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#forma"><i class="fa fa-check"></i><b>10.1.2</b> Forma</a></li>
<li class="chapter" data-level="10.1.3" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#familia"><i class="fa fa-check"></i><b>10.1.3</b> Familia</a></li>
<li class="chapter" data-level="10.1.4" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#modelo-asumido-modelo-ajustado"><i class="fa fa-check"></i><b>10.1.4</b> Modelo asumido, modelo ajustado</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#explicación-versus-predicción"><i class="fa fa-check"></i><b>10.2</b> Explicación versus predicción</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#explicación"><i class="fa fa-check"></i><b>10.2.1</b> Explicación</a></li>
<li class="chapter" data-level="10.2.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#predicción"><i class="fa fa-check"></i><b>10.2.2</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#resumen"><i class="fa fa-check"></i><b>10.3</b> Resumen</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html"><i class="fa fa-check"></i><b>11</b> Interacciones y predictores categóricos</a>
<ul>
<li class="chapter" data-level="11.1" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#variables-ficticias-dummy"><i class="fa fa-check"></i><b>11.1</b> Variables ficticias (Dummy)</a></li>
<li class="chapter" data-level="11.2" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#interacciones"><i class="fa fa-check"></i><b>11.2</b> Interacciones</a></li>
<li class="chapter" data-level="11.3" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#variables-factor"><i class="fa fa-check"></i><b>11.3</b> Variables factor</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#factores-con-más-de-dos-niveles"><i class="fa fa-check"></i><b>11.3.1</b> Factores con más de dos niveles</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#parametrización"><i class="fa fa-check"></i><b>11.4</b> Parametrización</a></li>
<li class="chapter" data-level="11.5" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#construcción-de-modelos-más-grandes"><i class="fa fa-check"></i><b>11.5</b> Construcción de modelos más grandes</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html"><i class="fa fa-check"></i><b>12</b> Análisis de varianza</a>
<ul>
<li class="chapter" data-level="12.1" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#experimentos"><i class="fa fa-check"></i><b>12.1</b> Experimentos</a></li>
<li class="chapter" data-level="12.2" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#prueba-t-de-dos-muestras"><i class="fa fa-check"></i><b>12.2</b> Prueba t de dos muestras</a></li>
<li class="chapter" data-level="12.3" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#anova-de-una-vía"><i class="fa fa-check"></i><b>12.3</b> ANOVA de una vía</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#variables-factor-1"><i class="fa fa-check"></i><b>12.3.1</b> Variables factor</a></li>
<li class="chapter" data-level="12.3.2" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#algo-de-simulación"><i class="fa fa-check"></i><b>12.3.2</b> Algo de simulación</a></li>
<li class="chapter" data-level="12.3.3" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#potencia"><i class="fa fa-check"></i><b>12.3.3</b> Potencia</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#pruebas-post-hoc"><i class="fa fa-check"></i><b>12.4</b> Pruebas Post Hoc</a></li>
<li class="chapter" data-level="12.5" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#anova-de-dos-vías"><i class="fa fa-check"></i><b>12.5</b> ANOVA de dos vías</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html"><i class="fa fa-check"></i><b>13</b> Diagnóstico de modelos</a>
<ul>
<li class="chapter" data-level="13.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#supuestos-del-modelo"><i class="fa fa-check"></i><b>13.1</b> Supuestos del modelo</a></li>
<li class="chapter" data-level="13.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#comprobación-de-supuestos"><i class="fa fa-check"></i><b>13.2</b> Comprobación de supuestos</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#gráfica-de-ajustados-versus-residuos"><i class="fa fa-check"></i><b>13.2.1</b> Gráfica de ajustados versus residuos</a></li>
<li class="chapter" data-level="13.2.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#prueba-de-breusch-pagan"><i class="fa fa-check"></i><b>13.2.2</b> Prueba de Breusch-Pagan</a></li>
<li class="chapter" data-level="13.2.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#histogramas-1"><i class="fa fa-check"></i><b>13.2.3</b> Histogramas</a></li>
<li class="chapter" data-level="13.2.4" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#gráficos-q-q"><i class="fa fa-check"></i><b>13.2.4</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="13.2.5" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#prueba-de-shapiro-wilk"><i class="fa fa-check"></i><b>13.2.5</b> Prueba de Shapiro-Wilk</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#observaciones-inusuales"><i class="fa fa-check"></i><b>13.3</b> Observaciones inusuales</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#apalancamiento"><i class="fa fa-check"></i><b>13.3.1</b> Apalancamiento</a></li>
<li class="chapter" data-level="13.3.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#valores-atípicos"><i class="fa fa-check"></i><b>13.3.2</b> Valores atípicos</a></li>
<li class="chapter" data-level="13.3.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#influencia"><i class="fa fa-check"></i><b>13.3.3</b> Influencia</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#ejemplos-de-análisis-de-datos"><i class="fa fa-check"></i><b>13.4</b> Ejemplos de análisis de datos</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#buenos-diagnósticos"><i class="fa fa-check"></i><b>13.4.1</b> Buenos diagnósticos</a></li>
<li class="chapter" data-level="13.4.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#diagnóstico-sospechoso"><i class="fa fa-check"></i><b>13.4.2</b> Diagnóstico sospechoso</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="transformaciones.html"><a href="transformaciones.html"><i class="fa fa-check"></i><b>14</b> Transformaciones</a>
<ul>
<li class="chapter" data-level="14.1" data-path="transformaciones.html"><a href="transformaciones.html#transformación-de-respuesta"><i class="fa fa-check"></i><b>14.1</b> Transformación de respuesta</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-estabilizadoras-de-varianza"><i class="fa fa-check"></i><b>14.1.1</b> Transformaciones estabilizadoras de varianza</a></li>
<li class="chapter" data-level="14.1.2" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-box-cox"><i class="fa fa-check"></i><b>14.1.2</b> Transformaciones de Box-Cox</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="transformaciones.html"><a href="transformaciones.html#transformación-del-predictor"><i class="fa fa-check"></i><b>14.2</b> Transformación del predictor</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="transformaciones.html"><a href="transformaciones.html#polinomios"><i class="fa fa-check"></i><b>14.2.1</b> Polinomios</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-respuesta"><i class="fa fa-check"></i>Transformaciones de respuesta</a></li>
<li class="chapter" data-level="" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-predictores"><i class="fa fa-check"></i>Transformaciones de predictores</a>
<ul>
<li class="chapter" data-level="14.2.2" data-path="transformaciones.html"><a href="transformaciones.html#un-modelo-cuadrático"><i class="fa fa-check"></i><b>14.2.2</b> Un modelo cuadrático</a></li>
<li class="chapter" data-level="14.2.3" data-path="transformaciones.html"><a href="transformaciones.html#sobreajuste-y-extrapolación"><i class="fa fa-check"></i><b>14.2.3</b> Sobreajuste y extrapolación</a></li>
<li class="chapter" data-level="14.2.4" data-path="transformaciones.html"><a href="transformaciones.html#comparación-de-modelos-polinomiales"><i class="fa fa-check"></i><b>14.2.4</b> Comparación de modelos polinomiales</a></li>
<li class="chapter" data-level="14.2.5" data-path="transformaciones.html"><a href="transformaciones.html#poly-función-y-polinomios-ortogonales"><i class="fa fa-check"></i><b>14.2.5</b> <code>poly()</code> Función y polinomios ortogonales</a></li>
<li class="chapter" data-level="14.2.6" data-path="transformaciones.html"><a href="transformaciones.html#función-de-inhibición"><i class="fa fa-check"></i><b>14.2.6</b> Función de inhibición</a></li>
<li class="chapter" data-level="14.2.7" data-path="transformaciones.html"><a href="transformaciones.html#ejemplo-con-datos"><i class="fa fa-check"></i><b>14.2.7</b> Ejemplo con datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="colinealidad.html"><a href="colinealidad.html"><i class="fa fa-check"></i><b>15</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="15.1" data-path="colinealidad.html"><a href="colinealidad.html#colinealidad-exacta"><i class="fa fa-check"></i><b>15.1</b> Colinealidad exacta</a></li>
<li class="chapter" data-level="15.2" data-path="colinealidad.html"><a href="colinealidad.html#colinealidad-1"><i class="fa fa-check"></i><b>15.2</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="colinealidad.html"><a href="colinealidad.html#factor-de-inflación-de-la-varianza."><i class="fa fa-check"></i><b>15.2.1</b> Factor de inflación de la varianza.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="colinealidad.html"><a href="colinealidad.html#simulación-2"><i class="fa fa-check"></i><b>15.3</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html"><i class="fa fa-check"></i><b>16</b> Selección de variables y construcción de modelos</a>
<ul>
<li class="chapter" data-level="16.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-calidad"><i class="fa fa-check"></i><b>16.1</b> Criterio de calidad</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-información-de-akaike"><i class="fa fa-check"></i><b>16.1.1</b> Criterio de información de Akaike</a></li>
<li class="chapter" data-level="16.1.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-información-bayesiano"><i class="fa fa-check"></i><b>16.1.2</b> Criterio de información Bayesiano</a></li>
<li class="chapter" data-level="16.1.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#r-cuadrado-ajustado"><i class="fa fa-check"></i><b>16.1.3</b> R cuadrado ajustado</a></li>
<li class="chapter" data-level="16.1.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#rmse-con-validación-cruzada"><i class="fa fa-check"></i><b>16.1.4</b> RMSE con validación cruzada</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#procedimientos-de-selección"><i class="fa fa-check"></i><b>16.2</b> Procedimientos de selección</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-hacia-atrás-backward"><i class="fa fa-check"></i><b>16.2.1</b> Búsqueda hacia atrás (Backward)</a></li>
<li class="chapter" data-level="16.2.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-hacia-adelante-forward"><i class="fa fa-check"></i><b>16.2.2</b> Búsqueda hacia adelante (Forward)</a></li>
<li class="chapter" data-level="16.2.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-por-pasos-stepwise"><i class="fa fa-check"></i><b>16.2.3</b> Búsqueda por pasos (Stepwise)</a></li>
<li class="chapter" data-level="16.2.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-exhaustiva"><i class="fa fa-check"></i><b>16.2.4</b> Búsqueda exhaustiva</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#términos-de-orden-superior"><i class="fa fa-check"></i><b>16.3</b> Términos de orden superior</a></li>
<li class="chapter" data-level="16.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#explicación-versus-predicción-1"><i class="fa fa-check"></i><b>16.4</b> Explicación versus predicción</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#explicación-1"><i class="fa fa-check"></i><b>16.4.1</b> Explicación</a></li>
<li class="chapter" data-level="16.4.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#predicción-1"><i class="fa fa-check"></i><b>16.4.2</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>17</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="17.1" data-path="regresión-logística.html"><a href="regresión-logística.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>17.1</b> Modelos lineales generalizados</a></li>
<li class="chapter" data-level="17.2" data-path="regresión-logística.html"><a href="regresión-logística.html#respuesta-binaria"><i class="fa fa-check"></i><b>17.2</b> Respuesta binaria</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="regresión-logística.html"><a href="regresión-logística.html#ajuste-de-la-regresión-logística"><i class="fa fa-check"></i><b>17.2.1</b> Ajuste de la regresión logística</a></li>
<li class="chapter" data-level="17.2.2" data-path="regresión-logística.html"><a href="regresión-logística.html#problemas-de-ajuste"><i class="fa fa-check"></i><b>17.2.2</b> Problemas de ajuste</a></li>
<li class="chapter" data-level="17.2.3" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplos-de-simulación"><i class="fa fa-check"></i><b>17.2.3</b> Ejemplos de simulación</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="regresión-logística.html"><a href="regresión-logística.html#trabajar-con-regresión-logística"><i class="fa fa-check"></i><b>17.3</b> Trabajar con regresión logística</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="regresión-logística.html"><a href="regresión-logística.html#pruebas-con-glms"><i class="fa fa-check"></i><b>17.3.1</b> Pruebas con GLMs</a></li>
<li class="chapter" data-level="17.3.2" data-path="regresión-logística.html"><a href="regresión-logística.html#prueba-de-wald"><i class="fa fa-check"></i><b>17.3.2</b> Prueba de Wald</a></li>
<li class="chapter" data-level="17.3.3" data-path="regresión-logística.html"><a href="regresión-logística.html#prueba-de-razón-de-verosimilitud"><i class="fa fa-check"></i><b>17.3.3</b> Prueba de razón de verosimilitud</a></li>
<li class="chapter" data-level="17.3.4" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-saheart"><i class="fa fa-check"></i><b>17.3.4</b> Ejemplo <code>SAheart</code></a></li>
<li class="chapter" data-level="17.3.5" data-path="regresión-logística.html"><a href="regresión-logística.html#intervalos-de-confianza-1"><i class="fa fa-check"></i><b>17.3.5</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="17.3.6" data-path="regresión-logística.html"><a href="regresión-logística.html#intervalos-de-confianza-para-la-respuesta-promedio"><i class="fa fa-check"></i><b>17.3.6</b> Intervalos de confianza para la respuesta promedio</a></li>
<li class="chapter" data-level="17.3.7" data-path="regresión-logística.html"><a href="regresión-logística.html#sintaxis-de-la-fórmula"><i class="fa fa-check"></i><b>17.3.7</b> Sintaxis de la fórmula</a></li>
<li class="chapter" data-level="17.3.8" data-path="regresión-logística.html"><a href="regresión-logística.html#desviación"><i class="fa fa-check"></i><b>17.3.8</b> Desviación</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="regresión-logística.html"><a href="regresión-logística.html#clasificación"><i class="fa fa-check"></i><b>17.4</b> Clasificación</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-spam"><i class="fa fa-check"></i><b>17.4.1</b> Ejemplo <code>spam</code></a></li>
<li class="chapter" data-level="17.4.2" data-path="regresión-logística.html"><a href="regresión-logística.html#evaluar-clasificadores"><i class="fa fa-check"></i><b>17.4.2</b> Evaluar clasificadores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="más-allá.html"><a href="más-allá.html"><i class="fa fa-check"></i><b>18</b> Más allá</a>
<ul>
<li class="chapter" data-level="18.1" data-path="más-allá.html"><a href="más-allá.html#rstudio"><i class="fa fa-check"></i><b>18.1</b> RStudio</a></li>
<li class="chapter" data-level="18.2" data-path="más-allá.html"><a href="más-allá.html#tidy-data"><i class="fa fa-check"></i><b>18.2</b> Tidy Data</a></li>
<li class="chapter" data-level="18.3" data-path="más-allá.html"><a href="más-allá.html#visualización"><i class="fa fa-check"></i><b>18.3</b> Visualización</a></li>
<li class="chapter" data-level="18.4" data-path="más-allá.html"><a href="más-allá.html#aplicaciones-web"><i class="fa fa-check"></i><b>18.4</b> Aplicaciones web</a></li>
<li class="chapter" data-level="18.5" data-path="más-allá.html"><a href="más-allá.html#diseño-experimental"><i class="fa fa-check"></i><b>18.5</b> Diseño experimental</a></li>
<li class="chapter" data-level="18.6" data-path="más-allá.html"><a href="más-allá.html#aprendizaje-automático-machine-learning"><i class="fa fa-check"></i><b>18.6</b> Aprendizaje automático (Machine Learning)</a>
<ul>
<li class="chapter" data-level="18.6.1" data-path="más-allá.html"><a href="más-allá.html#aprendizaje-profundo-deep-learning"><i class="fa fa-check"></i><b>18.6.1</b> Aprendizaje profundo (Deep Learning)</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="más-allá.html"><a href="más-allá.html#series-de-tiempo"><i class="fa fa-check"></i><b>18.7</b> Series de tiempo</a></li>
<li class="chapter" data-level="18.8" data-path="más-allá.html"><a href="más-allá.html#bayesiana"><i class="fa fa-check"></i><b>18.8</b> Bayesiana</a></li>
<li class="chapter" data-level="18.9" data-path="más-allá.html"><a href="más-allá.html#computación-de-alto-rendimiento."><i class="fa fa-check"></i><b>18.9</b> Computación de alto rendimiento.</a></li>
<li class="chapter" data-level="18.10" data-path="más-allá.html"><a href="más-allá.html#recursos-adicionales-de-r"><i class="fa fa-check"></i><b>18.10</b> Recursos adicionales de <code>R</code></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/appliedstats" target="blank">&copy; 2020 Adapatado de David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística aplicada con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regresión-lineal-múltiple" class="section level1" number="9">
<h1><span class="header-section-number">Capítulo 9</span> Regresión lineal múltiple</h1>
<blockquote>
<p>“La vida es realmente simple, pero insistimos en complicarla.”</p>
<p>— <strong>Confucio</strong></p>
</blockquote>
<p>Después de leer este capítulo, podrá:</p>
<ul>
<li>Construir e interpretar modelos de regresión lineal con más de un predictor.</li>
<li>Comprender cómo se obtienen los modelos de regresión mediante matrices.</li>
<li>Crear estimaciones de intervalos y realizar pruebas de hipótesis para múltiples parámetros de regresión.</li>
<li>Formular e interpretar estimaciones de intervalos para la respuesta media en diversas condiciones.</li>
<li>Comparar modelos anidados usando una prueba F ANOVA.</li>
</ul>
<p>Los dos últimos capítulos vimos cómo ajustar un modelo que asumía una relación lineal entre una variable de respuesta y una única variable predictora. Específicamente, definimos el modelo de regresión lineal simple,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]</span></p>
<p>donde <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>.</p>
<p>Sin embargo, rara vez se da el caso de que un conjunto de datos tenga una única variable predictora. También es raro el caso de que una variable respuesta solo dependa de una sola variable. Entonces, en este capítulo, ampliaremos nuestro modelo lineal actual para permitir que una respuesta dependa de <em>múltiples</em> predictores.</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="regresión-lineal-múltiple.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="co"># leer los datos de la web</span></span>
<span id="cb581-2"><a href="regresión-lineal-múltiple.html#cb581-2" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">read.table</span>(</span>
<span id="cb581-3"><a href="regresión-lineal-múltiple.html#cb581-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data&quot;</span>,</span>
<span id="cb581-4"><a href="regresión-lineal-múltiple.html#cb581-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">quote =</span> <span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span>,</span>
<span id="cb581-5"><a href="regresión-lineal-múltiple.html#cb581-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">comment.char =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb581-6"><a href="regresión-lineal-múltiple.html#cb581-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb581-7"><a href="regresión-lineal-múltiple.html#cb581-7" aria-hidden="true" tabindex="-1"></a><span class="co"># dar los encabezados del marco de datos</span></span>
<span id="cb581-8"><a href="regresión-lineal-múltiple.html#cb581-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(autompg) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;mpg&quot;</span>, <span class="st">&quot;cyl&quot;</span>, <span class="st">&quot;disp&quot;</span>, <span class="st">&quot;hp&quot;</span>, <span class="st">&quot;wt&quot;</span>, <span class="st">&quot;acc&quot;</span>, <span class="st">&quot;year&quot;</span>, <span class="st">&quot;origin&quot;</span>, <span class="st">&quot;name&quot;</span>)</span>
<span id="cb581-9"><a href="regresión-lineal-múltiple.html#cb581-9" aria-hidden="true" tabindex="-1"></a><span class="co"># eliminar los datos que faltan, que se almacenan como &quot;?&quot;</span></span>
<span id="cb581-10"><a href="regresión-lineal-múltiple.html#cb581-10" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, autompg<span class="sc">$</span>hp <span class="sc">!=</span> <span class="st">&quot;?&quot;</span>)</span>
<span id="cb581-11"><a href="regresión-lineal-múltiple.html#cb581-11" aria-hidden="true" tabindex="-1"></a><span class="co"># eliminar el plymouth dependiente, ya que causa algunos problemas</span></span>
<span id="cb581-12"><a href="regresión-lineal-múltiple.html#cb581-12" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, autompg<span class="sc">$</span>name <span class="sc">!=</span> <span class="st">&quot;plymouth reliant&quot;</span>)</span>
<span id="cb581-13"><a href="regresión-lineal-múltiple.html#cb581-13" aria-hidden="true" tabindex="-1"></a><span class="co"># dar los nombres de las filas del conjunto de datos, según el motor, el año y el nombre</span></span>
<span id="cb581-14"><a href="regresión-lineal-múltiple.html#cb581-14" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(autompg) <span class="ot">=</span> <span class="fu">paste</span>(autompg<span class="sc">$</span>cyl, <span class="st">&quot;cylinder&quot;</span>, autompg<span class="sc">$</span>year, autompg<span class="sc">$</span>name)</span>
<span id="cb581-15"><a href="regresión-lineal-múltiple.html#cb581-15" aria-hidden="true" tabindex="-1"></a><span class="co"># eliminar la variable para el nombre, así como el origen</span></span>
<span id="cb581-16"><a href="regresión-lineal-múltiple.html#cb581-16" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">&quot;mpg&quot;</span>, <span class="st">&quot;cyl&quot;</span>, <span class="st">&quot;disp&quot;</span>, <span class="st">&quot;hp&quot;</span>, <span class="st">&quot;wt&quot;</span>, <span class="st">&quot;acc&quot;</span>, <span class="st">&quot;year&quot;</span>))</span>
<span id="cb581-17"><a href="regresión-lineal-múltiple.html#cb581-17" aria-hidden="true" tabindex="-1"></a><span class="co"># cambiar caballos de fuerza de carácter a numérico</span></span>
<span id="cb581-18"><a href="regresión-lineal-múltiple.html#cb581-18" aria-hidden="true" tabindex="-1"></a>autompg<span class="sc">$</span>hp <span class="ot">=</span> <span class="fu">as.numeric</span>(autompg<span class="sc">$</span>hp)</span>
<span id="cb581-19"><a href="regresión-lineal-múltiple.html#cb581-19" aria-hidden="true" tabindex="-1"></a><span class="co"># comprobar la estructura final de los datos</span></span>
<span id="cb581-20"><a href="regresión-lineal-múltiple.html#cb581-20" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(autompg)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    390 obs. of  7 variables:
##  $ mpg : num  18 15 18 16 17 15 14 14 14 15 ...
##  $ cyl : int  8 8 8 8 8 8 8 8 8 8 ...
##  $ disp: num  307 350 318 304 302 429 454 440 455 390 ...
##  $ hp  : num  130 165 150 150 140 198 220 215 225 190 ...
##  $ wt  : num  3504 3693 3436 3433 3449 ...
##  $ acc : num  12 11.5 11 12 10.5 10 9 8.5 10 8.5 ...
##  $ year: int  70 70 70 70 70 70 70 70 70 70 ...</code></pre>
<p>Una vez más, discutiremos un conjunto de datos con información sobre automóviles. <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data" target="_blank">Este conjunto de datos</a>, que se puede encontrar en el <a href="https://archive.ics.uci.edu/ml/datasets/Auto+MPG" target="_blank">UCI Machine Learning Repository</a> contiene una variable de respuesta <code>mpg</code> que almacena la eficiencia de combustible de los automóviles en la ciudad, así como varias variables predictoras para los atributos de los vehículos. Cargamos los datos y realizamos algunos arreglos básicos antes de pasar al análisis.</p>
<p>Por ahora nos centraremos en el uso de dos variables, <code>wt</code> y<code>year</code>, como variables predictoras. Es decir, nos gustaría modelar la eficiencia de combustible (<code>mpg</code>) de un automóvil en función de su peso (<code>wt</code>) y el año del modelo (<code>year</code>). Para ello, definiremos el siguiente modelo lineal,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]</span></p>
<p>donde <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>. En esta notación definiremos:</p>
<ul>
<li><span class="math inline">\(x_{i1}\)</span> como el peso (<code>wt</code>) de el <span class="math inline">\(i\)</span>-esimo carro.</li>
<li><span class="math inline">\(x_{i2}\)</span> como el año del modelo (<code>year</code>) de el <span class="math inline">\(i\)</span>-esimo carro.</li>
</ul>
<p>En la siguiente imagen se visualizará lo que nos gustaría lograr. Los puntos de datos $(x_{i1},x_{i2}, y_i) $ ahora existen en un espacio tridimensional, por lo que en lugar de ajustar una línea a los datos, ajustaremos un plano. (Pronto pasaremos a dimensiones más altas, por lo que este será el último ejemplo que sea fácil de visualizar y pensar de esta manera).</p>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-244-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>¿Cómo encontramos un plano así?, bueno, nos gustaría un plano que esté lo más cerca posible de los puntos de datos. Es decir, nos gustaría que minimizara los errores que está cometiendo. ¿Cómo definiremos estos errores? ¡Distancia al cuadrado, por supuesto! Entonces, nos gustaría minimizar</p>
<p><span class="math display">\[
f(\beta_0, \beta_1, \beta_2) = \sum_{i = 1}^{n}(y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}))^2
\]</span></p>
<p>con respecto a <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span>. ¿Cómo lo hacemos? Es otro problema sencillo de cálculo multivariado. Todo lo que hemos hecho es agregar una variable extra desde que hicimos esto la última vez. Entonces, nuevamente, derivamos con respecto a cada uno de los <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\ beta_2\)</span> y los igualamos a cero, luego resolvemos el sistema de ecuaciones resultante. Es decir,</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial f}{\partial \beta_0} &amp;= 0 \\
\frac{\partial f}{\partial \beta_1} &amp;= 0 \\
\frac{\partial f}{\partial \beta_2} &amp;= 0
\end{aligned}
\]</span></p>
<p>Una vez hecho esto, volveremos a obtener las <strong>ecuaciones normales.</strong></p>
<p><span class="math display">\[
\begin{aligned}
n \beta_0 + \beta_1 \sum_{i = 1}^{n} x_{i1} + \beta_2 \sum_{i = 1}^{n} x_{i2} &amp;= \sum_{i = 1}^{n} y_i  \\
\beta_0 \sum_{i = 1}^{n} x_{i1} + \beta_1 \sum_{i = 1}^{n} x_{i1}^2 + \beta_2 \sum_{i = 1}^{n} x_{i1}x_{i2} &amp;= \sum_{i = 1}^{n} x_{i1}y_i \\
\beta_0 \sum_{i = 1}^{n} x_{i2} + \beta_1 \sum_{i = 1}^{n} x_{i1}x_{i2} + \beta_2 \sum_{i = 1}^{n} x_{i2}^2 &amp;= \sum_{i = 1}^{n} x_{i2}y_i
\end{aligned}
\]</span></p>
<p>Ahora tenemos tres ecuaciones y tres variables, que podríamos resolver, o simplemente dejar que <code>R</code> resuelva por nosotros.</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="regresión-lineal-múltiple.html#cb583-1" aria-hidden="true" tabindex="-1"></a>mpg_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> year, <span class="at">data =</span> autompg)</span>
<span id="cb583-2"><a href="regresión-lineal-múltiple.html#cb583-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mpg_model)</span></code></pre></div>
<pre><code>##   (Intercept)            wt          year 
## -14.637641945  -0.006634876   0.761401955</code></pre>
<p><span class="math display">\[
\hat{y} = -14.6376419 + -0.0066349 x_1 + 0.761402 x_2
\]</span></p>
<p>Aquí hemos vuelto a ajustar nuestro modelo usando <code>lm()</code>, sin embargo, hemos introducido un nuevo elemento sintáctico. La fórmula <code>mpg ~ wt + year</code> ahora dice: “modela la variable de respuesta <code>mpg</code> como una función lineal de <code>wt</code> y <code>year</code>”. Es decir, estimará una intersección, así como los coeficientes de la pendiente para <code>wt</code> y<code>year</code>. Luego los extraemos como lo hicimos antes de usar <code>coef()</code>.</p>
<p>En la configuración de regresión lineal múltiple, algunas de las interpretaciones de los coeficientes cambian ligeramente.</p>
<p>Aquí, <span class="math inline">\(\hat{\beta}_0 = -14.6376419\)</span> es nuestra estimación de <span class="math inline">\(\beta_0\)</span>, la media de millas por galón de un automóvil que pesa 0 libras y fue construido en 1900. Vea que nuestra estimación aquí es negativa, lo cual es una imposibilidad física. Sin embargo, esto no es inesperado, ya que no deberíamos esperar que nuestro modelo sea preciso para autos de 1900 que pesan 0 libras. (¡Porque nunca existieron!) Este no es un gran cambio con respecto a SLR. Es decir, <span class="math inline">\(\beta_0\)</span> sigue siendo simplemente la media cuando todos los predictores son 0.</p>
<p>La interpretación de los coeficientes frente a nuestros predictores es ligeramente diferente al anterior. Por ejemplo, <span class="math inline">\(\hat{\beta}_1 = -0.0066349\)</span> es nuestra estimación de <span class="math inline">\(\beta_1\)</span>, el cambio promedio en millas por galón para un aumento de peso (<span class="math inline">\(x_{1}\)</span> ) de una libra <strong>para un automóvil de un determinado año de modelo</strong>, es decir, por un valor fijo de <span class="math inline">\(x_{2}\)</span>. Tenga en cuenta que este coeficiente es en realidad el mismo para cualquier valor dado de <span class="math inline">\(x_{2}\)</span>. Más adelante, veremos modelos que permiten un cambio diferente en la respuesta media para diferentes valores de <span class="math inline">\(x_{2}\)</span>. También tenga en cuenta que esta estimación es negativa, lo que esperaríamos ya que, en general, la eficiencia del combustible disminuye para los vehículos más grandes. Recuerde que en la configuración de regresión lineal múltiple, esta interpretación depende de un valor fijo para <span class="math inline">\(x_{2}\)</span>, es decir, “para un automóvil de un determinado año de modelo”. Es posible que la relación indirecta entre la eficiencia del combustible y el peso no se mantenga cuando se incluye un factor adicional, digamos un año, y por lo tanto podríamos tener el signo de nuestro coeficiente invertido.</p>
<p>Por último, <span class="math inline">\(\hat{\beta}_2 = 0.761402\)</span> es nuestra estimación de <span class="math inline">\(\beta_2\)</span>, el cambio promedio en millas por galón para un aumento de un año en el año modelo (<span class="math inline">\(x_{2}\)</span>) por un automóvil de cierto peso, es decir, por un valor fijo de <span class="math inline">\(x_{1}\)</span>. No es de extrañar que la estimación sea positiva. Esperamos que a medida que pase el tiempo y los años, la tecnología mejore para que un automóvil de un peso específico obtenga un mejor kilometraje ahora en comparación con sus predecesores. Y, sin embargo, el coeficiente podría haber sido negativo porque también incluimos el peso como variable, y no estrictamente como un valor fijo.</p>
<div id="enfoque-matricial-para-la-regresión" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Enfoque matricial para la regresión</h2>
<p>En nuestro ejemplo anterior, usamos dos variables predictoras, pero solo se necesitará un poco más de trabajo para permitir un número arbitrario de variables predictoras y derivar sus estimaciones de coeficientes. Podemos considerar el modelo,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]</span></p>
<p>donde <span class="math inline">\(\epsilon_i\sim N(0,\sigma^2)\)</span>. En este modelo, hay <span class="math inline">\(p - 1\)</span> variables predictoras, <span class="math inline">\(x_1,x_2,\cdots, x_{p-1}\)</span>. Hay un total de <span class="math inline">\(p\)</span> <span class="math inline">\(\beta\)</span> -parámetros y un solo parámetro <span class="math inline">\(\sigma^2\)</span> para la varianza de los errores. (Cabe señalar que casi con la misma frecuencia, los autores usarán <span class="math inline">\(p\)</span> como el número de predictores, lo que hace que el número total de <span class="math inline">\(\beta\)</span> parámetros <span class="math inline">\(p+1\)</span>. Esto siempre es algo que debe tener en cuenta al leer sobre regresión múltiple. No existe un estándar que se utilice con más frecuencia).</p>
<p>Si tuviéramos que apilar las ecuaciones lineales <span class="math inline">\(n\)</span> que representan cada <span class="math inline">\(Y_i\)</span> en un vector de columna, obtenemos lo siguiente.</p>
<p><span class="math display">\[
\begin{bmatrix}
Y_1   \\
Y_2   \\
\vdots\\
Y_n   \\
\end{bmatrix}
=
\begin{bmatrix}
1      &amp; x_{11}    &amp; x_{12}    &amp; \cdots &amp; x_{1(p-1)} \\
1      &amp; x_{21}    &amp; x_{22}    &amp; \cdots &amp; x_{2(p-1)} \\
\vdots &amp; \vdots    &amp; \vdots    &amp;  &amp; \vdots \\
1      &amp; x_{n1}    &amp; x_{n2}    &amp; \cdots &amp; x_{n(p-1)} \\
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_{p-1} \\
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1   \\
\epsilon_2   \\
\vdots\\
\epsilon_n   \\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
Y = X \beta + \epsilon
\]</span></p>
<p><span class="math display">\[
Y = \begin{bmatrix} Y_1 \\ Y_2 \\ \vdots\\ Y_n \end{bmatrix}, \quad
X = \begin{bmatrix}
1      &amp; x_{11}    &amp; x_{12}    &amp; \cdots &amp; x_{1(p-1)} \\
1      &amp; x_{21}    &amp; x_{22}    &amp; \cdots &amp; x_{2(p-1)} \\
\vdots &amp; \vdots    &amp; \vdots    &amp;  &amp; \vdots \\
1      &amp; x_{n1}    &amp; x_{n2}    &amp; \cdots &amp; x_{n(p-1)} \\
\end{bmatrix}, \quad
\beta = \begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_{p-1} \\
\end{bmatrix}, \quad
\epsilon = \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \vdots\\ \epsilon_n \end{bmatrix}
\]</span></p>
<p>Así que ahora con los datos</p>
<p><span class="math display">\[
y = \begin{bmatrix} y_1 \\ y_2 \\ \vdots\\ y_n \end{bmatrix}
\]</span></p>
<p>Al igual que antes, podemos estimar <span class="math inline">\(\beta\)</span> minimizando,</p>
<p><span class="math display">\[
f(\beta_0, \beta_1, \beta_2, \cdots, \beta_{p-1}) = \sum_{i = 1}^{n}(y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)}))^2,
\]</span></p>
<p>que requeriría tomar <span class="math inline">\(p\)</span> derivadas, que dan como resultado las siguientes <strong>ecuaciones normales</strong>.</p>
<p><span class="math display">\[
\begin{bmatrix}
n                           &amp; \sum_{i = 1}^{n} x_{i1}           &amp; \sum_{i = 1}^{n} x_{i2}           &amp; \cdots &amp; \sum_{i = 1}^{n} x_{i(p-1)}       \\
\sum_{i = 1}^{n} x_{i1}     &amp; \sum_{i = 1}^{n} x_{i1}^2         &amp; \sum_{i = 1}^{n} x_{i1}x_{i2}     &amp; \cdots &amp; \sum_{i = 1}^{n} x_{i1}x_{i(p-1)} \\
\vdots                      &amp; \vdots                            &amp; \vdots                            &amp;        &amp; \vdots                            \\
\sum_{i = 1}^{n} x_{i(p-1)} &amp; \sum_{i = 1}^{n} x_{i(p-1)}x_{i1} &amp; \sum_{i = 1}^{n} x_{i(p-1)}x_{i2} &amp; \cdots &amp; \sum_{i = 1}^{n} x_{i(p-1)}^2     \\
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_{p-1} \\
\end{bmatrix}
=
\begin{bmatrix}
\sum_{i = 1}^{n} y_i \\
\sum_{i = 1}^{n} x_{i1}y_i \\
\vdots \\
\sum_{i = 1}^{n} x_{i(p-1)}y_i \\
\end{bmatrix}
\]</span></p>
<p>Las ecuaciones normales se pueden escribir mucho más resumidas en notación matricial,</p>
<p><span class="math display">\[
X^\top X \beta = X^\top y.
\]</span></p>
<p>Entonces podemos resolver esta expresión multiplicando ambos lados por el inverso de <span class="math inline">\(X^\top X\)</span>, que existe, siempre que las columnas de <span class="math inline">\(X\)</span> sean linealmente independientes. Entonces, como siempre, denotamos nuestra solución con un sombrero.</p>
<p><span class="math display">\[
\hat{\beta} = \left(  X^\top X  \right)^{-1}X^\top y
\]</span></p>
<p>Para verificar que esto es lo que <code>R</code> ha hecho por nosotros en el caso de dos predictores, creamos una matriz <span class="math inline">\(X\)</span>. Tenga en cuenta que la primera columna son todos 1 y las columnas restantes contienen los datos.</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="regresión-lineal-múltiple.html#cb585-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">nrow</span>(autompg)</span>
<span id="cb585-2"><a href="regresión-lineal-múltiple.html#cb585-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">coef</span>(mpg_model))</span>
<span id="cb585-3"><a href="regresión-lineal-múltiple.html#cb585-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), autompg<span class="sc">$</span>wt, autompg<span class="sc">$</span>year)</span>
<span id="cb585-4"><a href="regresión-lineal-múltiple.html#cb585-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> autompg<span class="sc">$</span>mpg</span>
<span id="cb585-5"><a href="regresión-lineal-múltiple.html#cb585-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb585-6"><a href="regresión-lineal-múltiple.html#cb585-6" aria-hidden="true" tabindex="-1"></a>(<span class="at">beta_hat =</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y)</span></code></pre></div>
<pre><code>##               [,1]
## [1,] -14.637641945
## [2,]  -0.006634876
## [3,]   0.761401955</code></pre>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="regresión-lineal-múltiple.html#cb587-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mpg_model)</span></code></pre></div>
<pre><code>##   (Intercept)            wt          year 
## -14.637641945  -0.006634876   0.761401955</code></pre>
<p><span class="math display">\[
\hat{\beta} = \begin{bmatrix}
-14.6376419    \\
-0.0066349    \\
0.761402    \\
\end{bmatrix}
\]</span></p>
<p>En nuestra nueva notación, los valores ajustados se pueden escribir</p>
<p><span class="math display">\[
\hat{y} = X \hat{\beta}.
\]</span></p>
<p><span class="math display">\[
\hat{y} = \begin{bmatrix} \hat{y}_1 \\ \hat{y}_2 \\ \vdots\\ \hat{y}_n \end{bmatrix}
\]</span></p>
<p>Luego, podemos crear un vector para los valores residuales,</p>
<p><span class="math display">\[
e 
= \begin{bmatrix} e_1 \\ e_2 \\ \vdots\\ e_n \end{bmatrix} 
= \begin{bmatrix} y_1 \\ y_2 \\ \vdots\\ y_n \end{bmatrix} - \begin{bmatrix} \hat{y}_1 \\ \hat{y}_2 \\ \vdots\\ \hat{y}_n \end{bmatrix}.
\]</span></p>
<p>Y, por último, podemos actualizar nuestra estimación de $ ^2$.</p>
<p><span class="math display">\[
s_e^2 = \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n - p} = \frac{e^\top e}{n-p}
\]</span></p>
<p>Recuerde, nos gusta esta estimación porque no tiene sesgo, es decir,</p>
<p><span class="math display">\[
\text{E}[s_e^2] = \sigma^2
\]</span></p>
<p>Tenga en cuenta que el cambio desde la estimación SLR hasta ahora está en el denominador. Específicamente ahora dividimos por <span class="math inline">\(n-p\)</span> en lugar de <span class="math inline">\(n-2\)</span>. O en realidad, deberíamos tener en cuenta que en el caso de SLR, hay dos parámetros <span class="math inline">\(\beta\)</span> y, por tanto, <span class="math inline">\(p = 2\)</span>.</p>
<p>También tenga en cuenta que si nos ajustamos al modelo <span class="math inline">\(Y_i = \beta + \epsilon_i\)</span> que <span class="math inline">\(\hat{y} = \bar{y}\)</span>, <span class="math inline">\(p = 1\)</span> y <span class="math inline">\(s_e^2\)</span> se convertiría</p>
<p><span class="math display">\[
s_e^2 = \frac{\sum_{i=1}^n (y_i - \bar{y})^2}{n - 1}
\]</span></p>
<p>que es probablemente la primera desviación estándar muestral que vio en una clase de estadística matemática. La misma razón para <span class="math inline">\(n - 1\)</span> en este caso, que estimamos un parámetro, por lo que perdemos un grado de libertad. Ahora, en general, estamos estimando los parámetros <span class="math inline">\(p\)</span>, los parámetros <span class="math inline">\(\beta\)</span>, por lo que perdemos <span class="math inline">\(p\)</span> grados de libertad.</p>
<p>Además, recuerde que la mayoría de las veces nos interesará <span class="math inline">\(s_e\)</span>, el error estándar residual como lo llama <code>R</code>,</p>
<p><span class="math display">\[
s_e = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n - p}}.
\]</span></p>
<p>En <code>R</code>, podríamos acceder directamente a <span class="math inline">\(s_e\)</span> para un modelo ajustado, como hemos visto antes.</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="regresión-lineal-múltiple.html#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 3.431367</code></pre>
<p>Y ahora podemos verificar que nuestra matemática anterior está calculando las mismas cantidades.</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="regresión-lineal-múltiple.html#cb591-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">=</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y</span>
<span id="cb591-2"><a href="regresión-lineal-múltiple.html#cb591-2" aria-hidden="true" tabindex="-1"></a>e     <span class="ot">=</span> y <span class="sc">-</span> y_hat</span>
<span id="cb591-3"><a href="regresión-lineal-múltiple.html#cb591-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">t</span>(e) <span class="sc">%*%</span> e <span class="sc">/</span> (n <span class="sc">-</span> p))</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 3.431367</code></pre>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="regresión-lineal-múltiple.html#cb593-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">sum</span>((y <span class="sc">-</span> y_hat) <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> p))</span></code></pre></div>
<pre><code>## [1] 3.431367</code></pre>
</div>
<div id="distribución-muestral" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Distribución muestral</h2>
<p>Como podemos ver a continuación, los resultados de llamar a <code>summary ()</code> son similares a SLR, pero hay algunas diferencias, la más obvia es una nueva fila para la variable predictora agregada.</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="regresión-lineal-múltiple.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + year, data = autompg)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.852 -2.292 -0.100  2.039 14.325 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.464e+01  4.023e+00  -3.638 0.000312 ***
## wt          -6.635e-03  2.149e-04 -30.881  &lt; 2e-16 ***
## year         7.614e-01  4.973e-02  15.312  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.431 on 387 degrees of freedom
## Multiple R-squared:  0.8082, Adjusted R-squared:  0.8072 
## F-statistic: 815.6 on 2 and 387 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Para comprender estas diferencias en detalle, primero necesitaremos obtener la distribución muestral de <span class="math inline">\(\hat{\beta}\)</span>.</p>
<p>La derivación de la distribución muestral de <span class="math inline">\(\hat{\beta}\)</span> implica la distribución normal multivariante.</p>
<p>Nuestro objetivo ahora es obtener la distribución del vector <span class="math inline">\(\hat{\beta}\)</span>,</p>
<p><span class="math display">\[
\hat{\beta} = \begin{bmatrix}
\hat{\beta}_0 \\
\hat{\beta}_1 \\
\hat{\beta}_2 \\
\vdots \\
\hat{\beta}_{p-1} \end{bmatrix}
\]</span></p>
<p>Recuerde de la última vez que cuando hablamos de distribuciones muestrales, ahora consideramos que <span class="math inline">\(\hat{\beta}\)</span> es un vector aleatorio, por lo que usamos <span class="math inline">\(Y\)</span> en lugar del vector de datos <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[
\hat{\beta} = \left(  X^\top X  \right)^{-1}X^\top Y
\]</span></p>
<p>Entonces es una consecuencia de la distribución normal multivariante que,</p>
<p><span class="math display">\[
\hat{\beta} \sim N\left(\beta, \sigma^2 \left(X^\top X\right)^{-1}  \right).
\]</span></p>
<p>Entonces tenemos</p>
<p><span class="math display">\[
\text{E}[\hat{\beta}] = \beta
\]</span></p>
<p>y para cualquier <span class="math inline">\(\hat{\beta}_j\)</span> tenemos</p>
<p><span class="math display">\[
\text{E}[\hat{\beta}_j] = \beta_j.
\]</span></p>
<p>Tambien tenemos</p>
<p><span class="math display">\[
\text{Var}[\hat{\beta}] = \sigma^2 \left(  X^\top X  \right)^{-1}
\]</span></p>
<p>y para cualquier <span class="math inline">\(\hat{\beta}_j\)</span> tenemos</p>
<p><span class="math display">\[
\text{Var}[\hat{\beta}_j] = \sigma^2 C_{jj}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
C = \left(X^\top X\right)^{-1}
\]</span></p>
<p>y los elementos de <span class="math inline">\(C\)</span> se denotan</p>
<p><span class="math display">\[
C = \begin{bmatrix}
C_{00}     &amp; C_{01}     &amp; C_{02}     &amp; \cdots &amp; C_{0(p-1)}     \\
C_{10}     &amp; C_{11}     &amp; C_{12}     &amp; \cdots &amp; C_{1(p-1)}     \\
C_{20}     &amp; C_{21}     &amp; C_{22}     &amp; \cdots &amp; C_{2(p-1)}     \\
\vdots     &amp; \vdots     &amp; \vdots     &amp;        &amp; \vdots         \\
C_{(p-1)0} &amp; C_{(p-1)1} &amp; C_{(p-1)2} &amp; \cdots &amp; C_{(p-1)(p-1)} \\
\end{bmatrix}.
\]</span></p>
<p>Esencialmente, los elementos de la diagonal corresponden al vector <span class="math inline">\(\beta\)</span>.</p>
<p>Entonces, el error estándar para el vector <span class="math inline">\(\hat{\beta}\)</span> viene dado por</p>
<p><span class="math display">\[
\text{SE}[\hat{\beta}] = s_e \sqrt{\left(  X^\top X  \right)^{-1}}
\]</span></p>
<p>y en particular <span class="math inline">\(\hat{\beta}_j\)</span></p>
<p><span class="math display">\[
\text{SE}[\hat{\beta}_j] = s_e \sqrt{C_{jj}}.
\]</span></p>
<p>Por último, cada uno de los <span class="math inline">\(\hat{\beta}_j\)</span> siguen una distribución normal,</p>
<p><span class="math display">\[
\hat{\beta}_j \sim N\left(\beta_j, \sigma^2 C_{jj}  \right).
\]</span></p>
<p>por lo tanto</p>
<p><span class="math display">\[
\frac{\hat{\beta}_j - \beta_j}{s_e \sqrt{C_{jj}}} \sim t_{n-p}.
\]</span></p>
<p>Ahora que tenemos los resultados de distribución necesarios, podemos pasar a realizar pruebas y hacer estimaciones de intervalo.</p>
<div id="pruebas-de-un-solo-parámetro" class="section level3" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Pruebas de un solo parámetro</h3>
<p>La primera prueba que veremos es una prueba para un solo <span class="math inline">\(\beta_j\)</span>.</p>
<p><span class="math display">\[
H_0: \beta_j = 0 \quad \text{vs} \quad H_1: \beta_j \neq 0
\]</span></p>
<p>Nuevamente, el estadístico de prueba toma la forma</p>
<p><span class="math display">\[
\text{TS} = \frac{\text{EST} - \text{HYP}}{\text{SE}}.
\]</span></p>
<p>En particular,</p>
<p><span class="math display">\[
t = \frac{\hat{\beta}_j - \beta_j}{\text{SE}[\hat{\beta}_j]} = \frac{\hat{\beta}_j-0}{s_e\sqrt{C_{jj}}},
\]</span></p>
<p>que, bajo la hipótesis nula, sigue una distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(n-p\)</span> grados de libertad.</p>
<p>Recuerde nuestro modelo para <code>mpg</code>,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]</span></p>
<p>donde <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>.</p>
<ul>
<li><span class="math inline">\(x_{i1}\)</span> como el peso (<code>wt</code>) de el <span class="math inline">\(i\)</span>-esimo carro.</li>
<li><span class="math inline">\(x_{i2}\)</span> como el año del modelo (<code>year</code>) de el <span class="math inline">\(i\)</span>-esimo carro.</li>
</ul>
<p>Entonces la prueba</p>
<p><span class="math display">\[
H_0: \beta_1 = 0 \quad \text{vs} \quad H_1: \beta_1 \neq 0
\]</span></p>
<p>se puede encontrar en la salida de <code>summary()</code>, en particular:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="regresión-lineal-múltiple.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)<span class="sc">$</span>coef</span></code></pre></div>
<pre><code>##                  Estimate   Std. Error    t value      Pr(&gt;|t|)
## (Intercept) -14.637641945 4.0233913563  -3.638135  3.118311e-04
## wt           -0.006634876 0.0002148504 -30.881372 1.850466e-106
## year          0.761401955 0.0497265950  15.311765  1.036597e-41</code></pre>
<p>La estimación (<code>Estimate</code>), el error estándar (<code>Std.Error</code>), el estadístico de prueba (<code>valor t</code>) y el valor p (<code>Pr(&gt;|t|)</code>) para esta prueba se muestran en la segundo fila, etiquetada como <code>wt</code>. Recuerde que el valor p dado aquí es específicamente para una prueba de dos colas, donde el valor hipotético es 0.</p>
<p>También tenga en cuenta en este caso, al plantear la hipótesis nula de que <span class="math inline">\(\beta_1=0\)</span> y la alternativa esencialmente especifican dos modelos diferentes:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(Y = \beta_0 + \beta_2 x_{2} + \epsilon\)</span></li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(Y = \beta_0 + \beta_1 x_{1} + \beta_2 x_{2} + \epsilon\)</span></li>
</ul>
<p>Esto es importante. No estamos simplemente probando si existe o no una relación entre el peso y la eficiencia del combustible. Estamos probando si existe una relación entre el peso y la eficiencia del combustible, dado que en el modelo hay un término para el año. (Tenga en cuenta que hemos eliminado algunas indexaciones aquí para facilitar la lectura).</p>
</div>
<div id="intervalos-de-confianza" class="section level3" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Intervalos de confianza</h3>
<p>Dado que <span class="math inline">\(\hat{\beta}_j\)</span> es nuestra estimación de <span class="math inline">\(\beta_j\)</span> y tenemos</p>
<p><span class="math display">\[
\text{E}[\hat{\beta}_j] = \beta_j
\]</span></p>
<p>así como el error estándar,</p>
<p><span class="math display">\[
\text{SE}[\hat{\beta}_j] = s_e\sqrt{C_{jj}}
\]</span></p>
<p>y la distribución muestral de <span class="math inline">\(\hat{\beta}_j\)</span> es Normal, entonces podemos construir fácilmente intervalos de confianza para cada uno de los <span class="math inline">\(\hat{\beta}_j\)</span>.</p>
<p><span class="math display">\[
\hat{\beta}_j \pm t_{\alpha/2, n - p} \cdot s_e\sqrt{C_{jj}}
\]</span></p>
<p>Podemos encontrarlos en <code>R</code> usando el mismo método que antes. Ahora simplemente habrá filas adicionales para los <span class="math inline">\(\beta\)</span> adicionales.</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="regresión-lineal-múltiple.html#cb599-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mpg_model, <span class="at">level =</span> <span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>##                     0.5 %       99.5 %
## (Intercept) -25.052563681 -4.222720208
## wt           -0.007191036 -0.006078716
## year          0.632680051  0.890123859</code></pre>
</div>
<div id="intervalos-de-confianza-para-la-respuesta-media" class="section level3" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Intervalos de confianza para la respuesta media</h3>
<p>Como vimos en SLR, podemos crear intervalos de confianza para la respuesta media, es decir, una estimación de intervalo para <span class="math inline">\(\text{E}[Y \mid X = x]\)</span>. En SLR, la media de <span class="math inline">\(Y\)</span> solo dependía de un valor único <span class="math inline">\(x\)</span>. Ahora, en regresión múltiple, <span class="math inline">\(\text{E}[Y \mid X = x]\)</span> depende del valor de cada uno de los predictores, por lo que definimos el vector <span class="math inline">\(x_0\)</span> como,</p>
<p><span class="math display">\[
x_{0} = \begin{bmatrix}
1 \\
x_{01} \\
x_{02} \\
\vdots \\
x_{0(p-1)} \\
\end{bmatrix}.
\]</span></p>
<p>Entonces nuestra estimación de <span class="math inline">\(\text{E}[Y \mid X = x_0]\)</span> para un conjunto de valores <span class="math inline">\(x_0\)</span> viene dada por</p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}(x_0) &amp;= x_{0}^\top\hat{\beta} \\
&amp;= \hat{\beta}_0 + \hat{\beta}_1 x_{01} + \hat{\beta}_2 x_{02} + \cdots + \hat{\beta}_{p-1} x_{0(p-1)}.
\end{aligned}
\]</span></p>
<p>Al igual que con SLR, esta es una estimación no sesgada.</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}[\hat{y}(x_0)] &amp;= x_{0}^\top\beta \\
&amp;= \beta_0 + \beta_1 x_{01} + \beta_2 x_{02} + \cdots + \beta_{p-1} x_{0(p-1)}
\end{aligned}
\]</span></p>
<p>Para hacer una estimación de intervalo, también necesitaremos su error estándar.</p>
<p><span class="math display">\[
\text{SE}[\hat{y}(x_0)] = s_e \sqrt{x_{0}^\top\left(X^\top X\right)^{-1}x_{0}}
\]</span></p>
<p>Poniéndolo todo junto, obtenemos un intervalo de confianza para la respuesta media.</p>
<p><span class="math display">\[
\hat{y}(x_0) \pm t_{\alpha/2, n - p} \cdot s_e \sqrt{x_{0}^\top\left(X^\top X\right)^{-1}x_{0}}
\]</span></p>
<p>Las matemáticas han cambiado un poco, pero el proceso en <code>R</code> sigue siendo casi idéntico. Aquí, creamos un marco de datos para dos autos adicionales. Un automóvil que pesa 3500 libras producido en 1976, así como un segundo automóvil que pesa 5000 libras que se fabricó en 1981.</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="regresión-lineal-múltiple.html#cb601-1" aria-hidden="true" tabindex="-1"></a>new_cars <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">wt =</span> <span class="fu">c</span>(<span class="dv">3500</span>, <span class="dv">5000</span>), <span class="at">year =</span> <span class="fu">c</span>(<span class="dv">76</span>, <span class="dv">81</span>))</span>
<span id="cb601-2"><a href="regresión-lineal-múltiple.html#cb601-2" aria-hidden="true" tabindex="-1"></a>new_cars</span></code></pre></div>
<pre><code>##     wt year
## 1 3500   76
## 2 5000   81</code></pre>
<p>Entonces podemos usar la función <code>predict()</code> con <code>interval = "confidence"</code> para obtener intervalos de la eficiencia media del combustible para ambos autos nuevos. Nuevamente, es importante hacer que los datos pasados a <code>newdata</code> sea un marco de datos, de modo que <code>R</code> sepa qué valores son para qué variables.</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="regresión-lineal-múltiple.html#cb603-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mpg_model, <span class="at">newdata =</span> new_cars, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level =</span> <span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>##        fit     lwr      upr
## 1 20.00684 19.4712 20.54248
## 2 13.86154 12.3341 15.38898</code></pre>
<p><code>R</code> luego muestra la estimación <span class="math inline">\(\hat{y}(x_0)\)</span> (<code>fit</code>) para cada uno, así como los límites inferior (<code>lwr</code>) y superior (<code>upr</code>) para el intervalo en un nivel deseado (99%).</p>
<p>Una advertencia aquí: una de estas estimaciones es buena, mientras que otra es sospechosa.</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="regresión-lineal-múltiple.html#cb605-1" aria-hidden="true" tabindex="-1"></a>new_cars<span class="sc">$</span>wt</span></code></pre></div>
<pre><code>## [1] 3500 5000</code></pre>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="regresión-lineal-múltiple.html#cb607-1" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(autompg<span class="sc">$</span>wt)</span></code></pre></div>
<pre><code>## [1] 1613 5140</code></pre>
<p>Tenga en cuenta que ambos pesos de los automóviles nuevos están dentro del rango de valores observados.</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="regresión-lineal-múltiple.html#cb609-1" aria-hidden="true" tabindex="-1"></a>new_cars<span class="sc">$</span>year</span></code></pre></div>
<pre><code>## [1] 76 81</code></pre>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="regresión-lineal-múltiple.html#cb611-1" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(autompg<span class="sc">$</span>year)</span></code></pre></div>
<pre><code>## [1] 70 82</code></pre>
<p>Como son los años de cada uno de los coches nuevos.</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="regresión-lineal-múltiple.html#cb613-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year <span class="sc">~</span> wt, <span class="at">data =</span> autompg, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span>
<span id="cb613-2"><a href="regresión-lineal-múltiple.html#cb613-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(new_cars, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">cex =</span> <span class="dv">3</span>, <span class="at">pch =</span> <span class="st">&quot;X&quot;</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-256-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Sin embargo, ahora tenemos que considerar el peso y el año juntos. Y según la gráfica anterior, uno de los autos nuevos está dentro de la “mancha” de valores observados, mientras que el otro, el automóvil de 1981 que pesa 5000 libras, está notablemente fuera de los valores observados. Esta es una extrapolación oculta que debe tener en cuenta cuando utilice la regresión múltiple.</p>
<p>Cambiando de velocidad al nuevo par de datos que se puede estimar razonablemente, hacemos una verificación rápida de algunas de las matemáticas en <code>R</code>.</p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="regresión-lineal-múltiple.html#cb614-1" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3500</span>, <span class="dv">76</span>)</span>
<span id="cb614-2"><a href="regresión-lineal-múltiple.html#cb614-2" aria-hidden="true" tabindex="-1"></a>x0 <span class="sc">%*%</span> beta_hat</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 20.00684</code></pre>
<p><span class="math display">\[
x_{0} = \begin{bmatrix}
1    \\
3500 \\
76   \\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{\beta} = \begin{bmatrix}
-14.6376419    \\
-0.0066349    \\
0.761402    \\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{y}(x_0)  = x_{0}^\top\hat{\beta} = 
\begin{bmatrix}
1    &amp;
3500 &amp;
76   \\
\end{bmatrix}
\begin{bmatrix}
-14.6376419    \\
-0.0066349    \\
0.761402    \\
\end{bmatrix}= 20.0068411
\]</span></p>
<p>También tenga en cuenta que, usando un valor particular para <span class="math inline">\(x_0\)</span>, básicamente podemos extraer ciertos valores de <span class="math inline">\(\hat{\beta}_j\)</span>.</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="regresión-lineal-múltiple.html#cb616-1" aria-hidden="true" tabindex="-1"></a>beta_hat</span></code></pre></div>
<pre><code>##               [,1]
## [1,] -14.637641945
## [2,]  -0.006634876
## [3,]   0.761401955</code></pre>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="regresión-lineal-múltiple.html#cb618-1" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb618-2"><a href="regresión-lineal-múltiple.html#cb618-2" aria-hidden="true" tabindex="-1"></a>x0 <span class="sc">%*%</span> beta_hat</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 0.761402</code></pre>
<p>Teniendo esto en cuenta, los intervalos de confianza para el individuo <span class="math inline">\(\hat{\beta}_j\)</span> son en realidad un caso especial de un intervalo de confianza para la respuesta media.</p>
</div>
<div id="intervalos-de-predicción" class="section level3" number="9.2.4">
<h3><span class="header-section-number">9.2.4</span> Intervalos de predicción</h3>
<p>Al igual que con SLR, la creación de intervalos de predicción implica un ligero cambio en el error estándar para tener en cuenta el hecho de que ahora estamos considerando una observación, en lugar de una media.</p>
<p>Aquí usamos <span class="math inline">\(\hat{y}(x_0)\)</span> para estimar <span class="math inline">\(Y_0\)</span>, una nueva observación de <span class="math inline">\(Y\)</span> en el vector predictor <span class="math inline">\(x_0\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}(x_0) &amp;= x_{0}^\top\hat{\beta} \\
&amp;= \hat{\beta}_0 + \hat{\beta}_1 x_{01} + \hat{\beta}_2 x_{02} + \cdots + \hat{\beta}_{p-1} x_{0(p-1)}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{E}[\hat{y}(x_0)] &amp;= x_{0}^\top\beta \\
&amp;= \beta_0 + \beta_1 x_{01} + \beta_2 x_{02} + \cdots + \beta_{p-1} x_{0(p-1)}
\end{aligned}
\]</span></p>
<p>Como hicimos con SLR, debemos tener en cuenta la variabilidad adicional de una observación sobre su media.</p>
<p><span class="math display">\[
\text{SE}[\hat{y}(x_0) + \epsilon] = s_e \sqrt{1 + x_{0}^\top\left(X^\top X\right)^{-1}x_{0}}
\]</span></p>
<p>Luego llegamos a nuestro intervalo de predicción actualizado para MLR.</p>
<p><span class="math display">\[
\hat{y}(x_0) \pm t_{\alpha/2, n - p} \cdot s_e \sqrt{1 + x_{0}^\top\left(X^\top X\right)^{-1}x_{0}}
\]</span></p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="regresión-lineal-múltiple.html#cb620-1" aria-hidden="true" tabindex="-1"></a>new_cars</span></code></pre></div>
<pre><code>##     wt year
## 1 3500   76
## 2 5000   81</code></pre>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="regresión-lineal-múltiple.html#cb622-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mpg_model, <span class="at">newdata =</span> new_cars, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">level =</span> <span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>##        fit       lwr      upr
## 1 20.00684 11.108294 28.90539
## 2 13.86154  4.848751 22.87432</code></pre>
</div>
</div>
<div id="significancia-de-la-regresión" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Significancia de la regresión</h2>
<p>La descomposición de la variación que habíamos visto en SLR todavía se mantiene para MLR.</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_i - \bar{y})^2 = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2
\]</span></p>
<p>Es decir,</p>
<p><span class="math display">\[
\text{SST} = \text{SSE} + \text{SSReg}.
\]</span></p>
<p>Esto significa que, todavía podemos calcular <span class="math inline">\(R^2\)</span> de la misma manera que antes, lo que <code>R</code> continúa haciendo automáticamente.</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="regresión-lineal-múltiple.html#cb624-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.8082355</code></pre>
<p>La interpretación cambia ligeramente en comparación con SLR. En este caso de MLR, decimos que <span class="math inline">\(80.82\%\)</span> para la variación observada en millas por galón se explica por la relación lineal con las dos variables predictoras, peso y año.</p>
<p>En regresión múltiple, la significancia de la prueba de regresión es</p>
<p><span class="math display">\[
H_0: \beta_1 = \beta_2 = \cdots = \beta_{p - 1} = 0.
\]</span></p>
<p>Aquí, vemos que la hipótesis nula establece todos los <span class="math inline">\(\beta_j\)</span> iguales a 0, <em>excepto</em> la intersección, <span class="math inline">\(\beta_0\)</span>. Entonces podríamos decir que el modelo nulo, o “modelo bajo la hipótesis nula” es</p>
<p><span class="math display">\[
Y_i = \beta_0 + \epsilon_i.
\]</span></p>
<p>Este es un modelo donde la <em>regresión</em> es insignificante. <strong>Ninguno</strong> de los predictores tiene una relación lineal significativa con la respuesta. Notacionalmente, denotaremos los valores ajustados de este modelo como <span class="math inline">\(\hat{y}_{0i}\)</span>, que en este caso resulta ser:</p>
<p><span class="math display">\[
\hat{y}_{0i} = \bar{y}.
\]</span></p>
<p>La hipótesis alternativa aquí es que al menos uno de los <span class="math inline">\(\beta_j\)</span> de la hipótesis nula no es 0.</p>
<p><span class="math display">\[
H_1: \text{Al menos uno de los } \beta_j \neq 0, j = 1, 2, \cdots, (p-1)
\]</span></p>
<p>Entonces podríamos decir que el modelo completo, o “modelo bajo la hipótesis alternativa” es</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{(p-1)} x_{i(p-1)} + \epsilon_i
\]</span></p>
<p>Este es un modelo donde la regresión es significativa. <strong>Al menos uno</strong> de los predictores tiene una relación lineal significativa con la respuesta. Existe una relación lineal entre <span class="math inline">\(y\)</span> y los predictores, <span class="math inline">\(x_1, x_2,\ldots,x_{p-1}\)</span>.</p>
<p>Denotaremos los valores ajustados de este modelo como <span class="math inline">\(\hat{y}_{1i}\)</span>.</p>
<p>Para desarrollar la prueba <span class="math inline">\(F\)</span> para la significancia de la regresión, organizaremos la descomposición de la varianza en una tabla ANOVA.</p>
<table>
<colgroup>
<col width="19%" />
<col width="26%" />
<col width="19%" />
<col width="17%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th>Fuente</th>
<th>Suma de cuadrados</th>
<th>Grados de libertad</th>
<th>Cuadrado medio</th>
<th><span class="math inline">\(F\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regression</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(\hat{y}_{1i} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(p - 1\)</span></td>
<td><span class="math inline">\(\text{SSReg} / (p - 1)\)</span></td>
<td><span class="math inline">\(\text{MSReg} / \text{MSE}\)</span></td>
</tr>
<tr class="even">
<td>Error</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(y_i - \hat{y}_{1i})^2\)</span></td>
<td><span class="math inline">\(n - p\)</span></td>
<td><span class="math inline">\(\text{SSE} / (n - p)\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(y_i - \bar{y})^2\)</span></td>
<td><span class="math inline">\(n - 1\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>En resumen, la estadística <span class="math inline">\(F\)</span> es</p>
<p><span class="math display">\[
F = \frac{\sum_{i=1}^{n}(\hat{y}_{1i} - \bar{y})^2 / (p - 1)}{\sum_{i=1}^{n}(y_i - \hat{y}_{1i})^2 / (n - p)},
\]</span></p>
<p>y el valor p se calcula como</p>
<p><span class="math display">\[
P(F_{p-1, n-p} &gt; F)
\]</span></p>
<p>ya que rechazamos para valores grandes de <span class="math inline">\(F\)</span>. Un gran valor de la estadística corresponde a una gran parte de la varianza explicada por la regresión. Aquí <span class="math inline">\(F_{p-1,n-p}\)</span> representa una variable aleatoria que sigue una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(p-1\)</span> y <span class="math inline">\(n-p\)</span> grados de libertad.</p>
<p>Para realizar esta prueba en <code>R</code>, primero especificamos explícitamente los dos modelos y guardamos los resultados en diferentes variables. Luego usamos <code>anova()</code> para comparar los dos modelos, dando a `anova() el modelo nulo primero y el modelo alternativo (completo) en segundo lugar. (Especificar el modelo completo primero dará como resultado el mismo valor p, pero algunos valores intermedios sin sentido).</p>
<p>En este caso,</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(Y_i = \beta_0 + \epsilon_i\)</span></li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i\)</span></li>
</ul>
<p>Es decir, en el modelo nulo, no usamos ninguno de los predictores, mientras que en el modelo completo (alternativo), al menos uno de los predictores es útil.</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="regresión-lineal-múltiple.html#cb626-1" aria-hidden="true" tabindex="-1"></a>null_mpg_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> autompg)</span>
<span id="cb626-2"><a href="regresión-lineal-múltiple.html#cb626-2" aria-hidden="true" tabindex="-1"></a>full_mpg_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> year, <span class="at">data =</span> autompg)</span>
<span id="cb626-3"><a href="regresión-lineal-múltiple.html#cb626-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(null_mpg_model, full_mpg_model)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mpg ~ 1
## Model 2: mpg ~ wt + year
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    389 23761.7                                  
## 2    387  4556.6  2     19205 815.55 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Primero, observe que <code>R</code> no muestra los resultados de la misma manera que la tabla anterior. Más importante que el diseño de la tabla es su contenido. Vemos que el valor de la estadística <span class="math inline">\(F\)</span> es 815.55, y el valor p es extremadamente bajo, por lo que rechazamos la hipótesis nula en cualquier <span class="math inline">\(\alpha\)</span> y decimos que la regresión es significativa. Al menos uno de <code>wt</code> o <code>year</code> tiene una relación lineal útil con <code>mpg</code>.</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="regresión-lineal-múltiple.html#cb628-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + year, data = autompg)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.852 -2.292 -0.100  2.039 14.325 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.464e+01  4.023e+00  -3.638 0.000312 ***
## wt          -6.635e-03  2.149e-04 -30.881  &lt; 2e-16 ***
## year         7.614e-01  4.973e-02  15.312  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.431 on 387 degrees of freedom
## Multiple R-squared:  0.8082, Adjusted R-squared:  0.8072 
## F-statistic: 815.6 on 2 and 387 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Observe que el valor reportado en la fila para el <code>estadístico F</code> es de hecho el estadístico de prueba <span class="math inline">\(F\)</span> para la significancia de la prueba de regresión y, además, informa los dos grados de libertad relevantes.</p>
<p>Además, tenga en cuenta que ninguna de las pruebas-<span class="math inline">\(t\)</span> individuales son equivalentes a la prueba <span class="math inline">\(F\)</span> como lo eran en SLR. Esta equivalencia solo es válida para SLR porque la prueba individual para <span class="math inline">\(\beta_1\)</span> es la misma que la prueba para todos los parámetros que no son de intercepción, ya que solo hay uno.</p>
<p>También podemos verificar las sumas de cuadrados y grados de libertad directamente en <code>R</code>.</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="regresión-lineal-múltiple.html#cb630-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SSReg</span></span>
<span id="cb630-2"><a href="regresión-lineal-múltiple.html#cb630-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((<span class="fu">fitted</span>(full_mpg_model) <span class="sc">-</span> <span class="fu">fitted</span>(null_mpg_model)) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 19205.03</code></pre>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="regresión-lineal-múltiple.html#cb632-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE</span></span>
<span id="cb632-2"><a href="regresión-lineal-múltiple.html#cb632-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">resid</span>(full_mpg_model) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4556.646</code></pre>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="regresión-lineal-múltiple.html#cb634-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SST</span></span>
<span id="cb634-2"><a href="regresión-lineal-múltiple.html#cb634-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">resid</span>(null_mpg_model) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 23761.67</code></pre>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="regresión-lineal-múltiple.html#cb636-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Regression</span></span>
<span id="cb636-2"><a href="regresión-lineal-múltiple.html#cb636-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(full_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(null_mpg_model))</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="regresión-lineal-múltiple.html#cb638-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Error</span></span>
<span id="cb638-2"><a href="regresión-lineal-múltiple.html#cb638-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">resid</span>(full_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(full_mpg_model))</span></code></pre></div>
<pre><code>## [1] 387</code></pre>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="regresión-lineal-múltiple.html#cb640-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Total</span></span>
<span id="cb640-2"><a href="regresión-lineal-múltiple.html#cb640-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">resid</span>(null_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(null_mpg_model))</span></code></pre></div>
<pre><code>## [1] 389</code></pre>
</div>
<div id="modelos-anidados" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Modelos anidados</h2>
<p>La importancia de la prueba de regresión es en realidad un caso especial de prueba de lo que llamaremos <strong>modelos anidados</strong>. De manera más general, podemos comparar dos modelos, donde un modelo está “anidado” dentro del otro, lo que significa que un modelo contiene un subconjunto de predictores solo del modelo más grande.</p>
<p>Considere el siguiente modelo completo,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{(p-1)} x_{i(p-1)} + \epsilon_i
\]</span></p>
<p>Este modelo tiene <span class="math inline">\(p - 1\)</span> predictores, para un total de <span class="math inline">\(p\)</span> <span class="math inline">\(\beta\)</span>-parámetros. Denotaremos los valores ajustados de este modelo como <span class="math inline">\(\hat{y}_{1i}\)</span>.</p>
<p>Sea el modelo nulo</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{(q-1)} x_{i(q-1)} + \epsilon_i
\]</span></p>
<p>donde <span class="math inline">\(q&lt;p\)</span>. Este modelo tiene <span class="math inline">\(q-1\)</span> predictores , para un total de <span class="math inline">\(q\)</span> <span class="math inline">\(\beta\)</span>-parámetros. Denotaremos los valores ajustados de este modelo como <span class="math inline">\(\hat{y}_{0i}\)</span>.</p>
<p>La diferencia entre estos dos modelos se puede codificar mediante la hipótesis nula de una prueba.</p>
<p><span class="math display">\[
H_0: \beta_q = \beta_{q+1} = \cdots = \beta_{p - 1} = 0.
\]</span></p>
<p>Específicamente, los parámetros <span class="math inline">\(\beta\)</span> del modelo completo que no están en el modelo nulo son cero. El modelo resultante, que está anidado, es el modelo nulo.</p>
<p>Luego podemos realizar esta prueba usando una prueba <span class="math inline">\(F\)</span>, que es el resultado de la siguiente tabla ANOVA.</p>
<table>
<colgroup>
<col width="13%" />
<col width="28%" />
<col width="20%" />
<col width="18%" />
<col width="18%" />
</colgroup>
<thead>
<tr class="header">
<th>Fuente</th>
<th>Suma de cuadrados</th>
<th>Grados de libertad</th>
<th>Cuadrado medio</th>
<th><span class="math inline">\(F\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Diff</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(\hat{y}_{1i} - \hat{y}_{0i})^2\)</span></td>
<td><span class="math inline">\(p - q\)</span></td>
<td><span class="math inline">\(\text{SSD} / (p - q)\)</span></td>
<td><span class="math inline">\(\text{MSD} / \text{MSE}\)</span></td>
</tr>
<tr class="even">
<td>Full</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(y_i - \hat{y}_{1i})^2\)</span></td>
<td><span class="math inline">\(n - p\)</span></td>
<td><span class="math inline">\(\text{SSE} / (n - p)\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Null</td>
<td><span class="math inline">\(\sum_{i=1}^{n}(y_i - \hat{y}_{0i})^2\)</span></td>
<td><span class="math inline">\(n - q\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
F = \frac{\sum_{i=1}^{n}(\hat{y}_{1i} - \hat{y}_{0i})^2 / (p - q)}{\sum_{i=1}^{n}(y_i - \hat{y}_{1i})^2 / (n - p)}.
\]</span></p>
<p>Observe que la fila de “Diff” compara la suma de las diferencias al cuadrado de los valores ajustados. Los grados de libertad son entonces la diferencia del número de parámetros <span class="math inline">\(\beta\)</span> estimados entre los dos modelos.</p>
<p>Por ejemplo, el conjunto de datos <code>autompg</code> tiene una serie de variables adicionales que todavía tenemos que usar.</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="regresión-lineal-múltiple.html#cb642-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(autompg)</span></code></pre></div>
<pre><code>## [1] &quot;mpg&quot;  &quot;cyl&quot;  &quot;disp&quot; &quot;hp&quot;   &quot;wt&quot;   &quot;acc&quot;  &quot;year&quot;</code></pre>
<p>Continuaremos usando <code>mpg</code> como respuesta, pero ahora consideraremos dos modelos diferentes.</p>
<ul>
<li>Full: <code>mpg ~ wt + year + cyl + disp + hp + acc</code></li>
<li>Null: <code>mpg ~ wt + year</code></li>
</ul>
<p>Tenga en cuenta que estos son modelos anidados, ya que el modelo nulo contiene un subconjunto de los predictores del modelo completo y no hay predictores adicionales. Ambos modelos tienen un intercepto <span class="math inline">\(\beta_0\)</span> así como un coeficiente delante de cada uno de los predictores. Entonces podríamos escribir la hipótesis nula para comparar estos dos modelos como,</p>
<p><span class="math display">\[
H_0: \beta_{\texttt{cyl}} = \beta_{\texttt{disp}} = \beta_{\texttt{hp}} = \beta_{\texttt{acc}} = 0
\]</span></p>
<p>La alternativa es simplemente que al menos uno de los <span class="math inline">\(\beta_ {j}\)</span> de la hipotesis nula no sea 0.</p>
<p>Para realizar esta prueba en <code>R</code> primero definimos ambos modelos, luego usamos el comando <code>anova()</code>.</p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="regresión-lineal-múltiple.html#cb644-1" aria-hidden="true" tabindex="-1"></a>null_mpg_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> year, <span class="at">data =</span> autompg)</span>
<span id="cb644-2"><a href="regresión-lineal-múltiple.html#cb644-2" aria-hidden="true" tabindex="-1"></a><span class="co">#full_mpg_model = lm(mpg ~ wt + year + cyl + disp + hp + acc, data = autompg)</span></span>
<span id="cb644-3"><a href="regresión-lineal-múltiple.html#cb644-3" aria-hidden="true" tabindex="-1"></a>full_mpg_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> ., <span class="at">data =</span> autompg)</span>
<span id="cb644-4"><a href="regresión-lineal-múltiple.html#cb644-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(null_mpg_model, full_mpg_model)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mpg ~ wt + year
## Model 2: mpg ~ cyl + disp + hp + wt + acc + year
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    387 4556.6                           
## 2    383 4530.5  4     26.18 0.5533 0.6967</code></pre>
<p>Aquí hemos utilizado la fórmula <code>mpg ~ .</code> para definir el modelo completo. Esto es lo mismo que la línea comentada. Específicamente, este es un atajo común en <code>R</code> que dice “modelar <code>mpg</code> como respuesta con cada una de las variables restantes en el marco de datos como predictores”.</p>
<p>Aquí vemos que el valor de la estadística <span class="math inline">\(F\)</span> es 0.553, y el valor p es muy grande, por lo que no rechazamos la hipótesis nula en cualquier <span class="math inline">\(\alpha\)</span> razonable y podemos decir que ninguno de <code>cyl</code>, <code>disp</code>, <code>hp</code> y <code>acc</code> son significativos con <code>wt</code> y <code>year</code> ya en el modelo.</p>
<p>Nuevamente, verificamos las sumas de cuadrados y grados de libertad directamente en <code>R</code>.</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="regresión-lineal-múltiple.html#cb646-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SSDiff</span></span>
<span id="cb646-2"><a href="regresión-lineal-múltiple.html#cb646-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((<span class="fu">fitted</span>(full_mpg_model) <span class="sc">-</span> <span class="fu">fitted</span>(null_mpg_model)) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 26.17981</code></pre>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="regresión-lineal-múltiple.html#cb648-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE (For Full)</span></span>
<span id="cb648-2"><a href="regresión-lineal-múltiple.html#cb648-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">resid</span>(full_mpg_model) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4530.466</code></pre>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="regresión-lineal-múltiple.html#cb650-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SST (For Null)</span></span>
<span id="cb650-2"><a href="regresión-lineal-múltiple.html#cb650-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">resid</span>(null_mpg_model) <span class="sc">^</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4556.646</code></pre>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="regresión-lineal-múltiple.html#cb652-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Diff</span></span>
<span id="cb652-2"><a href="regresión-lineal-múltiple.html#cb652-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(full_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(null_mpg_model))</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb654-1"><a href="regresión-lineal-múltiple.html#cb654-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Full</span></span>
<span id="cb654-2"><a href="regresión-lineal-múltiple.html#cb654-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">resid</span>(full_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(full_mpg_model))</span></code></pre></div>
<pre><code>## [1] 383</code></pre>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="regresión-lineal-múltiple.html#cb656-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of Freedom: Null</span></span>
<span id="cb656-2"><a href="regresión-lineal-múltiple.html#cb656-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">resid</span>(null_mpg_model)) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(null_mpg_model))</span></code></pre></div>
<pre><code>## [1] 387</code></pre>
</div>
<div id="simulación-1" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Simulación</h2>
<p>Dado que ignoramos la derivación de ciertos resultados, usaremos nuevamente la simulación para convencernos de algunos de los resultados anteriores. En particular, simularemos muestras de tamaño <code>n = 100</code> del modelo</p>
<p><span class="math display">\[
Y_i = 5 + -2 x_{i1} + 6 x_{i2} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]</span></p>
<p>donde <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2 = 16)\)</span>. Aquí tenemos dos predictores, entonces <span class="math inline">\(p = 3\)</span>.</p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb658-1"><a href="regresión-lineal-múltiple.html#cb658-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1337</span>)</span>
<span id="cb658-2"><a href="regresión-lineal-múltiple.html#cb658-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">100</span> <span class="co"># tamaño de la muestra</span></span>
<span id="cb658-3"><a href="regresión-lineal-múltiple.html#cb658-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb658-4"><a href="regresión-lineal-múltiple.html#cb658-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb658-5"><a href="regresión-lineal-múltiple.html#cb658-5" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">=</span> <span class="dv">5</span></span>
<span id="cb658-6"><a href="regresión-lineal-múltiple.html#cb658-6" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">=</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb658-7"><a href="regresión-lineal-múltiple.html#cb658-7" aria-hidden="true" tabindex="-1"></a>beta_2 <span class="ot">=</span> <span class="dv">6</span></span>
<span id="cb658-8"><a href="regresión-lineal-múltiple.html#cb658-8" aria-hidden="true" tabindex="-1"></a>sigma  <span class="ot">=</span> <span class="dv">4</span></span></code></pre></div>
<p>Como es la norma con la regresión, los valores de <span class="math inline">\(x\)</span> se consideran cantidades fijas y conocidas, por lo que las simularemos primero y permanecerán iguales durante el resto del estudio de simulación. También tenga en cuenta que creamos un <code>x0</code> que contiene solo <code>1</code>, que necesitamos para crear nuestra matriz <code>X</code>. Si observa la formulación matricial de regresión, este vector unitario de todos los <code>1</code> es un “predictor” que coloca el intercepto en el modelo. También calculamos la matriz <code>C</code> para su uso posterior.</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="regresión-lineal-múltiple.html#cb659-1" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, n)</span>
<span id="cb659-2"><a href="regresión-lineal-múltiple.html#cb659-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="at">length =</span> n))</span>
<span id="cb659-3"><a href="regresión-lineal-múltiple.html#cb659-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="at">length =</span> n))</span>
<span id="cb659-4"><a href="regresión-lineal-múltiple.html#cb659-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">cbind</span>(x0, x1, x2)</span>
<span id="cb659-5"><a href="regresión-lineal-múltiple.html#cb659-5" aria-hidden="true" tabindex="-1"></a>C <span class="ot">=</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X)</span></code></pre></div>
<p>Luego simulamos la respuesta de acuerdo con el modelo anterior. Por último, colocamos los dos predictores y la respuesta en un marco de datos. Tenga en cuenta que <strong>no</strong> colocamos <code>x0</code> en el marco de datos. Este es el resultado de que <code>R</code> agregue una intersección por defecto.</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="regresión-lineal-múltiple.html#cb660-1" aria-hidden="true" tabindex="-1"></a>eps      <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb660-2"><a href="regresión-lineal-múltiple.html#cb660-2" aria-hidden="true" tabindex="-1"></a>y        <span class="ot">=</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x1 <span class="sc">+</span> beta_2 <span class="sc">*</span> x2 <span class="sc">+</span> eps</span>
<span id="cb660-3"><a href="regresión-lineal-múltiple.html#cb660-3" aria-hidden="true" tabindex="-1"></a>sim_data <span class="ot">=</span> <span class="fu">data.frame</span>(x1, x2, y)</span></code></pre></div>
<p>Trazar estos datos y ajustar la regresión produce el siguiente gráfico.</p>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-270-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Luego calculamos</p>
<p><span class="math display">\[
\hat{\beta} = \left(  X^\top X  \right)^{-1}X^\top y.
\]</span></p>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="regresión-lineal-múltiple.html#cb661-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">beta_hat =</span> C <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y)</span></code></pre></div>
<pre><code>##         [,1]
## x0  7.290735
## x1 -2.282176
## x2  5.843424</code></pre>
<p>Observe que estos valores son los mismos que los coeficientes encontrados usando <code>lm()</code> en <code>R</code>.</p>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="regresión-lineal-múltiple.html#cb663-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> sim_data))</span></code></pre></div>
<pre><code>## (Intercept)          x1          x2 
##    7.290735   -2.282176    5.843424</code></pre>
<p>Además, estos valores están cerca de lo que esperaríamos.</p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="regresión-lineal-múltiple.html#cb665-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(beta_0, beta_1, beta_2)</span></code></pre></div>
<pre><code>## [1]  5 -2  6</code></pre>
<p>Luego calculamos los valores ajustados para calcular <span class="math inline">\(s_e\)</span>, vemos que es el mismo <code>sigma</code> que devuelve <code>summary()</code>.</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="regresión-lineal-múltiple.html#cb667-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">=</span> X <span class="sc">%*%</span> beta_hat</span>
<span id="cb667-2"><a href="regresión-lineal-múltiple.html#cb667-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">s_e =</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((y <span class="sc">-</span> y_hat) <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> p)))</span></code></pre></div>
<pre><code>## [1] 4.294307</code></pre>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="regresión-lineal-múltiple.html#cb669-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> sim_data))<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 4.294307</code></pre>
<p>Hasta aquí todo está bien. Ahora finalmente simularemos repetidamente a partir de este modelo para obtener una distribución empírica de <span class="math inline">\(\hat{\beta}_2\)</span>.</p>
<p>Esperamos que <span class="math inline">\(\hat{\beta}_2\)</span> siga una distribución normal,</p>
<p><span class="math display">\[
\hat{\beta}_2 \sim N\left(\beta_2, \sigma^2 C_{22}  \right).
\]</span></p>
<p>En este caso,</p>
<p><span class="math display">\[
\hat{\beta}_2 \sim N\left(\mu = 6, \sigma^2 = 16 \times 0.0014534 = 0.0232549  \right).
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_2 \sim N\left(\mu = 6, \sigma^2 = 0.0232549  \right).
\]</span></p>
<p>Tenga en cuenta que <span class="math inline">\(C_{22}\)</span> corresponde al elemento en la <strong>tercera</strong> fila y <strong>tercera</strong> columna ya que <span class="math inline">\(\beta_2\)</span> es el <strong>tercer</strong> parámetro en el modelo y porque <code>R</code> está indexado comenzando en “1”. Sin embargo, indexamos la matriz <span class="math inline">\(C\)</span> comenzando en <code>0</code> para hacer coincidir los elementos diagonales con el <span class="math inline">\(\beta_j\)</span> correspondiente.</p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="regresión-lineal-múltiple.html#cb671-1" aria-hidden="true" tabindex="-1"></a>C[<span class="dv">3</span>, <span class="dv">3</span>]</span></code></pre></div>
<pre><code>## [1] 0.00145343</code></pre>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="regresión-lineal-múltiple.html#cb673-1" aria-hidden="true" tabindex="-1"></a>C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] 0.00145343</code></pre>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="regresión-lineal-múltiple.html#cb675-1" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] 0.02325487</code></pre>
<p>Ahora realizamos la simulación un gran número de veces. Cada vez, actualizamos la variable <code>y</code> en el marco de datos, dejando las variables <code>x</code> iguales. Luego ajustamos un modelo y almacenamos <span class="math inline">\(\hat{\beta}_2\)</span>.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="regresión-lineal-múltiple.html#cb677-1" aria-hidden="true" tabindex="-1"></a>num_sims <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb677-2"><a href="regresión-lineal-múltiple.html#cb677-2" aria-hidden="true" tabindex="-1"></a>beta_hat_2 <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, num_sims)</span>
<span id="cb677-3"><a href="regresión-lineal-múltiple.html#cb677-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_sims) {</span>
<span id="cb677-4"><a href="regresión-lineal-múltiple.html#cb677-4" aria-hidden="true" tabindex="-1"></a>  eps           <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span> , <span class="at">sd =</span> sigma)</span>
<span id="cb677-5"><a href="regresión-lineal-múltiple.html#cb677-5" aria-hidden="true" tabindex="-1"></a>  sim_data<span class="sc">$</span>y    <span class="ot">=</span> beta_0 <span class="sc">*</span> x0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x1 <span class="sc">+</span> beta_2 <span class="sc">*</span> x2 <span class="sc">+</span> eps</span>
<span id="cb677-6"><a href="regresión-lineal-múltiple.html#cb677-6" aria-hidden="true" tabindex="-1"></a>  fit           <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> sim_data)</span>
<span id="cb677-7"><a href="regresión-lineal-múltiple.html#cb677-7" aria-hidden="true" tabindex="-1"></a>  beta_hat_2[i] <span class="ot">=</span> <span class="fu">coef</span>(fit)[<span class="dv">3</span>]</span>
<span id="cb677-8"><a href="regresión-lineal-múltiple.html#cb677-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Luego vemos que la media de los valores simulados está cerca del valor real de <span class="math inline">\(\beta_2\)</span>.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="regresión-lineal-múltiple.html#cb678-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(beta_hat_2)</span></code></pre></div>
<pre><code>## [1] 5.999723</code></pre>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="regresión-lineal-múltiple.html#cb680-1" aria-hidden="true" tabindex="-1"></a>beta_2</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>También vemos que la varianza de los valores simulados está cerca de la verdadera varianza de <span class="math inline">\(\hat{\beta}_2\)</span>.</p>
<p><span class="math display">\[
\text{Var}[\hat{\beta}_2] = \sigma^2 \cdot C_{22} = 16 \times 0.0014534 = 0.0232549
\]</span></p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="regresión-lineal-múltiple.html#cb682-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(beta_hat_2)</span></code></pre></div>
<pre><code>## [1] 0.02343408</code></pre>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="regresión-lineal-múltiple.html#cb684-1" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] 0.02325487</code></pre>
<p>Las desviaciones estándar encontradas a partir de los datos simulados y la población de origen también son muy cercanas.</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="regresión-lineal-múltiple.html#cb686-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(beta_hat_2)</span></code></pre></div>
<pre><code>## [1] 0.1530819</code></pre>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="regresión-lineal-múltiple.html#cb688-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(sigma <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 0.1524955</code></pre>
<p>Por último, graficamos un histograma de los <em>valores simulados</em> y superponemos la <em>distribución verdadera</em>.</p>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="regresión-lineal-múltiple.html#cb690-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(beta_hat_2, <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">breaks =</span> <span class="dv">20</span>, </span>
<span id="cb690-2"><a href="regresión-lineal-múltiple.html#cb690-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">2</span>]), <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">border =</span> <span class="st">&quot;dodgerblue&quot;</span>)</span>
<span id="cb690-3"><a href="regresión-lineal-múltiple.html#cb690-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="at">mean =</span> beta_2, <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>])), </span>
<span id="cb690-4"><a href="regresión-lineal-múltiple.html#cb690-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-280-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>¡Esto luce bien! El histograma basado en simulación parece ser Normal con una media de 6 y una extensión de aproximadamente 0,15 a medida que mide desde el centro hasta el punto de inflexión. Eso coincide muy bien con la distribución muestral de <span class="math inline">\(\hat{\beta}_2 \sim N\left(\mu = 6, \sigma^2 = 0.0232549 \right)\)</span>.</p>
<p>Una última comprobación, verificamos la regla de <span class="math inline">\(68 - 95 - 99.7\)</span>.</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="regresión-lineal-múltiple.html#cb691-1" aria-hidden="true" tabindex="-1"></a>sd_bh2 <span class="ot">=</span> <span class="fu">sqrt</span>(sigma <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> C[<span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb691-2"><a href="regresión-lineal-múltiple.html#cb691-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We expect these to be: 0.68, 0.95, 0.997</span></span>
<span id="cb691-3"><a href="regresión-lineal-múltiple.html#cb691-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(beta_2 <span class="sc">-</span> <span class="dv">1</span> <span class="sc">*</span> sd_bh2 <span class="sc">&lt;</span> beta_hat_2 <span class="sc">&amp;</span> beta_hat_2 <span class="sc">&lt;</span> beta_2 <span class="sc">+</span> <span class="dv">1</span> <span class="sc">*</span> sd_bh2)</span></code></pre></div>
<pre><code>## [1] 0.6807</code></pre>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="regresión-lineal-múltiple.html#cb693-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(beta_2 <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> sd_bh2 <span class="sc">&lt;</span> beta_hat_2 <span class="sc">&amp;</span> beta_hat_2 <span class="sc">&lt;</span> beta_2 <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> sd_bh2)</span></code></pre></div>
<pre><code>## [1] 0.9529</code></pre>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="regresión-lineal-múltiple.html#cb695-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(beta_2 <span class="sc">-</span> <span class="dv">3</span> <span class="sc">*</span> sd_bh2 <span class="sc">&lt;</span> beta_hat_2 <span class="sc">&amp;</span> beta_hat_2 <span class="sc">&lt;</span> beta_2 <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> sd_bh2)</span></code></pre></div>
<pre><code>## [1] 0.9967</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferencia-para-regresión-lineal-simple.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="construcción-del-modelo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
