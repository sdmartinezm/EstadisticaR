<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 16 Selección de variables y construcción de modelos | Estadística aplicada con R</title>
  <meta name="description" content="Capítulo 16 Selección de variables y construcción de modelos | Estadística aplicada con R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 16 Selección de variables y construcción de modelos | Estadística aplicada con R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 16 Selección de variables y construcción de modelos | Estadística aplicada con R" />
  
  
  



<meta name="date" content="2021-05-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.gif" type="image/x-icon" />
<link rel="prev" href="colinealidad.html"/>
<link rel="next" href="regresión-logística.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística aplicada con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#convenciones"><i class="fa fa-check"></i><b>1.1</b> Convenciones</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-a-r.html"><a href="introducción-a-r.html"><i class="fa fa-check"></i><b>2</b> Introducción a <code>R</code></a>
<ul>
<li class="chapter" data-level="2.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#primeros-pasos"><i class="fa fa-check"></i><b>2.1</b> Primeros pasos</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#cálculos-básicos"><i class="fa fa-check"></i><b>2.2</b> Cálculos básicos</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#obteniendo-ayuda"><i class="fa fa-check"></i><b>2.3</b> Obteniendo ayuda</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instalación-de-paquetes"><i class="fa fa-check"></i><b>2.4</b> Instalación de paquetes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datos-y-programación.html"><a href="datos-y-programación.html"><i class="fa fa-check"></i><b>3</b> Datos y programación</a>
<ul>
<li class="chapter" data-level="3.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#tipos-de-datos"><i class="fa fa-check"></i><b>3.1</b> Tipos de datos</a></li>
<li class="chapter" data-level="3.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#estructuras-de-datos"><i class="fa fa-check"></i><b>3.2</b> Estructuras de datos</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#vectores"><i class="fa fa-check"></i><b>3.2.1</b> Vectores</a></li>
<li class="chapter" data-level="3.2.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#vectorización"><i class="fa fa-check"></i><b>3.2.2</b> Vectorización</a></li>
<li class="chapter" data-level="3.2.3" data-path="datos-y-programación.html"><a href="datos-y-programación.html#operadores-logicos"><i class="fa fa-check"></i><b>3.2.3</b> Operadores logicos</a></li>
<li class="chapter" data-level="3.2.4" data-path="datos-y-programación.html"><a href="datos-y-programación.html#más-vectorización"><i class="fa fa-check"></i><b>3.2.4</b> Más vectorización</a></li>
<li class="chapter" data-level="3.2.5" data-path="datos-y-programación.html"><a href="datos-y-programación.html#matrices"><i class="fa fa-check"></i><b>3.2.5</b> Matrices</a></li>
<li class="chapter" data-level="3.2.6" data-path="datos-y-programación.html"><a href="datos-y-programación.html#listas"><i class="fa fa-check"></i><b>3.2.6</b> Listas</a></li>
<li class="chapter" data-level="3.2.7" data-path="datos-y-programación.html"><a href="datos-y-programación.html#marcos-de-datos"><i class="fa fa-check"></i><b>3.2.7</b> Marcos de datos</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="datos-y-programación.html"><a href="datos-y-programación.html#conceptos-básicos-de-programación"><i class="fa fa-check"></i><b>3.3</b> Conceptos básicos de programación</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="datos-y-programación.html"><a href="datos-y-programación.html#flujo-de-control"><i class="fa fa-check"></i><b>3.3.1</b> Flujo de control</a></li>
<li class="chapter" data-level="3.3.2" data-path="datos-y-programación.html"><a href="datos-y-programación.html#funciones"><i class="fa fa-check"></i><b>3.3.2</b> Funciones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html"><i class="fa fa-check"></i><b>4</b> Resumen de datos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#resumen-estadístico"><i class="fa fa-check"></i><b>4.1</b> Resumen estadístico</a>
<ul>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#tendencia-central"><i class="fa fa-check"></i>Tendencia central</a></li>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#dispersión"><i class="fa fa-check"></i>Dispersión</a></li>
<li class="chapter" data-level="" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#categórica"><i class="fa fa-check"></i>Categórica</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#graficas"><i class="fa fa-check"></i><b>4.2</b> Graficas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#histogramas"><i class="fa fa-check"></i><b>4.2.1</b> Histogramas</a></li>
<li class="chapter" data-level="4.2.2" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#gráfico-de-barras"><i class="fa fa-check"></i><b>4.2.2</b> Gráfico de barras</a></li>
<li class="chapter" data-level="4.2.3" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#diagramas-de-cajas"><i class="fa fa-check"></i><b>4.2.3</b> Diagramas de cajas</a></li>
<li class="chapter" data-level="4.2.4" data-path="resumen-de-datos.html"><a href="resumen-de-datos.html#gráfico-de-dispersión"><i class="fa fa-check"></i><b>4.2.4</b> Gráfico de dispersión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html"><i class="fa fa-check"></i><b>5</b> Probabilidad y estadística en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#probabilidad-en-r"><i class="fa fa-check"></i><b>5.1</b> Probabilidad en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#distribuciones"><i class="fa fa-check"></i><b>5.1.1</b> Distribuciones</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#pruebas-de-hipótesis-en-r"><i class="fa fa-check"></i><b>5.2</b> Pruebas de hipótesis en <code>R</code></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-una-muestra-revisión"><i class="fa fa-check"></i><b>5.2.1</b> Prueba t de una muestra: revisión</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-una-muestra-ejemplo"><i class="fa fa-check"></i><b>5.2.2</b> Prueba t de una muestra: ejemplo</a></li>
<li class="chapter" data-level="5.2.3" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-dos-muestras-revisión"><i class="fa fa-check"></i><b>5.2.3</b> Prueba t de dos muestras: revisión</a></li>
<li class="chapter" data-level="5.2.4" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#prueba-t-de-dos-muestras-ejemplo"><i class="fa fa-check"></i><b>5.2.4</b> Prueba t de dos muestras: Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#simulación"><i class="fa fa-check"></i><b>5.3</b> Simulación</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#diferencias-emparejadas"><i class="fa fa-check"></i><b>5.3.1</b> Diferencias emparejadas</a></li>
<li class="chapter" data-level="5.3.2" data-path="probabilidad-y-estadística-en-r.html"><a href="probabilidad-y-estadística-en-r.html#distribución-de-una-media-muestral"><i class="fa fa-check"></i><b>5.3.2</b> Distribución de una media muestral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="recursos-r.html"><a href="recursos-r.html"><i class="fa fa-check"></i><b>6</b> Recursos <code>R</code></a>
<ul>
<li class="chapter" data-level="6.1" data-path="recursos-r.html"><a href="recursos-r.html#referencias-y-tutoriales-para-principiantes"><i class="fa fa-check"></i><b>6.1</b> Referencias y tutoriales para principiantes</a></li>
<li class="chapter" data-level="6.2" data-path="recursos-r.html"><a href="recursos-r.html#referencias-intermedias"><i class="fa fa-check"></i><b>6.2</b> Referencias intermedias</a></li>
<li class="chapter" data-level="6.3" data-path="recursos-r.html"><a href="recursos-r.html#referencias-avanzadas"><i class="fa fa-check"></i><b>6.3</b> Referencias avanzadas</a></li>
<li class="chapter" data-level="6.4" data-path="recursos-r.html"><a href="recursos-r.html#comparaciones-rápidas-con-otros-lenguajes"><i class="fa fa-check"></i><b>6.4</b> Comparaciones rápidas con otros lenguajes</a></li>
<li class="chapter" data-level="6.5" data-path="recursos-r.html"><a href="recursos-r.html#vídeos-de-rstudio-y-rmarkdown"><i class="fa fa-check"></i><b>6.5</b> Vídeos de RStudio y RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html"><i class="fa fa-check"></i><b>7</b> Regresión lineal simple</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#modelado"><i class="fa fa-check"></i><b>7.1</b> Modelado</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#modelo-de-regresión-lineal-simple"><i class="fa fa-check"></i><b>7.1.1</b> Modelo de regresión lineal simple</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#enfoque-de-mínimos-cuadrados"><i class="fa fa-check"></i><b>7.2</b> Enfoque de mínimos cuadrados</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#haciendo-predicciones"><i class="fa fa-check"></i><b>7.2.1</b> Haciendo predicciones</a></li>
<li class="chapter" data-level="7.2.2" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#residuales"><i class="fa fa-check"></i><b>7.2.2</b> Residuales</a></li>
<li class="chapter" data-level="7.2.3" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#estimación-de-la-varianza"><i class="fa fa-check"></i><b>7.2.3</b> Estimación de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#descomposición-de-variación"><i class="fa fa-check"></i><b>7.3</b> Descomposición de variación</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#coeficiente-de-determinación"><i class="fa fa-check"></i><b>7.3.1</b> Coeficiente de determinación</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#la-función-lm"><i class="fa fa-check"></i><b>7.4</b> La función <code>lm</code></a></li>
<li class="chapter" data-level="7.5" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#enfoque-de-estimación-de-máxima-verosimilitud-mle"><i class="fa fa-check"></i><b>7.5</b> Enfoque de estimación de máxima verosimilitud (MLE)</a></li>
<li class="chapter" data-level="7.6" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#simulando-slr"><i class="fa fa-check"></i><b>7.6</b> Simulando SLR</a></li>
<li class="chapter" data-level="7.7" data-path="regresión-lineal-simple.html"><a href="regresión-lineal-simple.html#historia"><i class="fa fa-check"></i><b>7.7</b> Historia</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html"><i class="fa fa-check"></i><b>8</b> Inferencia para regresión lineal simple</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#teorema-de-gauss-markov"><i class="fa fa-check"></i><b>8.1</b> Teorema de Gauss-Markov</a></li>
<li class="chapter" data-level="8.2" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#distribuciones-muestrales"><i class="fa fa-check"></i><b>8.2</b> Distribuciones muestrales</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#simular-distribuciones-muestrales"><i class="fa fa-check"></i><b>8.2.1</b> Simular distribuciones muestrales</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#errores-estándar"><i class="fa fa-check"></i><b>8.3</b> Errores estándar</a></li>
<li class="chapter" data-level="8.4" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalos-de-confianza-para-pendiente-e-intercepto"><i class="fa fa-check"></i><b>8.4</b> Intervalos de confianza para pendiente e Intercepto</a></li>
<li class="chapter" data-level="8.5" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>8.5</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="8.6" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#ejemplo-cars"><i class="fa fa-check"></i><b>8.6</b> Ejemplo <code>cars</code></a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#pruebas-en-r"><i class="fa fa-check"></i><b>8.6.1</b> Pruebas en <code>R</code></a></li>
<li class="chapter" data-level="8.6.2" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#significancia-de-la-regresión-prueba-t."><i class="fa fa-check"></i><b>8.6.2</b> Significancia de la regresión, prueba t.</a></li>
<li class="chapter" data-level="8.6.3" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalos-de-confianza-en-r"><i class="fa fa-check"></i><b>8.6.3</b> Intervalos de confianza en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalo-de-confianza-para-la-respuesta-promedio"><i class="fa fa-check"></i><b>8.7</b> Intervalo de confianza para la respuesta Promedio</a></li>
<li class="chapter" data-level="8.8" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#intervalo-de-predicción-para-nuevas-observaciones"><i class="fa fa-check"></i><b>8.8</b> Intervalo de predicción para nuevas observaciones</a></li>
<li class="chapter" data-level="8.9" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#bandas-de-confianza-y-predicción"><i class="fa fa-check"></i><b>8.9</b> Bandas de confianza y predicción</a></li>
<li class="chapter" data-level="8.10" data-path="inferencia-para-regresión-lineal-simple.html"><a href="inferencia-para-regresión-lineal-simple.html#significancia-de-la-regresión-prueba-f"><i class="fa fa-check"></i><b>8.10</b> Significancia de la regresión, prueba F</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html"><i class="fa fa-check"></i><b>9</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#enfoque-matricial-para-la-regresión"><i class="fa fa-check"></i><b>9.1</b> Enfoque matricial para la regresión</a></li>
<li class="chapter" data-level="9.2" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#distribución-muestral"><i class="fa fa-check"></i><b>9.2</b> Distribución muestral</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#pruebas-de-un-solo-parámetro"><i class="fa fa-check"></i><b>9.2.1</b> Pruebas de un solo parámetro</a></li>
<li class="chapter" data-level="9.2.2" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>9.2.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="9.2.3" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-confianza-para-la-respuesta-media"><i class="fa fa-check"></i><b>9.2.3</b> Intervalos de confianza para la respuesta media</a></li>
<li class="chapter" data-level="9.2.4" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#intervalos-de-predicción"><i class="fa fa-check"></i><b>9.2.4</b> Intervalos de predicción</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#significancia-de-la-regresión"><i class="fa fa-check"></i><b>9.3</b> Significancia de la regresión</a></li>
<li class="chapter" data-level="9.4" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#modelos-anidados"><i class="fa fa-check"></i><b>9.4</b> Modelos anidados</a></li>
<li class="chapter" data-level="9.5" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#simulación-1"><i class="fa fa-check"></i><b>9.5</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html"><i class="fa fa-check"></i><b>10</b> Construcción del modelo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#familia-forma-y-ajuste."><i class="fa fa-check"></i><b>10.1</b> Familia, forma, y ajuste.</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#ajuste."><i class="fa fa-check"></i><b>10.1.1</b> Ajuste.</a></li>
<li class="chapter" data-level="10.1.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#forma"><i class="fa fa-check"></i><b>10.1.2</b> Forma</a></li>
<li class="chapter" data-level="10.1.3" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#familia"><i class="fa fa-check"></i><b>10.1.3</b> Familia</a></li>
<li class="chapter" data-level="10.1.4" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#modelo-asumido-modelo-ajustado"><i class="fa fa-check"></i><b>10.1.4</b> Modelo asumido, modelo ajustado</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#explicación-versus-predicción"><i class="fa fa-check"></i><b>10.2</b> Explicación versus predicción</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#explicación"><i class="fa fa-check"></i><b>10.2.1</b> Explicación</a></li>
<li class="chapter" data-level="10.2.2" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#predicción"><i class="fa fa-check"></i><b>10.2.2</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="construcción-del-modelo.html"><a href="construcción-del-modelo.html#resumen"><i class="fa fa-check"></i><b>10.3</b> Resumen</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html"><i class="fa fa-check"></i><b>11</b> Interacciones y predictores categóricos</a>
<ul>
<li class="chapter" data-level="11.1" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#variables-ficticias-dummy"><i class="fa fa-check"></i><b>11.1</b> Variables ficticias (Dummy)</a></li>
<li class="chapter" data-level="11.2" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#interacciones"><i class="fa fa-check"></i><b>11.2</b> Interacciones</a></li>
<li class="chapter" data-level="11.3" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#variables-factor"><i class="fa fa-check"></i><b>11.3</b> Variables factor</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#factores-con-más-de-dos-niveles"><i class="fa fa-check"></i><b>11.3.1</b> Factores con más de dos niveles</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#parametrización"><i class="fa fa-check"></i><b>11.4</b> Parametrización</a></li>
<li class="chapter" data-level="11.5" data-path="interacciones-y-predictores-categóricos.html"><a href="interacciones-y-predictores-categóricos.html#construcción-de-modelos-más-grandes"><i class="fa fa-check"></i><b>11.5</b> Construcción de modelos más grandes</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html"><i class="fa fa-check"></i><b>12</b> Análisis de varianza</a>
<ul>
<li class="chapter" data-level="12.1" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#experimentos"><i class="fa fa-check"></i><b>12.1</b> Experimentos</a></li>
<li class="chapter" data-level="12.2" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#prueba-t-de-dos-muestras"><i class="fa fa-check"></i><b>12.2</b> Prueba t de dos muestras</a></li>
<li class="chapter" data-level="12.3" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#anova-de-una-vía"><i class="fa fa-check"></i><b>12.3</b> ANOVA de una vía</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#variables-factor-1"><i class="fa fa-check"></i><b>12.3.1</b> Variables factor</a></li>
<li class="chapter" data-level="12.3.2" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#algo-de-simulación"><i class="fa fa-check"></i><b>12.3.2</b> Algo de simulación</a></li>
<li class="chapter" data-level="12.3.3" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#potencia"><i class="fa fa-check"></i><b>12.3.3</b> Potencia</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#pruebas-post-hoc"><i class="fa fa-check"></i><b>12.4</b> Pruebas Post Hoc</a></li>
<li class="chapter" data-level="12.5" data-path="análisis-de-varianza.html"><a href="análisis-de-varianza.html#anova-de-dos-vías"><i class="fa fa-check"></i><b>12.5</b> ANOVA de dos vías</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html"><i class="fa fa-check"></i><b>13</b> Diagnóstico de modelos</a>
<ul>
<li class="chapter" data-level="13.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#supuestos-del-modelo"><i class="fa fa-check"></i><b>13.1</b> Supuestos del modelo</a></li>
<li class="chapter" data-level="13.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#comprobación-de-supuestos"><i class="fa fa-check"></i><b>13.2</b> Comprobación de supuestos</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#gráfica-de-ajustados-versus-residuos"><i class="fa fa-check"></i><b>13.2.1</b> Gráfica de ajustados versus residuos</a></li>
<li class="chapter" data-level="13.2.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#prueba-de-breusch-pagan"><i class="fa fa-check"></i><b>13.2.2</b> Prueba de Breusch-Pagan</a></li>
<li class="chapter" data-level="13.2.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#histogramas-1"><i class="fa fa-check"></i><b>13.2.3</b> Histogramas</a></li>
<li class="chapter" data-level="13.2.4" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#gráficos-q-q"><i class="fa fa-check"></i><b>13.2.4</b> Gráficos Q-Q</a></li>
<li class="chapter" data-level="13.2.5" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#prueba-de-shapiro-wilk"><i class="fa fa-check"></i><b>13.2.5</b> Prueba de Shapiro-Wilk</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#observaciones-inusuales"><i class="fa fa-check"></i><b>13.3</b> Observaciones inusuales</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#apalancamiento"><i class="fa fa-check"></i><b>13.3.1</b> Apalancamiento</a></li>
<li class="chapter" data-level="13.3.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#valores-atípicos"><i class="fa fa-check"></i><b>13.3.2</b> Valores atípicos</a></li>
<li class="chapter" data-level="13.3.3" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#influencia"><i class="fa fa-check"></i><b>13.3.3</b> Influencia</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#ejemplos-de-análisis-de-datos"><i class="fa fa-check"></i><b>13.4</b> Ejemplos de análisis de datos</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#buenos-diagnósticos"><i class="fa fa-check"></i><b>13.4.1</b> Buenos diagnósticos</a></li>
<li class="chapter" data-level="13.4.2" data-path="diagnóstico-de-modelos.html"><a href="diagnóstico-de-modelos.html#diagnóstico-sospechoso"><i class="fa fa-check"></i><b>13.4.2</b> Diagnóstico sospechoso</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="transformaciones.html"><a href="transformaciones.html"><i class="fa fa-check"></i><b>14</b> Transformaciones</a>
<ul>
<li class="chapter" data-level="14.1" data-path="transformaciones.html"><a href="transformaciones.html#transformación-de-respuesta"><i class="fa fa-check"></i><b>14.1</b> Transformación de respuesta</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-estabilizadoras-de-varianza"><i class="fa fa-check"></i><b>14.1.1</b> Transformaciones estabilizadoras de varianza</a></li>
<li class="chapter" data-level="14.1.2" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-box-cox"><i class="fa fa-check"></i><b>14.1.2</b> Transformaciones de Box-Cox</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="transformaciones.html"><a href="transformaciones.html#transformación-del-predictor"><i class="fa fa-check"></i><b>14.2</b> Transformación del predictor</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="transformaciones.html"><a href="transformaciones.html#polinomios"><i class="fa fa-check"></i><b>14.2.1</b> Polinomios</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-respuesta"><i class="fa fa-check"></i>Transformaciones de respuesta</a></li>
<li class="chapter" data-level="" data-path="transformaciones.html"><a href="transformaciones.html#transformaciones-de-predictores"><i class="fa fa-check"></i>Transformaciones de predictores</a>
<ul>
<li class="chapter" data-level="14.2.2" data-path="transformaciones.html"><a href="transformaciones.html#un-modelo-cuadrático"><i class="fa fa-check"></i><b>14.2.2</b> Un modelo cuadrático</a></li>
<li class="chapter" data-level="14.2.3" data-path="transformaciones.html"><a href="transformaciones.html#sobreajuste-y-extrapolación"><i class="fa fa-check"></i><b>14.2.3</b> Sobreajuste y extrapolación</a></li>
<li class="chapter" data-level="14.2.4" data-path="transformaciones.html"><a href="transformaciones.html#comparación-de-modelos-polinomiales"><i class="fa fa-check"></i><b>14.2.4</b> Comparación de modelos polinomiales</a></li>
<li class="chapter" data-level="14.2.5" data-path="transformaciones.html"><a href="transformaciones.html#poly-función-y-polinomios-ortogonales"><i class="fa fa-check"></i><b>14.2.5</b> <code>poly()</code> Función y polinomios ortogonales</a></li>
<li class="chapter" data-level="14.2.6" data-path="transformaciones.html"><a href="transformaciones.html#función-de-inhibición"><i class="fa fa-check"></i><b>14.2.6</b> Función de inhibición</a></li>
<li class="chapter" data-level="14.2.7" data-path="transformaciones.html"><a href="transformaciones.html#ejemplo-con-datos"><i class="fa fa-check"></i><b>14.2.7</b> Ejemplo con datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="colinealidad.html"><a href="colinealidad.html"><i class="fa fa-check"></i><b>15</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="15.1" data-path="colinealidad.html"><a href="colinealidad.html#colinealidad-exacta"><i class="fa fa-check"></i><b>15.1</b> Colinealidad exacta</a></li>
<li class="chapter" data-level="15.2" data-path="colinealidad.html"><a href="colinealidad.html#colinealidad-1"><i class="fa fa-check"></i><b>15.2</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="colinealidad.html"><a href="colinealidad.html#factor-de-inflación-de-la-varianza."><i class="fa fa-check"></i><b>15.2.1</b> Factor de inflación de la varianza.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="colinealidad.html"><a href="colinealidad.html#simulación-2"><i class="fa fa-check"></i><b>15.3</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html"><i class="fa fa-check"></i><b>16</b> Selección de variables y construcción de modelos</a>
<ul>
<li class="chapter" data-level="16.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-calidad"><i class="fa fa-check"></i><b>16.1</b> Criterio de calidad</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-información-de-akaike"><i class="fa fa-check"></i><b>16.1.1</b> Criterio de información de Akaike</a></li>
<li class="chapter" data-level="16.1.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#criterio-de-información-bayesiano"><i class="fa fa-check"></i><b>16.1.2</b> Criterio de información Bayesiano</a></li>
<li class="chapter" data-level="16.1.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#r-cuadrado-ajustado"><i class="fa fa-check"></i><b>16.1.3</b> R cuadrado ajustado</a></li>
<li class="chapter" data-level="16.1.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#rmse-con-validación-cruzada"><i class="fa fa-check"></i><b>16.1.4</b> RMSE con validación cruzada</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#procedimientos-de-selección"><i class="fa fa-check"></i><b>16.2</b> Procedimientos de selección</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-hacia-atrás-backward"><i class="fa fa-check"></i><b>16.2.1</b> Búsqueda hacia atrás (Backward)</a></li>
<li class="chapter" data-level="16.2.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-hacia-adelante-forward"><i class="fa fa-check"></i><b>16.2.2</b> Búsqueda hacia adelante (Forward)</a></li>
<li class="chapter" data-level="16.2.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-por-pasos-stepwise"><i class="fa fa-check"></i><b>16.2.3</b> Búsqueda por pasos (Stepwise)</a></li>
<li class="chapter" data-level="16.2.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#búsqueda-exhaustiva"><i class="fa fa-check"></i><b>16.2.4</b> Búsqueda exhaustiva</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#términos-de-orden-superior"><i class="fa fa-check"></i><b>16.3</b> Términos de orden superior</a></li>
<li class="chapter" data-level="16.4" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#explicación-versus-predicción-1"><i class="fa fa-check"></i><b>16.4</b> Explicación versus predicción</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#explicación-1"><i class="fa fa-check"></i><b>16.4.1</b> Explicación</a></li>
<li class="chapter" data-level="16.4.2" data-path="selección-de-variables-y-construcción-de-modelos.html"><a href="selección-de-variables-y-construcción-de-modelos.html#predicción-1"><i class="fa fa-check"></i><b>16.4.2</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>17</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="17.1" data-path="regresión-logística.html"><a href="regresión-logística.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>17.1</b> Modelos lineales generalizados</a></li>
<li class="chapter" data-level="17.2" data-path="regresión-logística.html"><a href="regresión-logística.html#respuesta-binaria"><i class="fa fa-check"></i><b>17.2</b> Respuesta binaria</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="regresión-logística.html"><a href="regresión-logística.html#ajuste-de-la-regresión-logística"><i class="fa fa-check"></i><b>17.2.1</b> Ajuste de la regresión logística</a></li>
<li class="chapter" data-level="17.2.2" data-path="regresión-logística.html"><a href="regresión-logística.html#problemas-de-ajuste"><i class="fa fa-check"></i><b>17.2.2</b> Problemas de ajuste</a></li>
<li class="chapter" data-level="17.2.3" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplos-de-simulación"><i class="fa fa-check"></i><b>17.2.3</b> Ejemplos de simulación</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="regresión-logística.html"><a href="regresión-logística.html#trabajar-con-regresión-logística"><i class="fa fa-check"></i><b>17.3</b> Trabajar con regresión logística</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="regresión-logística.html"><a href="regresión-logística.html#pruebas-con-glms"><i class="fa fa-check"></i><b>17.3.1</b> Pruebas con GLMs</a></li>
<li class="chapter" data-level="17.3.2" data-path="regresión-logística.html"><a href="regresión-logística.html#prueba-de-wald"><i class="fa fa-check"></i><b>17.3.2</b> Prueba de Wald</a></li>
<li class="chapter" data-level="17.3.3" data-path="regresión-logística.html"><a href="regresión-logística.html#prueba-de-razón-de-verosimilitud"><i class="fa fa-check"></i><b>17.3.3</b> Prueba de razón de verosimilitud</a></li>
<li class="chapter" data-level="17.3.4" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-saheart"><i class="fa fa-check"></i><b>17.3.4</b> Ejemplo <code>SAheart</code></a></li>
<li class="chapter" data-level="17.3.5" data-path="regresión-logística.html"><a href="regresión-logística.html#intervalos-de-confianza-1"><i class="fa fa-check"></i><b>17.3.5</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="17.3.6" data-path="regresión-logística.html"><a href="regresión-logística.html#intervalos-de-confianza-para-la-respuesta-promedio"><i class="fa fa-check"></i><b>17.3.6</b> Intervalos de confianza para la respuesta promedio</a></li>
<li class="chapter" data-level="17.3.7" data-path="regresión-logística.html"><a href="regresión-logística.html#sintaxis-de-la-fórmula"><i class="fa fa-check"></i><b>17.3.7</b> Sintaxis de la fórmula</a></li>
<li class="chapter" data-level="17.3.8" data-path="regresión-logística.html"><a href="regresión-logística.html#desviación"><i class="fa fa-check"></i><b>17.3.8</b> Desviación</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="regresión-logística.html"><a href="regresión-logística.html#clasificación"><i class="fa fa-check"></i><b>17.4</b> Clasificación</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-spam"><i class="fa fa-check"></i><b>17.4.1</b> Ejemplo <code>spam</code></a></li>
<li class="chapter" data-level="17.4.2" data-path="regresión-logística.html"><a href="regresión-logística.html#evaluar-clasificadores"><i class="fa fa-check"></i><b>17.4.2</b> Evaluar clasificadores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="más-allá.html"><a href="más-allá.html"><i class="fa fa-check"></i><b>18</b> Más allá</a>
<ul>
<li class="chapter" data-level="18.1" data-path="más-allá.html"><a href="más-allá.html#rstudio"><i class="fa fa-check"></i><b>18.1</b> RStudio</a></li>
<li class="chapter" data-level="18.2" data-path="más-allá.html"><a href="más-allá.html#tidy-data"><i class="fa fa-check"></i><b>18.2</b> Tidy Data</a></li>
<li class="chapter" data-level="18.3" data-path="más-allá.html"><a href="más-allá.html#visualización"><i class="fa fa-check"></i><b>18.3</b> Visualización</a></li>
<li class="chapter" data-level="18.4" data-path="más-allá.html"><a href="más-allá.html#aplicaciones-web"><i class="fa fa-check"></i><b>18.4</b> Aplicaciones web</a></li>
<li class="chapter" data-level="18.5" data-path="más-allá.html"><a href="más-allá.html#diseño-experimental"><i class="fa fa-check"></i><b>18.5</b> Diseño experimental</a></li>
<li class="chapter" data-level="18.6" data-path="más-allá.html"><a href="más-allá.html#aprendizaje-automático-machine-learning"><i class="fa fa-check"></i><b>18.6</b> Aprendizaje automático (Machine Learning)</a>
<ul>
<li class="chapter" data-level="18.6.1" data-path="más-allá.html"><a href="más-allá.html#aprendizaje-profundo-deep-learning"><i class="fa fa-check"></i><b>18.6.1</b> Aprendizaje profundo (Deep Learning)</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="más-allá.html"><a href="más-allá.html#series-de-tiempo"><i class="fa fa-check"></i><b>18.7</b> Series de tiempo</a></li>
<li class="chapter" data-level="18.8" data-path="más-allá.html"><a href="más-allá.html#bayesiana"><i class="fa fa-check"></i><b>18.8</b> Bayesiana</a></li>
<li class="chapter" data-level="18.9" data-path="más-allá.html"><a href="más-allá.html#computación-de-alto-rendimiento."><i class="fa fa-check"></i><b>18.9</b> Computación de alto rendimiento.</a></li>
<li class="chapter" data-level="18.10" data-path="más-allá.html"><a href="más-allá.html#recursos-adicionales-de-r"><i class="fa fa-check"></i><b>18.10</b> Recursos adicionales de <code>R</code></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/appliedstats" target="blank">&copy; 2020 Adapatado de David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística aplicada con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="selección-de-variables-y-construcción-de-modelos" class="section level1" number="16">
<h1><span class="header-section-number">Capítulo 16</span> Selección de variables y construcción de modelos</h1>
<blockquote>
<p>“Elige bien. Tu elección es breve y, sin embargo, interminable.”</p>
<p>— <strong>Johann Wolfgang von Goethe</strong></p>
</blockquote>
<p>Después de leer este capítulo, podrá:</p>
<ul>
<li>Comprender el equilibrio entre bondad de ajuste y complejidad del modelo.</li>
<li>Utilizar procedimientos de selección de variables para encontrar un buen modelo a partir de un conjunto de modelos posibles.</li>
<li>Comprender los dos usos de los modelos: explicación y predicción.</li>
</ul>
<p>En el capítulo anterior vimos cómo la correlación entre las variables predictoras puede tener efectos indeseables en los modelos. Usamos factores de inflación de la varianza para evaluar la gravedad de los problemas de colinealidad causados por estas correlaciones. También vimos cómo ajustar un modelo más pequeño, dejando de lado algunos de los predictores correlacionados, da como resultado un modelo que ya no sufre problemas de colinealidad. Pero, ¿cómo elegir este modelo más pequeño?</p>
<p>En este capítulo, discutiremos varios <em>criterios</em> y <em>procedimientos</em> para elegir un modelo “bueno” de entre muchos.</p>
<div id="criterio-de-calidad" class="section level2" number="16.1">
<h2><span class="header-section-number">16.1</span> Criterio de calidad</h2>
<p>Hasta ahora, hemos visto criterios como el <span class="math inline">\(R^2\)</span> y <span class="math inline">\(\text{RMSE}\)</span> para evaluar la calidad de ajuste. Sin embargo, ambos tienen un defecto fatal. Al aumentar el tamaño de un modelo, se agregan predictores que, en el peor de los casos, no pueden mejorar. Es imposible agregar un predictor a un modelo y empeorar el <span class="math inline">\(R^2\)</span> o <span class="math inline">\(\text{RMSE}\)</span>. Eso significa que, si usáramos cualquiera de estos para elegir entre modelos, <em>siempre</em> simplemente elegiríamos el modelo más grande. Con el tiempo, simplemente estaríamos adaptados al ruido.</p>
<p>Esto sugiere que necesitamos un criterio de calidad que tenga en cuenta el tamaño del modelo, ya que nuestra preferencia es por modelos pequeños que encajan bien. Estamos dispuestos a sacrificar una pequeña cantidad de “bondad de ajuste” para obtener un modelo más pequeño. (Aquí usamos “bondad de ajuste” para significar simplemente qué tan lejos están los datos del modelo, cuanto más pequeños sean los errores, mejor. A menudo, en la estadística, bondad de ajuste puede tener un significado más preciso), en tres criterios que hacen esto explícitamente: <span class="math inline">\(\text{AIC}\)</span>, <span class="math inline">\(\text{BIC}\)</span> y <span class="math inline">\(R^2\)</span> ajustados. También veremos uno, <span class="math inline">\(\text{RMSE}\)</span> con validación cruzada, que considera implícitamente el tamaño del modelo.</p>
<div id="criterio-de-información-de-akaike" class="section level3" number="16.1.1">
<h3><span class="header-section-number">16.1.1</span> Criterio de información de Akaike</h3>
<p>El primer criterio que discutiremos es el Criterio de información de Akaike, o <span class="math inline">\(\text{AIC}\)</span> para abreviar. (Tenga en cuenta que, cuando <em>Akaike</em> introdujo por primera vez esta métrica, simplemente se llamó <em>Un</em> Criterio de información.</p>
<p>Recuerde, la log-verosimilitud maximizada de un modelo de regresión se puede escribir como</p>
<p><span class="math display">\[
\log L(\boldsymbol{\hat{\beta}}, \hat{\sigma}^2) = -\frac{n}{2}\log(2\pi) - \frac{n}{2}\log\left(\frac{\text{RSS}}{n}\right) - \frac{n}{2},
\]</span></p>
<p>donde <span class="math inline">\(\text{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i) ^ 2\)</span>, <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span> y <span class="math inline">\(\hat{\sigma}^2\)</span> fueron elegidos para maximizar la verosimilitud.</p>
<p>Entonces podemos definir <span class="math inline">\(\text{AIC}\)</span> como</p>
<p><span class="math display">\[
\text{AIC} = -2 \log L(\boldsymbol{\hat{\beta}}, \hat{\sigma}^2) + 2p = n + n \log(2\pi) + n \log\left(\frac{\text{RSS}}{n}\right) + 2p,
\]</span></p>
<p>que es una medida de calidad del modelo. Cuanto menor sea el <span class="math inline">\(\text{AIC}\)</span>, mejor. Para ver por qué, hablemos de los dos componentes principales de <span class="math inline">\(\text{AIC}\)</span>, la <strong>verosimilitud</strong> (que mide la “bondad de ajuste”) y la <strong>penalización</strong> (que es una función de el tamaño del modelo).</p>
<p>La parte de verosimilitud de <span class="math inline">\(\text{AIC}\)</span> es dada por</p>
<p><span class="math display">\[
-2 \log L(\boldsymbol{\hat{\beta}}, \hat{\sigma}^2) = n + n \log(2\pi) + n \log\left(\frac{\text{RSS}}{n}\right).
\]</span></p>
<p>Para comparar modelos, el único término que cambiará es <span class="math inline">\(n \log\left(\frac{\text{RSS}}{n}\right)\)</span>, que es función de <span class="math inline">\(\text{RSS}\)</span>.</p>
<p><span class="math display">\[
n + n \log(2\pi)
\]</span></p>
<p>los términos serán constantes en todos los modelos aplicados a los mismos datos. Entonces, cuando un modelo se ajusta bien, es decir, tiene un <span class="math inline">\(\text{RSS}\)</span> bajo, entonces este componente de verosimilitud será pequeño.</p>
<p>De manera similar, podemos discutir el componente de penalización de <span class="math inline">\(\text{AIC}\)</span> que es,</p>
<p><span class="math display">\[
2p,
\]</span></p>
<p>donde <span class="math inline">\(p\)</span> es el número de parámetros <span class="math inline">\(\beta\)</span> en el modelo. A esto lo llamamos penalización, porque es grande cuando <span class="math inline">\(p\)</span> es grande, pero buscamos encontrar un <span class="math inline">\(\text{AIC}\)</span> pequeño.</p>
<p>Por lo tanto, un buen modelo, es decir, uno con un <span class="math inline">\(\text{AIC}\)</span> pequeño, tendrá un buen equilibrio entre un buen ajuste y el uso de una pequeña cantidad de parámetros. Para comparar modelos</p>
<p><span class="math display">\[
\text{AIC} = n\log\left(\frac{\text{RSS}}{n}\right) + 2p
\]</span></p>
<p>es una expresión suficiente, ya que <span class="math inline">\(n + n \log(2\pi)\)</span> es el mismo en todos los modelos para cualquier conjunto de datos en particular.</p>
</div>
<div id="criterio-de-información-bayesiano" class="section level3" number="16.1.2">
<h3><span class="header-section-number">16.1.2</span> Criterio de información Bayesiano</h3>
<p>El criterio de información Bayesiano, o <span class="math inline">\(\text{BIC}\)</span>, es similar a <span class="math inline">\(\text{AIC}\)</span>, pero tiene una penalización mayor. <span class="math inline">\(\text{BIC}\)</span> también cuantifica la compensación entre un modelo que se ajusta bien y el número de parámetros del modelo, sin embargo, para un tamaño de muestra razonable, generalmente elige un modelo más pequeño que <span class="math inline">\(\text{AIC}\)</span>. Nuevamente, para la selección del modelo, use el modelo con el <span class="math inline">\(\text{BIC}\)</span> más pequeño.</p>
<p><span class="math display">\[
\text{BIC} = -2 \log L(\boldsymbol{\hat{\beta}}, \hat{\sigma}^2) + \log(n) p = n + n\log(2\pi) + n\log\left(\frac{\text{RSS}}{n}\right) + \log(n)p.
\]</span></p>
<p>Observe que la penalización de <span class="math inline">\(\text{AIC}\)</span> fue</p>
<p><span class="math display">\[
2p,
\]</span></p>
<p>mientras que para <span class="math inline">\(\text{BIC}\)</span>, la penalización es</p>
<p><span class="math display">\[
\log(n) p.
\]</span></p>
<p>Entonces, para cualquier conjunto de datos donde <span class="math inline">\(log(n)&gt; 2\)</span>, la penalización de <span class="math inline">\(\text{BIC}\)</span> será mayor que la penalización de <span class="math inline">\(\text{AIC}\)</span>, por lo que <span class="math inline">\(\text{BIC}\)</span> probablemente preferirá un modelo pequeño.</p>
<p>Tenga en cuenta que, a veces, la penalización se considera una expresión general de la forma</p>
<p><span class="math display">\[
k \cdot p.
\]</span></p>
<p>Entonces, para <span class="math inline">\(\text{AIC}\)</span> <span class="math inline">\(k=2\)</span>, y para <span class="math inline">\(\text{BIC}\)</span> <span class="math inline">\(k=\log(n)\)</span>.</p>
<p>Para comparar modelos</p>
<p><span class="math display">\[
\text{BIC} = n\log\left(\frac{\text{RSS}}{n}\right) + \log(n)p
\]</span></p>
<p>es nuevamente una expresión suficiente, ya que <span class="math inline">\(n + n \log(2\pi)\)</span> es el mismo en todos los modelos para cualquier conjunto de datos en particular.</p>
</div>
<div id="r-cuadrado-ajustado" class="section level3" number="16.1.3">
<h3><span class="header-section-number">16.1.3</span> R cuadrado ajustado</h3>
<p>Recordemos que,</p>
<p><span class="math display">\[
R^2 = 1 - \frac{\text{SSE}}{\text{SST}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}.
\]</span></p>
<p>Ahora definimos</p>
<p><span class="math display">\[
R_a^2 = 1 - \frac{\text{SSE}/(n-p)}{\text{SST}/(n-1)} = 1 - \left(  \frac{n-1}{n-p} \right)(1-R^2)
\]</span></p>
<p>Lo que llamamos el <span class="math inline">\(R^2\)</span> ajustado.</p>
<p>A diferencia del <span class="math inline">\(R^2\)</span>, que nunca puede reducirse con predictores agregados, el <span class="math inline">\(R^2\)</span> ajustado penaliza efectivamente los predictores adicionales y puede disminuir con predictores adicionales. Al igual que el <span class="math inline">\(R^2\)</span>, cuanto más grande, mejor.</p>
</div>
<div id="rmse-con-validación-cruzada" class="section level3" number="16.1.4">
<h3><span class="header-section-number">16.1.4</span> RMSE con validación cruzada</h3>
<p>Cada una de las tres métricas anteriores utilizó explícitamente <span class="math inline">\(p\)</span>, el número de parámetros, en sus cálculos. Por lo tanto, todos ellos limitan explícitamente el tamaño de los modelos elegidos cuando se utilizan para comparar modelos.</p>
<p>Ahora presentaremos brevemente <strong>sobreajuste</strong> y <strong>validación cruzada</strong>.</p>
<div class="sourceCode" id="cb1278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1278-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1278-1" aria-hidden="true" tabindex="-1"></a>make_poly_data <span class="ot">=</span> <span class="cf">function</span>(<span class="at">sample_size =</span> <span class="dv">11</span>) {</span>
<span id="cb1278-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1278-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb1278-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1278-3" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">=</span> <span class="dv">3</span> <span class="sc">+</span> x <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> x <span class="sc">^</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> sample_size, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">20</span>)</span>
<span id="cb1278-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1278-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(x, y)</span>
<span id="cb1278-5"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1278-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb1279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1279-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1279-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb1279-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1279-2" aria-hidden="true" tabindex="-1"></a>poly_data <span class="ot">=</span> <span class="fu">make_poly_data</span>()</span></code></pre></div>
<p>Aquí hemos generado datos donde la media de <span class="math inline">\(Y\)</span> es una función cuadrática de un solo predictor <span class="math inline">\(x\)</span>, específicamente,</p>
<p><span class="math display">\[
Y = 3 + x + 4 x ^ 2 + \epsilon.
\]</span></p>
<p>Ahora ajustaremos dos modelos a estos datos, uno que tiene la forma correcta, cuadrática, y otro que es grande, que incluye términos hasta un octavo grado inclusive.</p>
<div class="sourceCode" id="cb1280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1280-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1280-1" aria-hidden="true" tabindex="-1"></a>fit_quad <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="at">degree =</span> <span class="dv">2</span>), <span class="at">data =</span> poly_data)</span>
<span id="cb1280-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1280-2" aria-hidden="true" tabindex="-1"></a>fit_big  <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="at">degree =</span> <span class="dv">8</span>), <span class="at">data =</span> poly_data)</span></code></pre></div>
<p>Luego graficamos los datos y los resultados de los dos modelos.</p>
<div class="sourceCode" id="cb1281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1281-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> poly_data, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>, <span class="dv">400</span>), <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">20</span>)</span>
<span id="cb1281-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-2" aria-hidden="true" tabindex="-1"></a>xplot <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb1281-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xplot, <span class="fu">predict</span>(fit_quad, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> xplot)),</span>
<span id="cb1281-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb1281-5"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xplot, <span class="fu">predict</span>(fit_big, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> xplot)),</span>
<span id="cb1281-6"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1281-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-604-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Podemos ver que la curva azul sólida modela estos datos bastante bien. La curva naranja discontinua se ajusta mejor a los puntos y comete errores más pequeños; sin embargo, es poco probable que esté modelando correctamente la verdadera relación entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>. Se ajusta al ruido aleatorio. Este es un ejemplo de <strong>sobreajuste</strong>.</p>
<p>Vemos que el modelo más grande de hecho tiene un menor <span class="math inline">\(\text{RMSE}\)</span>.</p>
<div class="sourceCode" id="cb1282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1282-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(<span class="fu">resid</span>(fit_quad) <span class="sc">^</span> <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 17.61812</code></pre>
<div class="sourceCode" id="cb1284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1284-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1284-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(<span class="fu">resid</span>(fit_big) <span class="sc">^</span> <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 10.4197</code></pre>
<p>Para corregir esto, introduciremos la validación cruzada. Definimos el RMSE de validación cruzada leave-one-out como</p>
<p><span class="math display">\[
\text{RMSE}_{\text{LOOCV}} = \sqrt{\frac{1}{n} \sum_{i=1}^n e_{[i]}^2}.
\]</span></p>
<p>Los <span class="math inline">\(e_{[i]}\)</span> son el residuo de la <span class="math inline">\(i\)</span>-ésima observación, cuando esa observación <strong>no</strong> se utiliza para ajustar el modelo.</p>
<p><span class="math display">\[
e_{[i]} = y_{i} - \hat{y}_{[i]}
\]</span></p>
<p>Es decir, el valor ajustado se calcula como</p>
<p><span class="math display">\[
\hat{y}_{[i]} = \boldsymbol{x}_i ^ \top \hat{\beta}_{[i]}
\]</span></p>
<p>donde <span class="math inline">\(\hat{\beta}_{[i]}\)</span> son los coeficientes estimados cuando la <span class="math inline">\(i\)</span>-ésima observación se elimina del conjunto de datos.</p>
<p>En general, para realizar este cálculo, tendríamos que ajustar el modelo <span class="math inline">\(n\)</span> veces, una vez con cada posible observación eliminada. Sin embargo, para modelos lineales y de validación cruzada leave-one-out, la ecuación se puede reescribir como</p>
<p><span class="math display">\[
\text{RMSE}_{\text{LOOCV}} = \sqrt{\frac{1}{n}\sum_{i=1}^n \left(\frac{e_{i}}{1-h_{i}}\right)^2},
\]</span></p>
<p>donde <span class="math inline">\(h_i\)</span> son los apalancamientos y <span class="math inline">\(e_i\)</span> son los residuos habituales. ¡Esto es genial, porque ahora podemos obtener LOOCV <span class="math inline">\(\text{RMSE}\)</span> ajustando solo un modelo! En la práctica, la validación cruzada de 5 o 10 veces es mucho más popular. Por ejemplo, en la validación cruzada de 5 veces, el modelo se ajusta 5 veces, cada vez se omite una quinta parte de los datos y luego se predice sobre esos valores. Dejaremos el examen en profundidad de la validación cruzada a un curso de aprendizaje automático y simplemente usaremos LOOCV aquí.</p>
<p>Calculemos LOOCV <span class="math inline">\(\text{RMSE}\)</span> para ambos modelos, luego analicemos <em>por qué</em> queremos hacerlo. Primero escribimos una función que calcula LOOCV <span class="math inline">\(\text{RMSE}\)</span> como se define usando la fórmula de acceso directo para modelos lineales.</p>
<div class="sourceCode" id="cb1286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1286-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1286-1" aria-hidden="true" tabindex="-1"></a>calc_loocv_rmse <span class="ot">=</span> <span class="cf">function</span>(model) {</span>
<span id="cb1286-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1286-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">mean</span>((<span class="fu">resid</span>(model) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">hatvalues</span>(model))) <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb1286-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1286-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Luego calcule la métrica para ambos modelos.</p>
<div class="sourceCode" id="cb1287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1287-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1287-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(fit_quad)</span></code></pre></div>
<pre><code>## [1] 23.57189</code></pre>
<div class="sourceCode" id="cb1289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1289-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1289-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(fit_big)</span></code></pre></div>
<pre><code>## [1] 1334.357</code></pre>
<p>Ahora vemos que el modelo cuadrático tiene un LOOCV <span class="math inline">\(\text{RMSE}\)</span> mucho más pequeño, por lo que preferiríamos este modelo. Esto se debe a que el modelo grande ha sobreajustado <em>gravemente</em> los datos. Al dejar un solo punto de datos y ajustar el modelo grande, el ajuste resultante es muy diferente al ajuste utilizando todos los datos. Por ejemplo, dejemos fuera el tercer punto de datos y ajustemos ambos modelos, luego tracemos el resultado.</p>
<div class="sourceCode" id="cb1291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1291-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-1" aria-hidden="true" tabindex="-1"></a>fit_quad_removed <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="at">degree =</span> <span class="dv">2</span>), <span class="at">data =</span> poly_data[<span class="sc">-</span><span class="dv">3</span>, ])</span>
<span id="cb1291-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-2" aria-hidden="true" tabindex="-1"></a>fit_big_removed  <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="at">degree =</span> <span class="dv">8</span>), <span class="at">data =</span> poly_data[<span class="sc">-</span><span class="dv">3</span>, ])</span>
<span id="cb1291-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1291-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> poly_data, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>, <span class="dv">400</span>), <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">20</span>)</span>
<span id="cb1291-5"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-5" aria-hidden="true" tabindex="-1"></a>xplot <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb1291-6"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xplot, <span class="fu">predict</span>(fit_quad_removed, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> xplot)),</span>
<span id="cb1291-7"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb1291-8"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xplot, <span class="fu">predict</span>(fit_big_removed, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> xplot)),</span>
<span id="cb1291-9"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1291-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-608-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Vemos que, en promedio, la línea azul sólida para el modelo cuadrático tiene errores similares a los de antes. Ha cambiado muy levemente. Sin embargo, la línea naranja discontinua para el modelo grande tiene un gran error en el punto que se eliminó y es muy diferente al ajuste anterior.</p>
<p>Este es el propósito de la validación cruzada. Al evaluar cómo el modelo se ajusta a los puntos que no se utilizaron para realizar la regresión, tenemos una idea de qué tan bien funcionará el modelo para las observaciones futuras. Evalúa qué tan bien funciona el modelo en general, no simplemente en los datos observados.</p>
</div>
</div>
<div id="procedimientos-de-selección" class="section level2" number="16.2">
<h2><span class="header-section-number">16.2</span> Procedimientos de selección</h2>
<p>Ahora hemos visto una serie de criterios de calidad del modelo, pero ahora debemos abordar qué modelos considerar. La selección del modelo implica tanto un criterio de calidad como un procedimiento de búsqueda.</p>
<div class="sourceCode" id="cb1292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1292-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faraway)</span>
<span id="cb1292-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1292-2" aria-hidden="true" tabindex="-1"></a>hipcenter_mod <span class="ot">=</span> <span class="fu">lm</span>(hipcenter <span class="sc">~</span> ., <span class="at">data =</span> seatpos)</span>
<span id="cb1292-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1292-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(hipcenter_mod)</span></code></pre></div>
<pre><code>##  (Intercept)          Age       Weight      HtShoes           Ht       Seated 
## 436.43212823   0.77571620   0.02631308  -2.69240774   0.60134458   0.53375170 
##          Arm        Thigh          Leg 
##  -1.32806864  -1.14311888  -6.43904627</code></pre>
<p>Regresemos a los datos de <code>seatpos</code> del paquete <code>faraway</code>. Ahora, consideremos solo modelos con términos de primer orden, por lo tanto, sin interacciones ni polinomios. Hay <em>ocho</em> predictores en este modelo. Entonces, si consideramos todos los modelos posibles, que van desde el uso de 0 predictores hasta los ocho predictores, hay</p>
<p><span class="math display">\[
\sum_{k = 0}^{p - 1} {{p - 1} \choose {k}} = 2 ^ {p - 1} = 2 ^ 8 = 256
\]</span></p>
<p>posibles modelos.</p>
<p>Si tuviéramos 10 o más predictores, ¡ya estaríamos considerando más de 1000 modelos! Por esta razón, a menudo buscamos a través de posibles modelos de una manera inteligente, pasando por alto algunos modelos que es poco probable que se consideren buenos. Consideraremos tres procedimientos de búsqueda: hacia atrás, hacia adelante y paso a paso.</p>
<div id="búsqueda-hacia-atrás-backward" class="section level3" number="16.2.1">
<h3><span class="header-section-number">16.2.1</span> Búsqueda hacia atrás (Backward)</h3>
<p>Los procedimientos de selección hacia atrás comienzan con todos los posibles predictores en el modelo, luego consideran cómo la eliminación de un solo predictor afectará una métrica elegida. Probemos esto con los datos <code>seatpos</code>. Usaremos la función <code>step()</code> en <code>R</code> que por defecto usa <span class="math inline">\(\text{AIC}\)</span> como su métrica de elección.</p>
<div class="sourceCode" id="cb1294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1294-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1294-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_back_aic <span class="ot">=</span> <span class="fu">step</span>(hipcenter_mod, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=283.62
## hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + 
##     Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Ht       1      5.01 41267 281.63
## - Weight   1      8.99 41271 281.63
## - Seated   1     28.64 41290 281.65
## - HtShoes  1    108.43 41370 281.72
## - Arm      1    164.97 41427 281.78
## - Thigh    1    262.76 41525 281.87
## &lt;none&gt;                 41262 283.62
## - Age      1   2632.12 43894 283.97
## - Leg      1   2654.85 43917 283.99
## 
## Step:  AIC=281.63
## hipcenter ~ Age + Weight + HtShoes + Seated + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Weight   1     11.10 41278 279.64
## - Seated   1     30.52 41297 279.66
## - Arm      1    160.50 41427 279.78
## - Thigh    1    269.08 41536 279.88
## - HtShoes  1    971.84 42239 280.51
## &lt;none&gt;                 41267 281.63
## - Leg      1   2664.65 43931 282.01
## - Age      1   2808.52 44075 282.13
## 
## Step:  AIC=279.64
## hipcenter ~ Age + HtShoes + Seated + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Seated   1     35.10 41313 277.67
## - Arm      1    156.47 41434 277.78
## - Thigh    1    285.16 41563 277.90
## - HtShoes  1    975.48 42253 278.53
## &lt;none&gt;                 41278 279.64
## - Leg      1   2661.39 43939 280.01
## - Age      1   3011.86 44290 280.31
## 
## Step:  AIC=277.67
## hipcenter ~ Age + HtShoes + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Arm      1    172.02 41485 275.83
## - Thigh    1    344.61 41658 275.99
## - HtShoes  1   1853.43 43166 277.34
## &lt;none&gt;                 41313 277.67
## - Leg      1   2871.07 44184 278.22
## - Age      1   2976.77 44290 278.31
## 
## Step:  AIC=275.83
## hipcenter ~ Age + HtShoes + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Thigh    1     472.8 41958 274.26
## &lt;none&gt;                 41485 275.83
## - HtShoes  1    2340.7 43826 275.92
## - Age      1    3501.0 44986 276.91
## - Leg      1    3591.7 45077 276.98
## 
## Step:  AIC=274.26
## hipcenter ~ Age + HtShoes + Leg
## 
##           Df Sum of Sq   RSS    AIC
## &lt;none&gt;                 41958 274.26
## - Age      1    3108.8 45067 274.98
## - Leg      1    3476.3 45434 275.28
## - HtShoes  1    4218.6 46176 275.90</code></pre>
<p>Comenzamos con el modelo <code>hipcenter ~ .</code>, que también se conoce como <code>hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg</code>. <code>R</code> intentará repetidamente eliminar un predictor hasta que se detenga o llegue al modelo <code>hipcenter ~ 1</code>, que no contiene predictores.</p>
<p>En cada “paso”, <code>R</code> informa el modelo actual, su <span class="math inline">\(\text{AIC}\)</span>, y los posibles pasos con su <span class="math inline">\(\text{RSS}\)</span> y, lo que es más importante, <span class="math inline">\(\text{AIC}\)</span>.</p>
<p>En este ejemplo, en el primer paso, el modelo actual es <code>hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg</code> que tiene un AIC de <code>283.62</code>. Tenga en cuenta que cuando <code>R</code> está calculando este valor, está usando <code>extractAIC()</code>, que usa la expresión</p>
<p><span class="math display">\[
\text{AIC} = n\log\left(\frac{\text{RSS}}{n}\right) + 2p,
\]</span></p>
<p>Lo que verificamos rápidamente.</p>
<div class="sourceCode" id="cb1296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1296-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod) <span class="co"># devuelve p y AIC</span></span></code></pre></div>
<pre><code>## [1]   9.000 283.624</code></pre>
<div class="sourceCode" id="cb1298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1298-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1298-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">resid</span>(hipcenter_mod))</span>
<span id="cb1298-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1298-2" aria-hidden="true" tabindex="-1"></a>(<span class="at">p =</span> <span class="fu">length</span>(<span class="fu">coef</span>(hipcenter_mod)))</span></code></pre></div>
<pre><code>## [1] 9</code></pre>
<div class="sourceCode" id="cb1300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1300-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1300-1" aria-hidden="true" tabindex="-1"></a>n <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">mean</span>(<span class="fu">resid</span>(hipcenter_mod) <span class="sc">^</span> <span class="dv">2</span>)) <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> p</span></code></pre></div>
<pre><code>## [1] 283.624</code></pre>
<p>Volviendo al primer paso, <code>R</code> nos da una fila que muestra el efecto de eliminar cada uno de los predictores actuales. Los signos <code>-</code> al principio de cada fila indican que estamos considerando eliminar un predictor. También hay una fila con <code>&lt;none&gt;</code> que es una fila para mantener el modelo actual. Observe que esta fila tiene el <span class="math inline">\(\text{RSS}\)</span> más pequeño, ya que es el modelo más grande.</p>
<p>Vemos que cada fila arriba de <code>&lt;none&gt;</code> tiene un <span class="math inline">\(\text{AIC}\)</span> más pequeño que la fila de <code>&lt;none&gt;</code> con el que está en la parte superior, <code>Ht</code>, dando el <span class="math inline">\(\text{AIC}\)</span> más bajo. Por lo tanto, eliminamos <code>Ht</code> del modelo y continuamos el proceso.</p>
<p>Observe que, en el segundo paso, comenzamos con el modelo <code>hipcenter ~ Age + Weight + HtShoes + Seated + Arm + Thigh + Leg</code> y la variable <code>Ht</code> ya no se considera.</p>
<p>Continuamos el proceso hasta llegar al modelo <code>hipcenter ~ Age + HtShoes + Leg</code>. En este paso, la fila para <code>&lt;none&gt;</code> encabeza la lista, ya que eliminar cualquier variable adicional no mejorará el <span class="math inline">\(\text{AIC}\)</span>. Este es el modelo que está almacenado en <code>hipcenter_mod_back_aic</code>.</p>
<div class="sourceCode" id="cb1302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1302-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1302-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(hipcenter_mod_back_aic)</span></code></pre></div>
<pre><code>## (Intercept)         Age     HtShoes         Leg 
## 456.2136538   0.5998327  -2.3022555  -6.8297461</code></pre>
<p>También podríamos buscar a través de los posibles modelos hacia atrás usando <span class="math inline">\(\text{BIC}\)</span>. Para hacerlo, usamos nuevamente la función <code>step()</code>, pero ahora especificamos <code>k = log(n)</code>, donde <code>n</code> almacena el número de observaciones en los datos.</p>
<div class="sourceCode" id="cb1304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1304-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1304-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">resid</span>(hipcenter_mod))</span>
<span id="cb1304-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1304-2" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_back_bic <span class="ot">=</span> <span class="fu">step</span>(hipcenter_mod, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## Start:  AIC=298.36
## hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + 
##     Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Ht       1      5.01 41267 294.73
## - Weight   1      8.99 41271 294.73
## - Seated   1     28.64 41290 294.75
## - HtShoes  1    108.43 41370 294.82
## - Arm      1    164.97 41427 294.88
## - Thigh    1    262.76 41525 294.97
## - Age      1   2632.12 43894 297.07
## - Leg      1   2654.85 43917 297.09
## &lt;none&gt;                 41262 298.36
## 
## Step:  AIC=294.73
## hipcenter ~ Age + Weight + HtShoes + Seated + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Weight   1     11.10 41278 291.10
## - Seated   1     30.52 41297 291.12
## - Arm      1    160.50 41427 291.24
## - Thigh    1    269.08 41536 291.34
## - HtShoes  1    971.84 42239 291.98
## - Leg      1   2664.65 43931 293.47
## - Age      1   2808.52 44075 293.59
## &lt;none&gt;                 41267 294.73
## 
## Step:  AIC=291.1
## hipcenter ~ Age + HtShoes + Seated + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Seated   1     35.10 41313 287.50
## - Arm      1    156.47 41434 287.61
## - Thigh    1    285.16 41563 287.73
## - HtShoes  1    975.48 42253 288.35
## - Leg      1   2661.39 43939 289.84
## - Age      1   3011.86 44290 290.14
## &lt;none&gt;                 41278 291.10
## 
## Step:  AIC=287.5
## hipcenter ~ Age + HtShoes + Arm + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Arm      1    172.02 41485 284.02
## - Thigh    1    344.61 41658 284.18
## - HtShoes  1   1853.43 43166 285.53
## - Leg      1   2871.07 44184 286.41
## - Age      1   2976.77 44290 286.50
## &lt;none&gt;                 41313 287.50
## 
## Step:  AIC=284.02
## hipcenter ~ Age + HtShoes + Thigh + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Thigh    1     472.8 41958 280.81
## - HtShoes  1    2340.7 43826 282.46
## - Age      1    3501.0 44986 283.46
## - Leg      1    3591.7 45077 283.54
## &lt;none&gt;                 41485 284.02
## 
## Step:  AIC=280.81
## hipcenter ~ Age + HtShoes + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Age      1    3108.8 45067 279.89
## - Leg      1    3476.3 45434 280.20
## &lt;none&gt;                 41958 280.81
## - HtShoes  1    4218.6 46176 280.81
## 
## Step:  AIC=279.89
## hipcenter ~ HtShoes + Leg
## 
##           Df Sum of Sq   RSS    AIC
## - Leg      1    3038.8 48105 278.73
## &lt;none&gt;                 45067 279.89
## - HtShoes  1    5004.4 50071 280.25
## 
## Step:  AIC=278.73
## hipcenter ~ HtShoes
## 
##           Df Sum of Sq    RSS    AIC
## &lt;none&gt;                  48105 278.73
## - HtShoes  1     83534 131639 313.35</code></pre>
<p>El procedimiento es exactamente el mismo, excepto que en cada paso buscamos mejorar <span class="math inline">\(\text{BIC}\)</span>, que <code>R</code> todavía etiqueta <span class="math inline">\(\text{AIC}\)</span> en la salida.</p>
<p>La variable <code>hipcenter_mod_back_bic</code> almacena el modelo elegido por este procedimiento.</p>
<div class="sourceCode" id="cb1306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1306-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1306-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(hipcenter_mod_back_bic)</span></code></pre></div>
<pre><code>## (Intercept)     HtShoes 
##  565.592659   -4.262091</code></pre>
<p>Observamos que este modelo es <em>más pequeño</em>, tiene menos predictores, que el modelo elegido por <span class="math inline">\(\text{AIC}\)</span>, que es lo que esperaríamos. También tenga en cuenta que si bien ambos modelos son diferentes, ninguno usa tanto <code>Ht</code> como <code>HtShoes</code>, que están extremadamente correlacionados.</p>
<p>Podemos usar información de la función <code>summary()</code> para comparar sus valores <span class="math inline">\(R^2\)</span> ajustados. Tenga en cuenta que cualquiera de los modelos seleccionados funciona mejor que el modelo completo original.</p>
<div class="sourceCode" id="cb1308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1308-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1308-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6000855</code></pre>
<div class="sourceCode" id="cb1310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1310-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1310-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_back_aic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6531427</code></pre>
<div class="sourceCode" id="cb1312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1312-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_back_bic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6244149</code></pre>
<p>También podemos calcular el LOOCV <span class="math inline">\(\text{RMSE}\)</span> para ambos modelos seleccionados, así como el modelo completo.</p>
<div class="sourceCode" id="cb1314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1314-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod)</span></code></pre></div>
<pre><code>## [1] 44.44564</code></pre>
<div class="sourceCode" id="cb1316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1316-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1316-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_back_aic)</span></code></pre></div>
<pre><code>## [1] 37.58473</code></pre>
<div class="sourceCode" id="cb1318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1318-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_back_bic)</span></code></pre></div>
<pre><code>## [1] 37.40564</code></pre>
<p>Vemos que preferiríamos el modelo elegido a través de <span class="math inline">\(\text{BIC}\)</span> si usamos LOOCV <span class="math inline">\(\text{RMSE}\)</span> como nuestra métrica.</p>
</div>
<div id="búsqueda-hacia-adelante-forward" class="section level3" number="16.2.2">
<h3><span class="header-section-number">16.2.2</span> Búsqueda hacia adelante (Forward)</h3>
<p>La selección hacia adelante es exactamente lo contrario de la selección hacia atrás. Aquí le decimos a <code>R</code> que comience con un modelo que no utilice predictores, es decir,<code>hipcenter ~ 1</code>, luego, en cada paso, <code>R</code> intentará agregar un predictor hasta que encuentre un buen modelo o alcance <code>hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg</code>.</p>
<div class="sourceCode" id="cb1320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1320-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1320-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_start <span class="ot">=</span> <span class="fu">lm</span>(hipcenter <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> seatpos)</span>
<span id="cb1320-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1320-2" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_forw_aic <span class="ot">=</span> <span class="fu">step</span>(</span>
<span id="cb1320-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1320-3" aria-hidden="true" tabindex="-1"></a>  hipcenter_mod_start, </span>
<span id="cb1320-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1320-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> hipcenter <span class="sc">~</span> Age <span class="sc">+</span> Weight <span class="sc">+</span> HtShoes <span class="sc">+</span> Ht <span class="sc">+</span> Seated <span class="sc">+</span> Arm <span class="sc">+</span> Thigh <span class="sc">+</span> Leg, </span>
<span id="cb1320-5"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1320-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=311.71
## hipcenter ~ 1
## 
##           Df Sum of Sq    RSS    AIC
## + Ht       1     84023  47616 275.07
## + HtShoes  1     83534  48105 275.45
## + Leg      1     81568  50071 276.98
## + Seated   1     70392  61247 284.63
## + Weight   1     53975  77664 293.66
## + Thigh    1     46010  85629 297.37
## + Arm      1     45065  86574 297.78
## &lt;none&gt;                 131639 311.71
## + Age      1      5541 126098 312.07
## 
## Step:  AIC=275.07
## hipcenter ~ Ht
## 
##           Df Sum of Sq   RSS    AIC
## + Leg      1   2781.10 44835 274.78
## &lt;none&gt;                 47616 275.07
## + Age      1   2353.51 45262 275.14
## + Weight   1    195.86 47420 276.91
## + Seated   1    101.56 47514 276.99
## + Arm      1     75.78 47540 277.01
## + HtShoes  1     25.76 47590 277.05
## + Thigh    1      4.63 47611 277.06
## 
## Step:  AIC=274.78
## hipcenter ~ Ht + Leg
## 
##           Df Sum of Sq   RSS    AIC
## + Age      1   2896.60 41938 274.24
## &lt;none&gt;                 44835 274.78
## + Arm      1    522.72 44312 276.33
## + Weight   1    445.10 44390 276.40
## + HtShoes  1     34.11 44801 276.75
## + Thigh    1     32.96 44802 276.75
## + Seated   1      1.12 44834 276.78
## 
## Step:  AIC=274.24
## hipcenter ~ Ht + Leg + Age
## 
##           Df Sum of Sq   RSS    AIC
## &lt;none&gt;                 41938 274.24
## + Thigh    1    372.71 41565 275.90
## + Arm      1    257.09 41681 276.01
## + Seated   1    121.26 41817 276.13
## + Weight   1     46.83 41891 276.20
## + HtShoes  1     13.38 41925 276.23</code></pre>
<p>Nuevamente, por defecto, <code>R</code> usa <span class="math inline">\(\text{AIC}\)</span> como su métrica de calidad cuando se usa la función <code>step()</code>. También tenga en cuenta que ahora las filas comienzan con un <code>+</code> que indica la adición de predictores al modelo actual desde cualquier paso.</p>
<div class="sourceCode" id="cb1322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1322-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1322-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_forw_bic <span class="ot">=</span> <span class="fu">step</span>(</span>
<span id="cb1322-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1322-2" aria-hidden="true" tabindex="-1"></a>  hipcenter_mod_start, </span>
<span id="cb1322-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1322-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> hipcenter <span class="sc">~</span> Age <span class="sc">+</span> Weight <span class="sc">+</span> HtShoes <span class="sc">+</span> Ht <span class="sc">+</span> Seated <span class="sc">+</span> Arm <span class="sc">+</span> Thigh <span class="sc">+</span> Leg, </span>
<span id="cb1322-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1322-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## Start:  AIC=313.35
## hipcenter ~ 1
## 
##           Df Sum of Sq    RSS    AIC
## + Ht       1     84023  47616 278.34
## + HtShoes  1     83534  48105 278.73
## + Leg      1     81568  50071 280.25
## + Seated   1     70392  61247 287.91
## + Weight   1     53975  77664 296.93
## + Thigh    1     46010  85629 300.64
## + Arm      1     45065  86574 301.06
## &lt;none&gt;                 131639 313.35
## + Age      1      5541 126098 315.35
## 
## Step:  AIC=278.34
## hipcenter ~ Ht
## 
##           Df Sum of Sq   RSS    AIC
## &lt;none&gt;                 47616 278.34
## + Leg      1   2781.10 44835 279.69
## + Age      1   2353.51 45262 280.05
## + Weight   1    195.86 47420 281.82
## + Seated   1    101.56 47514 281.90
## + Arm      1     75.78 47540 281.92
## + HtShoes  1     25.76 47590 281.96
## + Thigh    1      4.63 47611 281.98</code></pre>
<p>Podemos hacer la misma modificación que la última vez para usar <span class="math inline">\(\text{BIC}\)</span> con selección hacia adelante.</p>
<div class="sourceCode" id="cb1324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1324-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1324-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6000855</code></pre>
<div class="sourceCode" id="cb1326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1326-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_forw_aic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6533055</code></pre>
<div class="sourceCode" id="cb1328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1328-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1328-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_forw_bic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6282374</code></pre>
<p>Podemos comparar los dos modelos seleccionados con <span class="math inline">\(R^2\)</span> ajustado así como su LOOCV <span class="math inline">\(\text{RMSE}\)</span>. Los resultados son muy similares a los que utilizan la selección hacia atrás, aunque los modelos no son exactamente iguales.</p>
<div class="sourceCode" id="cb1330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1330-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1330-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod)</span></code></pre></div>
<pre><code>## [1] 44.44564</code></pre>
<div class="sourceCode" id="cb1332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1332-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_forw_aic)</span></code></pre></div>
<pre><code>## [1] 37.62516</code></pre>
<div class="sourceCode" id="cb1334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1334-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1334-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_forw_bic)</span></code></pre></div>
<pre><code>## [1] 37.2511</code></pre>
</div>
<div id="búsqueda-por-pasos-stepwise" class="section level3" number="16.2.3">
<h3><span class="header-section-number">16.2.3</span> Búsqueda por pasos (Stepwise)</h3>
<p>Las comprobaciones de búsqueda por pasos van hacia atrás y hacia adelante en cada paso. Considera la adición de cualquier variable que no esté actualmente en el modelo, así como la eliminación de cualquier variable que esté actualmente en el modelo.</p>
<p>Aquí realizamos una búsqueda paso a paso usando <span class="math inline">\(\text{AIC}\)</span> como nuestra métrica. Comenzamos con el modelo <code>hipcenter ~ 1</code> y buscamos hasta <code>hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg</code>. Observe que en muchos de los pasos, algunas filas comienzan con <code>-</code>, mientras que otras comienzan con<code>+</code>.</p>
<div class="sourceCode" id="cb1336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1336-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1336-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_both_aic <span class="ot">=</span> <span class="fu">step</span>(</span>
<span id="cb1336-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1336-2" aria-hidden="true" tabindex="-1"></a>  hipcenter_mod_start, </span>
<span id="cb1336-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1336-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> hipcenter <span class="sc">~</span> Age <span class="sc">+</span> Weight <span class="sc">+</span> HtShoes <span class="sc">+</span> Ht <span class="sc">+</span> Seated <span class="sc">+</span> Arm <span class="sc">+</span> Thigh <span class="sc">+</span> Leg, </span>
<span id="cb1336-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1336-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=311.71
## hipcenter ~ 1
## 
##           Df Sum of Sq    RSS    AIC
## + Ht       1     84023  47616 275.07
## + HtShoes  1     83534  48105 275.45
## + Leg      1     81568  50071 276.98
## + Seated   1     70392  61247 284.63
## + Weight   1     53975  77664 293.66
## + Thigh    1     46010  85629 297.37
## + Arm      1     45065  86574 297.78
## &lt;none&gt;                 131639 311.71
## + Age      1      5541 126098 312.07
## 
## Step:  AIC=275.07
## hipcenter ~ Ht
## 
##           Df Sum of Sq    RSS    AIC
## + Leg      1      2781  44835 274.78
## &lt;none&gt;                  47616 275.07
## + Age      1      2354  45262 275.14
## + Weight   1       196  47420 276.91
## + Seated   1       102  47514 276.99
## + Arm      1        76  47540 277.01
## + HtShoes  1        26  47590 277.05
## + Thigh    1         5  47611 277.06
## - Ht       1     84023 131639 311.71
## 
## Step:  AIC=274.78
## hipcenter ~ Ht + Leg
## 
##           Df Sum of Sq   RSS    AIC
## + Age      1    2896.6 41938 274.24
## &lt;none&gt;                 44835 274.78
## - Leg      1    2781.1 47616 275.07
## + Arm      1     522.7 44312 276.33
## + Weight   1     445.1 44390 276.40
## + HtShoes  1      34.1 44801 276.75
## + Thigh    1      33.0 44802 276.75
## + Seated   1       1.1 44834 276.78
## - Ht       1    5236.3 50071 276.98
## 
## Step:  AIC=274.24
## hipcenter ~ Ht + Leg + Age
## 
##           Df Sum of Sq   RSS    AIC
## &lt;none&gt;                 41938 274.24
## - Age      1    2896.6 44835 274.78
## - Leg      1    3324.2 45262 275.14
## - Ht       1    4238.3 46176 275.90
## + Thigh    1     372.7 41565 275.90
## + Arm      1     257.1 41681 276.01
## + Seated   1     121.3 41817 276.13
## + Weight   1      46.8 41891 276.20
## + HtShoes  1      13.4 41925 276.23</code></pre>
<p>En su lugar, podríamos usar nuevamente <span class="math inline">\(\text{BIC}\)</span> como nuestra métrica.</p>
<div class="sourceCode" id="cb1338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1338-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1338-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_both_bic <span class="ot">=</span> <span class="fu">step</span>(</span>
<span id="cb1338-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1338-2" aria-hidden="true" tabindex="-1"></a>  hipcenter_mod_start, </span>
<span id="cb1338-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1338-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope =</span> hipcenter <span class="sc">~</span> Age <span class="sc">+</span> Weight <span class="sc">+</span> HtShoes <span class="sc">+</span> Ht <span class="sc">+</span> Seated <span class="sc">+</span> Arm <span class="sc">+</span> Thigh <span class="sc">+</span> Leg, </span>
<span id="cb1338-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1338-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## Start:  AIC=313.35
## hipcenter ~ 1
## 
##           Df Sum of Sq    RSS    AIC
## + Ht       1     84023  47616 278.34
## + HtShoes  1     83534  48105 278.73
## + Leg      1     81568  50071 280.25
## + Seated   1     70392  61247 287.91
## + Weight   1     53975  77664 296.93
## + Thigh    1     46010  85629 300.64
## + Arm      1     45065  86574 301.06
## &lt;none&gt;                 131639 313.35
## + Age      1      5541 126098 315.35
## 
## Step:  AIC=278.34
## hipcenter ~ Ht
## 
##           Df Sum of Sq    RSS    AIC
## &lt;none&gt;                  47616 278.34
## + Leg      1      2781  44835 279.69
## + Age      1      2354  45262 280.05
## + Weight   1       196  47420 281.82
## + Seated   1       102  47514 281.90
## + Arm      1        76  47540 281.92
## + HtShoes  1        26  47590 281.96
## + Thigh    1         5  47611 281.98
## - Ht       1     84023 131639 313.35</code></pre>
<p>Las comparaciones de <span class="math inline">\(R^2\)</span> ajustado y LOOCV <span class="math inline">\(\text{RMSE}\)</span> son similares a los de hacia atrás y hacia adelante, lo cual no es para nada sorprendente, ya que algunos de los modelos seleccionados son los mismos que antes.</p>
<div class="sourceCode" id="cb1340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1340-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6000855</code></pre>
<div class="sourceCode" id="cb1342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1342-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_both_aic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6533055</code></pre>
<div class="sourceCode" id="cb1344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1344-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1344-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hipcenter_mod_both_bic)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.6282374</code></pre>
<div class="sourceCode" id="cb1346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1346-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod)</span></code></pre></div>
<pre><code>## [1] 44.44564</code></pre>
<div class="sourceCode" id="cb1348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1348-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1348-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_both_aic)</span></code></pre></div>
<pre><code>## [1] 37.62516</code></pre>
<div class="sourceCode" id="cb1350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1350-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1350-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(hipcenter_mod_both_bic)</span></code></pre></div>
<pre><code>## [1] 37.2511</code></pre>
</div>
<div id="búsqueda-exhaustiva" class="section level3" number="16.2.4">
<h3><span class="header-section-number">16.2.4</span> Búsqueda exhaustiva</h3>
<p>La búsqueda hacia atrás, hacia adelante y paso a paso son útiles, pero tienen un problema obvio. Al no comprobar todos los modelos posibles, a veces se perderán el mejor modelo posible. Con una cantidad extremadamente grande de predictores, a veces esto es necesario, ya que verificar todos los modelos posibles llevaría bastante tiempo, incluso con computadoras actuales.</p>
<p>Sin embargo, con un conjunto de datos de tamaño razonable, no es demasiado difícil verificar todos los modelos posibles. Para hacerlo, usaremos la función <code>regsubsets()</code> en el paquete <code>leaps</code> de <code>R</code>.</p>
<div class="sourceCode" id="cb1352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1352-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1352-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb1352-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1352-2" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod <span class="ot">=</span> <span class="fu">summary</span>(<span class="fu">regsubsets</span>(hipcenter <span class="sc">~</span> ., <span class="at">data =</span> seatpos))</span></code></pre></div>
<p>Algunos puntos sobre esta línea de código. Primero, tenga en cuenta que usamos inmediatamente <code>summary()</code> y almacenamos esos resultados. Ese es simplemente el uso previsto de <code>regsubsets()</code>. En segundo lugar, dentro de <code>regsubsets()</code> especificamos el modelo <code>hipcenter ~ .</code>. Este será el modelo más grande considerado, es decir, el modelo que utiliza todos los predictores de primer orden, y <code>R</code> comprobará todos los subconjuntos posibles.</p>
<p>Ahora veremos la información almacenada en <code>all_hipcenter_mod</code>.</p>
<div class="sourceCode" id="cb1353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1353-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1353-1" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>which</span></code></pre></div>
<pre><code>##   (Intercept)   Age Weight HtShoes    Ht Seated   Arm Thigh   Leg
## 1        TRUE FALSE  FALSE   FALSE  TRUE  FALSE FALSE FALSE FALSE
## 2        TRUE FALSE  FALSE   FALSE  TRUE  FALSE FALSE FALSE  TRUE
## 3        TRUE  TRUE  FALSE   FALSE  TRUE  FALSE FALSE FALSE  TRUE
## 4        TRUE  TRUE  FALSE    TRUE FALSE  FALSE FALSE  TRUE  TRUE
## 5        TRUE  TRUE  FALSE    TRUE FALSE  FALSE  TRUE  TRUE  TRUE
## 6        TRUE  TRUE  FALSE    TRUE FALSE   TRUE  TRUE  TRUE  TRUE
## 7        TRUE  TRUE   TRUE    TRUE FALSE   TRUE  TRUE  TRUE  TRUE
## 8        TRUE  TRUE   TRUE    TRUE  TRUE   TRUE  TRUE  TRUE  TRUE</code></pre>
<p>El uso de <code>$which</code> nos da el mejor modelo, de acuerdo con <span class="math inline">\(\text{RSS}\)</span>, para un modelo de cada tamaño posible, en este caso entre uno y ocho predictores. Por ejemplo, el mejor modelo con cuatro predictores (<span class="math inline">\(p=5\)</span>) usaría <code>Age</code>, <code>HtShoes</code>, <code>Thigh</code>, y <code>Leg</code>.</p>
<div class="sourceCode" id="cb1355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1355-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1355-1" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>rss</span></code></pre></div>
<pre><code>## [1] 47615.79 44834.69 41938.09 41485.01 41313.00 41277.90 41266.80 41261.78</code></pre>
<p>Podemos obtener <span class="math inline">\(\text{RSS}\)</span> para cada uno de estos modelos usando <code>$rss</code>. Tenga en cuenta que estos están disminuyendo ya que los modelos varían de pequeños a grandes.</p>
<p>Ahora que tenemos <span class="math inline">\(\text{RSS}\)</span> para cada uno de estos modelos, es bastante fácil obtener <span class="math inline">\(\text{AIC}\)</span>, <span class="math inline">\(\text{BIC}\)</span> y <span class="math inline">\(R^2\)</span> ajustado, ya que son toda una función de <span class="math inline">\(\text{RSS}\)</span> Además, dado que tenemos los modelos con los mejores <span class="math inline">\(\text{RSS}\)</span> para cada tamaño, darán como resultado los modelos con los mejores <span class="math inline">\(\text{AIC}\)</span>, <span class="math inline">\(\text {BIC}\)</span> y <span class="math inline">\(R^2\)</span> ajustados para cada tamaño. Luego, al elegir entre ellos, podemos encontrar el mejor <span class="math inline">\(\text{AIC}\)</span>, <span class="math inline">\(\text{BIC}\)</span> y <span class="math inline">\(R^2\)</span> ajustado.</p>
<p>Convenientemente, <span class="math inline">\(R^2\)</span> ajustado se calcula automáticamente.</p>
<div class="sourceCode" id="cb1357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1357-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1357-1" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>adjr2</span></code></pre></div>
<pre><code>## [1] 0.6282374 0.6399496 0.6533055 0.6466586 0.6371276 0.6257403 0.6133690
## [8] 0.6000855</code></pre>
<p>Para encontrar qué modelo tiene el <span class="math inline">\(R^2\)</span> ajustado más alto, podemos usar la función <code>which.max()</code>.</p>
<div class="sourceCode" id="cb1359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1359-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1359-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">best_r2_ind =</span> <span class="fu">which.max</span>(all_hipcenter_mod<span class="sc">$</span>adjr2))</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Luego podemos extraer los predictores de ese modelo.</p>
<div class="sourceCode" id="cb1361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1361-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1361-1" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>which[best_r2_ind, ]</span></code></pre></div>
<pre><code>## (Intercept)         Age      Weight     HtShoes          Ht      Seated 
##        TRUE        TRUE       FALSE       FALSE        TRUE       FALSE 
##         Arm       Thigh         Leg 
##       FALSE       FALSE        TRUE</code></pre>
<p>Ahora calcularemos <span class="math inline">\(\text{AIC}\)</span> y <span class="math inline">\(\text{BIC}\)</span> para cada uno de los modelos con el mejor <span class="math inline">\(\text{RSS}\)</span>. Para hacerlo, necesitaremos <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span> para el modelo más grande posible.</p>
<div class="sourceCode" id="cb1363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1363-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1363-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">coef</span>(hipcenter_mod))</span>
<span id="cb1363-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1363-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">resid</span>(hipcenter_mod))</span></code></pre></div>
<p>Usaremos la forma de <span class="math inline">\(\text{AIC}\)</span> que omite el término constante que es igual en todos los modelos.</p>
<p><span class="math display">\[
\text{AIC} = n\log\left(\frac{\text{RSS}}{n}\right) + 2p.
\]</span></p>
<p>Dado que tenemos el <span class="math inline">\(\text{RSS}\)</span> de cada modelo almacenado, esto es fácil de calcular.</p>
<div class="sourceCode" id="cb1364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1364-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1364-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_aic <span class="ot">=</span> n <span class="sc">*</span> <span class="fu">log</span>(all_hipcenter_mod<span class="sc">$</span>rss <span class="sc">/</span> n) <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">2</span><span class="sc">:</span>p)</span></code></pre></div>
<p>Luego podemos extraer los predictores del modelo con el mejor <span class="math inline">\(\text{AIC}\)</span>.</p>
<div class="sourceCode" id="cb1365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1365-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1365-1" aria-hidden="true" tabindex="-1"></a>best_aic_ind <span class="ot">=</span> <span class="fu">which.min</span>(hipcenter_mod_aic)</span>
<span id="cb1365-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1365-2" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>which[best_aic_ind,]</span></code></pre></div>
<pre><code>## (Intercept)         Age      Weight     HtShoes          Ht      Seated 
##        TRUE        TRUE       FALSE       FALSE        TRUE       FALSE 
##         Arm       Thigh         Leg 
##       FALSE       FALSE        TRUE</code></pre>
<p>Ajustemos este modelo para que podamos comparar con nuestros modelos previamente elegidos usando <span class="math inline">\(\text{AIC}\)</span> y procedimientos de búsqueda.</p>
<div class="sourceCode" id="cb1367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1367-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1367-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_best_aic <span class="ot">=</span> <span class="fu">lm</span>(hipcenter <span class="sc">~</span> Age <span class="sc">+</span> Ht <span class="sc">+</span> Leg, <span class="at">data =</span> seatpos)</span></code></pre></div>
<p>La función <code>extractAIC()</code> calculará el <span class="math inline">\(\text{AIC}\)</span> definido anteriormente para un modelo ajustado.</p>
<div class="sourceCode" id="cb1368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1368-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1368-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_best_aic)</span></code></pre></div>
<pre><code>## [1]   4.0000 274.2418</code></pre>
<div class="sourceCode" id="cb1370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1370-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1370-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_back_aic)</span></code></pre></div>
<pre><code>## [1]   4.0000 274.2597</code></pre>
<div class="sourceCode" id="cb1372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1372-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_forw_aic)</span></code></pre></div>
<pre><code>## [1]   4.0000 274.2418</code></pre>
<div class="sourceCode" id="cb1374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1374-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_both_aic)</span></code></pre></div>
<pre><code>## [1]   4.0000 274.2418</code></pre>
<p>Vemos que dos de los modelos elegidos por los procedimientos de búsqueda tienen el mejor <span class="math inline">\(\text{AIC}\)</span> posible, ya que son el mismo modelo. Sin embargo, esto nunca está garantizado. Vemos que el modelo elegido usando la selección hacia atrás no alcanza el <span class="math inline">\(\text{AIC}\)</span> más pequeño posible.</p>
<div class="sourceCode" id="cb1376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1376-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1376-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hipcenter_mod_aic <span class="sc">~</span> <span class="fu">I</span>(<span class="dv">2</span><span class="sc">:</span>p), <span class="at">ylab =</span> <span class="st">&quot;AIC&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;p, número de parámetros&quot;</span>, </span>
<span id="cb1376-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1376-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>,</span>
<span id="cb1376-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1376-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;AIC vs Complejidad del modelo&quot;</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-636-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Fácilmente podríamos repetir este proceso para <span class="math inline">\(\text{BIC}\)</span>.</p>
<p><span class="math display">\[
\text{BIC} = n\log\left(\frac{\text{RSS}}{n}\right) + \log(n)p.
\]</span></p>
<div class="sourceCode" id="cb1377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1377-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1377-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_bic <span class="ot">=</span> n <span class="sc">*</span> <span class="fu">log</span>(all_hipcenter_mod<span class="sc">$</span>rss <span class="sc">/</span> n) <span class="sc">+</span> <span class="fu">log</span>(n) <span class="sc">*</span> (<span class="dv">2</span><span class="sc">:</span>p)</span></code></pre></div>
<div class="sourceCode" id="cb1378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1378-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1378-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(hipcenter_mod_bic)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb1380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1380-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1380-1" aria-hidden="true" tabindex="-1"></a>all_hipcenter_mod<span class="sc">$</span>which[<span class="dv">1</span>,]</span></code></pre></div>
<pre><code>## (Intercept)         Age      Weight     HtShoes          Ht      Seated 
##        TRUE       FALSE       FALSE       FALSE        TRUE       FALSE 
##         Arm       Thigh         Leg 
##       FALSE       FALSE       FALSE</code></pre>
<div class="sourceCode" id="cb1382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1382-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1382-1" aria-hidden="true" tabindex="-1"></a>hipcenter_mod_best_bic <span class="ot">=</span> <span class="fu">lm</span>(hipcenter <span class="sc">~</span> Ht, <span class="at">data =</span> seatpos)</span></code></pre></div>
<div class="sourceCode" id="cb1383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1383-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1383-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_best_bic, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## [1]   2.0000 278.3418</code></pre>
<div class="sourceCode" id="cb1385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1385-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_back_bic, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## [1]   2.0000 278.7306</code></pre>
<div class="sourceCode" id="cb1387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1387-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_forw_bic, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## [1]   2.0000 278.3418</code></pre>
<div class="sourceCode" id="cb1389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1389-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1389-1" aria-hidden="true" tabindex="-1"></a><span class="fu">extractAIC</span>(hipcenter_mod_both_bic, <span class="at">k =</span> <span class="fu">log</span>(n))</span></code></pre></div>
<pre><code>## [1]   2.0000 278.3418</code></pre>
</div>
</div>
<div id="términos-de-orden-superior" class="section level2" number="16.3">
<h2><span class="header-section-number">16.3</span> Términos de orden superior</h2>
<p>Hasta ahora solo hemos permitido términos de primer orden en nuestros modelos. Regresemos al conjunto de datos <code>autompg</code> para explorar términos de orden superior.</p>
<div class="sourceCode" id="cb1391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1391-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-1" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">read.table</span>(</span>
<span id="cb1391-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data&quot;</span>,</span>
<span id="cb1391-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">quote =</span> <span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">&quot;</span>,</span>
<span id="cb1391-4"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">comment.char =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb1391-5"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1391-6"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-6" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(autompg) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;mpg&quot;</span>, <span class="st">&quot;cyl&quot;</span>, <span class="st">&quot;disp&quot;</span>, <span class="st">&quot;hp&quot;</span>, <span class="st">&quot;wt&quot;</span>, <span class="st">&quot;acc&quot;</span>, </span>
<span id="cb1391-7"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-7" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;year&quot;</span>, <span class="st">&quot;origin&quot;</span>, <span class="st">&quot;name&quot;</span>)</span>
<span id="cb1391-8"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-8" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, autompg<span class="sc">$</span>hp <span class="sc">!=</span> <span class="st">&quot;?&quot;</span>)</span>
<span id="cb1391-9"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-9" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, autompg<span class="sc">$</span>name <span class="sc">!=</span> <span class="st">&quot;plymouth reliant&quot;</span>)</span>
<span id="cb1391-10"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-10" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(autompg) <span class="ot">=</span> <span class="fu">paste</span>(autompg<span class="sc">$</span>cyl, <span class="st">&quot;cylinder&quot;</span>, autompg<span class="sc">$</span>year, autompg<span class="sc">$</span>name)</span>
<span id="cb1391-11"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-11" aria-hidden="true" tabindex="-1"></a>autompg<span class="sc">$</span>hp <span class="ot">=</span> <span class="fu">as.numeric</span>(autompg<span class="sc">$</span>hp)</span>
<span id="cb1391-12"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-12" aria-hidden="true" tabindex="-1"></a>autompg<span class="sc">$</span>domestic <span class="ot">=</span> <span class="fu">as.numeric</span>(autompg<span class="sc">$</span>origin <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb1391-13"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-13" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> autompg[autompg<span class="sc">$</span>cyl <span class="sc">!=</span> <span class="dv">5</span>,]</span>
<span id="cb1391-14"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-14" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> autompg[autompg<span class="sc">$</span>cyl <span class="sc">!=</span> <span class="dv">3</span>,]</span>
<span id="cb1391-15"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-15" aria-hidden="true" tabindex="-1"></a>autompg<span class="sc">$</span>cyl <span class="ot">=</span> <span class="fu">as.factor</span>(autompg<span class="sc">$</span>cyl)</span>
<span id="cb1391-16"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-16" aria-hidden="true" tabindex="-1"></a>autompg<span class="sc">$</span>domestic <span class="ot">=</span> <span class="fu">as.factor</span>(autompg<span class="sc">$</span>domestic)</span>
<span id="cb1391-17"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-17" aria-hidden="true" tabindex="-1"></a>autompg <span class="ot">=</span> <span class="fu">subset</span>(autompg, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">&quot;mpg&quot;</span>, <span class="st">&quot;cyl&quot;</span>, <span class="st">&quot;disp&quot;</span>, <span class="st">&quot;hp&quot;</span>, </span>
<span id="cb1391-18"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1391-18" aria-hidden="true" tabindex="-1"></a>                                     <span class="st">&quot;wt&quot;</span>, <span class="st">&quot;acc&quot;</span>, <span class="st">&quot;year&quot;</span>, <span class="st">&quot;domestic&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb1392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1392-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1392-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(autompg)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    383 obs. of  8 variables:
##  $ mpg     : num  18 15 18 16 17 15 14 14 14 15 ...
##  $ cyl     : Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 3 3 3 3 3 3 3 3 3 3 ...
##  $ disp    : num  307 350 318 304 302 429 454 440 455 390 ...
##  $ hp      : num  130 165 150 150 140 198 220 215 225 190 ...
##  $ wt      : num  3504 3693 3436 3433 3449 ...
##  $ acc     : num  12 11.5 11 12 10.5 10 9 8.5 10 8.5 ...
##  $ year    : int  70 70 70 70 70 70 70 70 70 70 ...
##  $ domestic: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ...</code></pre>
<p>Recuerde que tenemos dos variables factor, <code>cyl</code> y <code>domestic</code>. La variable <code>cyl</code> tiene tres niveles, mientras que la variable <code>domestic</code> sólo tiene dos. Por lo tanto, la variable <code>cyl</code> se codificará usando dos variables ficticias, mientras que la variable <code>domestic</code> solo necesitará una. Prestaremos atención a esto más adelante.</p>
<div class="sourceCode" id="cb1394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1394-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1394-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(autompg, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-643-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Usaremos el gráfico <code>pairs()</code> para determinar qué variables pueden beneficiarse de una relación cuadrática con la respuesta. También consideraremos todas las posibles interacciones de dos vías No consideraremos ningún orden de tres o más. Por ejemplo, no consideraremos la interacción entre los términos de primer orden y los términos cuadráticos agregados.</p>
<p>Así que ahora ajustaremos este modelo bastante grande. Usaremos una respuesta transformada logarítmicamente. Observe que <code>log(mpg) ~ . ^ 2</code> considerará automáticamente todos los términos de primer orden, así como todas las interacciones de dos vías. Usamos <code>I(var_name ^ 2)</code> para agregar términos cuadráticos para algunas variables. Esto generalmente funciona mejor que usar <code>poly()</code> cuando se realiza la selección de variables.</p>
<div class="sourceCode" id="cb1395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1395-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1395-1" aria-hidden="true" tabindex="-1"></a>autompg_big_mod <span class="ot">=</span> <span class="fu">lm</span>(</span>
<span id="cb1395-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1395-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">log</span>(mpg) <span class="sc">~</span> . <span class="sc">^</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fu">I</span>(disp <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(hp <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(wt <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(acc <span class="sc">^</span> <span class="dv">2</span>), </span>
<span id="cb1395-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1395-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> autompg)</span></code></pre></div>
<p>Creemos que es bastante improbable que realmente necesitemos todos estos términos. ¡Hay unos cuantos!</p>
<div class="sourceCode" id="cb1396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1396-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1396-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(autompg_big_mod))</span></code></pre></div>
<pre><code>## [1] 40</code></pre>
<p>Intentaremos buscar hacia atrás con <span class="math inline">\(\text{AIC}\)</span> y <span class="math inline">\(\text{BIC}\)</span> para intentar encontrar un modelo más pequeño y razonable.</p>
<div class="sourceCode" id="cb1398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1398-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1398-1" aria-hidden="true" tabindex="-1"></a>autompg_mod_back_aic <span class="ot">=</span> <span class="fu">step</span>(autompg_big_mod, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>, <span class="at">trace =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Observe que usamos <code>trace = 0</code> en la llamada a la función. Esto suprime la salida de cada paso y simplemente almacena el modelo elegido. Esto es útil, ya que este código de otro modo crearía una gran cantidad de resultados. Si hubiéramos visto la salida, que puede probar por su cuenta eliminando <code>trace = 0</code>, veríamos que <code>R</code> solo considera la variable <code>cyl</code> como una única variable, a pesar de que está codificada usando dos variables ficticias. Por lo tanto, eliminar <code>cyl</code> eliminaría dos parámetros del modelo resultante.</p>
<p>También debe notar que <code>R</code> respeta la jerarquía cuando intenta eliminar variables. Es decir, por ejemplo, <code>R</code> no considerará eliminar <code>hp</code> si <code>hp:disp</code> o <code>I(hp ^ 2)</code> están actualmente en el modelo.</p>
<p>También usamos <span class="math inline">\(\text{BIC}\)</span>.</p>
<div class="sourceCode" id="cb1399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1399-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1399-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">resid</span>(autompg_big_mod))</span>
<span id="cb1399-2"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1399-2" aria-hidden="true" tabindex="-1"></a>autompg_mod_back_bic <span class="ot">=</span> <span class="fu">step</span>(autompg_big_mod, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>, </span>
<span id="cb1399-3"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1399-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">k =</span> <span class="fu">log</span>(n), <span class="at">trace =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Al observar los coeficientes de los dos modelos elegidos, vemos que todavía son bastante grandes.</p>
<div class="sourceCode" id="cb1400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1400-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1400-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(autompg_mod_back_aic)</span></code></pre></div>
<pre><code>##    (Intercept)           cyl6           cyl8           disp             hp 
##   3.671884e+00  -1.602563e-01  -8.581644e-01  -9.371971e-03   2.293534e-02 
##             wt            acc           year      domestic1        I(hp^2) 
##  -3.064497e-04  -1.393888e-01  -1.966361e-03   9.369324e-01  -1.497669e-05 
##       cyl6:acc       cyl8:acc        disp:wt      disp:year         hp:acc 
##   7.220298e-03   5.041915e-02   5.797816e-07   9.493770e-05  -5.062295e-04 
##        hp:year       acc:year  acc:domestic1 year:domestic1 
##  -1.838985e-04   2.345625e-03  -2.372468e-02  -7.332725e-03</code></pre>
<div class="sourceCode" id="cb1402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1402-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1402-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(autompg_mod_back_bic)</span></code></pre></div>
<pre><code>##   (Intercept)          cyl6          cyl8          disp            hp 
##  4.657847e+00 -1.086165e-01 -7.611631e-01 -1.609316e-03  2.621266e-03 
##            wt           acc          year     domestic1      cyl6:acc 
## -2.635972e-04 -1.670601e-01 -1.045646e-02  3.341579e-01  4.315493e-03 
##      cyl8:acc       disp:wt        hp:acc      acc:year acc:domestic1 
##  4.610095e-02  4.102804e-07 -3.386261e-04  2.500137e-03 -2.193294e-02</code></pre>
<p>Sin embargo, son mucho más pequeños que el modelo completo original. También observe que los modelos resultantes respetan la jerarquía.</p>
<div class="sourceCode" id="cb1404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1404-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1404-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(autompg_big_mod))</span></code></pre></div>
<pre><code>## [1] 40</code></pre>
<div class="sourceCode" id="cb1406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1406-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1406-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(autompg_mod_back_aic))</span></code></pre></div>
<pre><code>## [1] 19</code></pre>
<div class="sourceCode" id="cb1408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1408-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1408-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">coef</span>(autompg_mod_back_bic))</span></code></pre></div>
<pre><code>## [1] 15</code></pre>
<p>Calculando el LOOCV <span class="math inline">\(\text{RMSE}\)</span> para cada uno, vemos que el modelo elegido usando <span class="math inline">\(\text{BIC}\)</span> funciona mejor. Eso significa que es el mejor modelo para la predicción, ya que logra el mejor LOOCV <span class="math inline">\(\text{RMSE}\)</span>, pero también el mejor modelo para la explicación, ya que también es el más pequeño.</p>
<div class="sourceCode" id="cb1410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1410-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1410-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(autompg_big_mod)</span></code></pre></div>
<pre><code>## [1] 0.1112024</code></pre>
<div class="sourceCode" id="cb1412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1412-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1412-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(autompg_mod_back_aic)</span></code></pre></div>
<pre><code>## [1] 0.1032888</code></pre>
<div class="sourceCode" id="cb1414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1414-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1414-1" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_loocv_rmse</span>(autompg_mod_back_bic)</span></code></pre></div>
<pre><code>## [1] 0.103134</code></pre>
</div>
<div id="explicación-versus-predicción-1" class="section level2" number="16.4">
<h2><span class="header-section-number">16.4</span> Explicación versus predicción</h2>
<p>A lo largo de este capítulo, hemos intentado encontrar modelos razonablemente “pequeños”, que son buenos <strong>para explicar</strong> la relación entre la respuesta y los predictores, que también tienen errores pequeños que son buenos para hacer <strong>predicciones</strong>.</p>
<p>Más adelante analizaremos el modelo <code>autompg_mod_back_bic</code> para explicar mejor la diferencia entre usar modelos para <em>explicar</em> y <em>predecir</em>. Este es el modelo que se ajusta a los datos de <code>autompg</code> que se eligieron usando busqueda hacia atrás y <span class="math inline">\(\text{BIC}\)</span>, que obtuvo el LOOCV <span class="math inline">\(\text{RMSE}\)</span> más bajo de los modelos que consideramos.</p>
<div class="sourceCode" id="cb1416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1416-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1416-1" aria-hidden="true" tabindex="-1"></a>autompg_mod_back_bic</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(mpg) ~ cyl + disp + hp + wt + acc + year + domestic + 
##     cyl:acc + disp:wt + hp:acc + acc:year + acc:domestic, data = autompg)
## 
## Coefficients:
##   (Intercept)           cyl6           cyl8           disp             hp  
##     4.658e+00     -1.086e-01     -7.612e-01     -1.609e-03      2.621e-03  
##            wt            acc           year      domestic1       cyl6:acc  
##    -2.636e-04     -1.671e-01     -1.046e-02      3.342e-01      4.315e-03  
##      cyl8:acc        disp:wt         hp:acc       acc:year  acc:domestic1  
##     4.610e-02      4.103e-07     -3.386e-04      2.500e-03     -2.193e-02</code></pre>
<p>Observe que este es un modelo algo “grande”, que usa parámetros 15, incluidos varios términos de interacción. ¿Nos importa que este sea un modelo “grande”? La respuesta es, <strong>depende</strong>.</p>
<div id="explicación-1" class="section level3" number="16.4.1">
<h3><span class="header-section-number">16.4.1</span> Explicación</h3>
<p>Supongamos que nos gustaría utilizar este modelo como explicación. Quizás somos un fabricante de automóviles que intenta diseñar un vehículo de bajo consumo de combustible. Si este es el caso, estamos interesados tanto en qué variables predictoras son útiles para explicar la eficiencia de combustible del automóvil como en cómo esas variables que afectan la eficiencia de combustible. Al comprender esta relación, podemos utilizar este conocimiento en nuestro beneficio al diseñar un automóvil.</p>
<p>Para explicar una relación, nos interesa mantener los modelos lo más pequeños posible, ya que los modelos más pequeños son fáciles de interpretar. Cuantos menos predictores, menos consideraciones debemos tener en cuenta en nuestro proceso de diseño. Además, cuantas menos interacciones y términos polinomiales, más fácil sea interpretar cualquier parámetro, ya que las interpretaciones de los parámetros están condicionadas a qué parámetros están en el modelo.</p>
<p>Tenga en cuenta que los modelos <em>lineales</em> son bastante interpretables para empezar. Más adelante en sus carreras de análisis de datos, verá modelos más complicados que pueden ajustarse mejor a los datos, pero son mucho más difíciles, si no imposibles, de interpretar. Estos modelos no son muy útiles para explicar una relación.</p>
<p>Para encontrar modelos pequeños e interpretables, usaríamos un criterio de selección que <em>explícitamente</em> penaliza a modelos más grandes, como AIC y BIC. En este caso todavía obtuvimos un modelo algo grande, pero mucho más pequeño que el modelo que usamos para iniciar el proceso de selección.</p>
<div id="correlación-y-causalidad-1" class="section level4" number="16.4.1.1">
<h4><span class="header-section-number">16.4.1.1</span> Correlación y causalidad</h4>
<p>Una advertencia al usar un modelo para <em>explicar</em> una relación. Hay dos términos que se utilizan a menudo para describir una relación entre dos variables: <em>causalidad</em> y <em>correlación</em>. <a href="https://xkcd.com/552/" target="_blank">Correlación</a> a menudo también se conoce como asociación.</p>
<p>El hecho de que dos variables estén correlacionadas no significa necesariamente que una cause la otra. Por ejemplo, considerando el modelado de <code>mpg</code> como solo una función de <code>hp</code>.</p>
<div class="sourceCode" id="cb1418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1418-1"><a href="selección-de-variables-y-construcción-de-modelos.html#cb1418-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mpg <span class="sc">~</span> hp, <span class="at">data =</span> autompg, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<p><img src="EstadisticaR_files/figure-html/unnamed-chunk-652-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>¿Un aumento en los caballos de fuerza causa una disminución en la eficiencia del combustible? O quizás la causalidad se invierte y un aumento en la eficiencia del combustible causa una disminución en los caballos de fuerza. ¡O quizás haya una tercera variable que explique ambos!</p>
<p>El problema es que tenemos datos <strong>de observación</strong>. Con datos de observación, solo podemos detectar asociaciones. Para hablar con confianza sobre la causalidad, necesitaríamos realizar <strong>experimentos</strong>.</p>
<p>Este es un concepto que debe encontrar a menudo en su educación estadística. Para leer más y algunas falacias relacionadas, consulte: <a href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation" target="_blank">Wikipedia: La correlación no implica causalidad</a>.</p>
</div>
</div>
<div id="predicción-1" class="section level3" number="16.4.2">
<h3><span class="header-section-number">16.4.2</span> Predicción</h3>
<p>Supongamos que ahora, en lugar del fabricante al que le gustaría fabricar un automóvil, somos un consumidor que desea comprar un automóvil nuevo. Sin embargo, este automóvil en particular es tan nuevo que no ha sido probado rigurosamente, por lo que no estamos seguros de qué eficiencia de combustible esperar. (Y, como escépticos, no confiamos en lo que nos dice el fabricante).</p>
<p>En este caso, nos gustaría usar el modelo para ayudar a <em>predecir</em> la eficiencia de combustible de este automóvil en función de sus atributos, que son los predictores del modelo. Cuanto menores son los errores que comete el modelo, más confianza tenemos en su predicción. Por lo tanto, para encontrar modelos de predicción, usaríamos un criterio de selección que <em>implícitamente</em> penaliza a los modelos más grandes, como LOOCV <span class="math inline">\(\text{RMSE}\)</span>. Siempre que el modelo no se ajuste demasiado, en realidad no nos importa qué tan grande sea el modelo. Explicar la relación entre las variables no es nuestro objetivo aquí, ¡simplemente queremos saber qué tipo de eficiencia de combustible debemos esperar!</p>
<p>Si ** solo ** nos preocupamos por la predicción, no debemos preocuparnos por la correlación frente a la causalidad, y no debemos preocuparnos por los supuestos del modelo.</p>
<p>Si una variable está correlacionada con la respuesta, en realidad no importa si causa un efecto en la respuesta, aún puede ser útil para la predicción. Por ejemplo, en los niños en edad escolar primaria la talla de su zapato ciertamente no <em>hace</em> que lean a un nivel superior, sin embargo, podríamos usar la talla de un zapato muy fácilmente para hacer una predicción sobre la capacidad de lectura de un niño. Cuanto mayor sea el tamaño de sus zapatos, mejor leen. Sin embargo, hay una variable al acecho aquí, ¡su edad! (No envíe a sus hijos a la escuela con zapatos de talla 40, ¡no les hará leer mejor!)</p>
<p>Tampoco nos importan los supuestos del modelo. Los mínimos cuadrados son mínimos cuadrados. Para un modelo específico, encontrará los valores de los parámetros que minimizarán la pérdida por error al cuadrado. Sus resultados pueden ser en gran parte ininterpretables e inútiles para la inferencia, pero para la predicción nada de eso importa.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="colinealidad.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regresión-logística.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
